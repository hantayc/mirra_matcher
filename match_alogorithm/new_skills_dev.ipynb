{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "import spacy\n",
    "from functools import lru_cache\n",
    "import torch\n",
    "from utils.semantic_similarity import nlp_similarity_cached # import first\n",
    "from utils.semantic_similarity import sentence_model # import second\n",
    "\n",
    "current_wd = os.getcwd()\n",
    "\n",
    "def safe_json_loads(val):\n",
    "    try:\n",
    "        return json.loads(val)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error parsing JSON: {val}\")\n",
    "        return None\n",
    "\n",
    "job_desc_data = pd.read_excel(os.path.join(current_wd, \"data\", \"sample_des_extractions_test_final_3.25.25.xlsx\"))\n",
    "resume_data = pd.read_excel(os.path.join(current_wd, \"data\", \"sample_res_extractions_final_3.26.25.xlsx\"))\n",
    "\n",
    "job_desc_data[\"job_desc_parsed\"] = job_desc_data[\"extracted\"].apply(safe_json_loads)\n",
    "resume_data[\"resume_parsed\"] = resume_data[\"extracted\"].apply(safe_json_loads)\n",
    "\n",
    "job_desc_json = job_desc_data['job_desc_parsed']\n",
    "resume_json = resume_data['resume_parsed']\n",
    "\n",
    "def append_job_id_to_job_desc(row):\n",
    "    job_id = row['id']\n",
    "    job_desc = row['job_desc_parsed']\n",
    "\n",
    "    if job_desc is None:\n",
    "        return None\n",
    "    \n",
    "    if isinstance(job_desc, str):\n",
    "        job_desc = safe_json_loads(job_desc)\n",
    "        if job_desc is None:\n",
    "            return None\n",
    "    \n",
    "    job_desc['job_id'] = job_id\n",
    "    return job_desc\n",
    "\n",
    "job_desc_data['job_desc_json'] = job_desc_data.apply(append_job_id_to_job_desc, axis=1)\n",
    "\n",
    "def extract_all_strings_from_json(j):\n",
    "    \"\"\"\n",
    "    Recursively extracts all non-empty strings from a JSON-like object (dict or list).\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if isinstance(j, dict):\n",
    "        for v in j.values():\n",
    "            result.extend(extract_all_strings_from_json(v))\n",
    "    elif isinstance(j, list):\n",
    "        for item in j:\n",
    "            if isinstance(item, str):\n",
    "                s = item.strip()\n",
    "                if s:\n",
    "                    result.append(s)\n",
    "            else:\n",
    "                result.extend(extract_all_strings_from_json(item))\n",
    "    return result\n",
    "\n",
    "# Precompute Embeddings from a list of JSONS\n",
    "def precompute_embeddings_for_json_list(json_list, batch_size=64):\n",
    "    \"\"\"\n",
    "    Iterates over a list (or Series) of JSON objects, extracts all non-empty strings\n",
    "    from each JSON, computes embeddings for all unique strings in batches, and returns\n",
    "    a dictionary mapping each unique string to its embedding.\n",
    "    \n",
    "    Parameters:\n",
    "      json_list (iterable): A list (or Series) of JSON objects (dicts).\n",
    "      batch_size (int): Batch size for encoding.\n",
    "      \n",
    "    Returns:\n",
    "      dict: A mapping from string to its embedding.\n",
    "    \"\"\"\n",
    "    all_strings = set()\n",
    "    for j in json_list:\n",
    "        if j is None:\n",
    "            continue\n",
    "        strings = extract_all_strings_from_json(j)\n",
    "        all_strings.update(strings)\n",
    "    \n",
    "    all_strings = list(all_strings)\n",
    "    if all_strings:\n",
    "        embeddings = sentence_model.encode(all_strings, batch_size=batch_size, convert_to_tensor=False)\n",
    "    else:\n",
    "        embeddings = np.zeros((0, sentence_model.get_sentence_embedding_dimension()))\n",
    "    \n",
    "    string_to_emb = {s: emb for s, emb in zip(all_strings, embeddings)}\n",
    "    return string_to_emb\n",
    "\n",
    "# Now call the function with your list of job description JSON objects:\n",
    "embeddings = precompute_embeddings_for_json_list(job_desc_json, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'skill': [['Salesforce development', 'Sales cloud'], ['Salesforce development', 'Services cloud'], ['Salesforce development', 'Financial Services cloud']], 'minyears': [0]}, {'skill': [['Salesforce.com development', 'SOQL'], ['Salesforce.com development', 'Apex']], 'minyears': [4]}, {'skill': [['SOQL']], 'minyears': [0]}, {'skill': [['Apex']], 'minyears': [0]}, {'skill': [['Lightning']], 'minyears': [0]}, {'skill': [['LWC']], 'minyears': [0]}, {'skill': [['User Management', 'User Profiles']], 'minyears': [0]}, {'skill': [['User Management', 'User Permission Sets']], 'minyears': [0]}, {'skill': [['User Management', 'Sharing Rules']], 'minyears': [0]}, {'skill': [['User Management', 'Role Hierarchy']], 'minyears': [0]}, {'skill': [['User Management', 'User Setup']], 'minyears': [0]}, {'skill': [['Standard Object testing', 'Workflows'], ['Standard Object modifications', 'Workflows']], 'minyears': [0]}, {'skill': [['Standard Object testing', 'Approval Processes'], ['Standard Object modifications', 'Approval Processes']], 'minyears': [0]}, {'skill': [['Standard Object testing', 'Page Layouts'], ['Standard Object modifications', 'Page Layouts']], 'minyears': [0]}]\n",
      "[{'skill': ['Engineered C# .NET Core solutions', 'Microsoft Azure microservices architecture', 'Kafka as a message queue'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Implemented external integration', 'several partners', 'exchange business-critical information'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Collaborated with the QA team', 'formulate comprehensive test cases', 'end-to-end testing'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Conducted thorough code reviews', 'suggested improvements', 'adhere to existing architecture'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Implemented Angular components', 'ASP.NET Core RESTful Web API'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Implemented solutions', 'Prometheus', 'Grafana', 'an intelligent dashboard', 'monitor services'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Optimized MongoDB', 'real-time high-throughput operations'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Optimized SQL Server', 'real-time high-throughput operations'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Produced accurate technical documentation', 'a strong knowledge base', 'future development', 'support initiatives'], 'years': 2.0, 'job_id': 'SoftwareDeveloper|Zellis|2.0'}, {'skill': ['Engineered C# .NET Core solutions', 'microservices architecture'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Worked with enterprise architects', 'design complex solutions'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Worked with enterprise architects', 'review complex solutions'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Worked with enterprise architects', 'simplify complex solutions'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Created React UI', 'ASP.NET RESTful Web API', 'WCF backends'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Completed integrations', 'several insurance providers', 'exchange policy and claims information'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Optimized code', 'legacy software solutions'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Produced accurate technical documentation', 'Wiki pages', 'improve the knowledge base'], 'years': 1.25, 'job_id': 'SoftwareDeveloper|HastingsMutual|1.25'}, {'skill': ['Planned migrations', 'legacy .NET Framework applications', '.NET Core'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Executed migrations', 'legacy .NET Framework applications', '.NET Core'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Created UI solutions', 'Angular', 'ASP.NET RESTful Web APIs'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Migrated legacy Windows Forms applications', 'ASP.NET', 'Angular'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Worked with business analysts', 'gather requirements'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Worked with business analysts', 'create requirements'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Worked with business analysts', 'optimize requirements'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Worked with end users', 'gather requirements'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Worked with end users', 'create requirements'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Worked with end users', 'optimize requirements'], 'years': 2.08, 'job_id': 'SoftwareDeveloper|[CompanyName]|2.08'}, {'skill': ['Planned the cloud platform', 'Microsoft Azure', 'a microservices infrastructure'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed the cloud platform', 'Microsoft Azure', 'a microservices infrastructure'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented the cloud platform', 'Microsoft Azure', 'a microservices infrastructure'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Optimized the cloud platform', 'Microsoft Azure', 'a microservices infrastructure'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed a geographically distributed MongoDB cluster architecture', 'configured Ops Manager'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented a geographically distributed MongoDB cluster architecture', 'configured Ops Manager'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed scalable Angular solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented scalable Angular solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed scalable .NET Core C# solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented scalable .NET Core C# solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed scalable Java solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented scalable Java solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed scalable Go solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented scalable Go solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed scalable Python solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented scalable Python solutions', 'Tibco EMS', 'Kafka'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Designed a high-throughput service layer', 'Kafka middleware', 'handling Privacy Law inquiries'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Implemented a high-throughput service layer', 'Kafka middleware', 'handling Privacy Law inquiries'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Executed integrations', 'Microsoft Dynamic', 'Salesforce', 'Siebel', 'in-house applications'], 'years': 6.17, 'job_id': 'SoftwareDeveloper|CITI|6.17'}, {'skill': ['Led the Enterprise Services and Solutions team', 'designing Service Oriented Architectures', '.NET Web API', 'WCF'], 'years': 0.92, 'job_id': 'SoftwareDeveloper|CIT|0.92'}, {'skill': ['Directed the implementation of software services and solutions', 'planning', 'monitoring', 'maintenance', 'development', 'upgrade', 'support'], 'years': 0.92, 'job_id': 'SoftwareDeveloper|CIT|0.92'}, {'skill': ['Collaborated with offshore development teams', 'optimize support-related activities'], 'years': 0.92, 'job_id': 'SoftwareDeveloper|CIT|0.92'}, {'skill': ['Worked with cross-functional management teams', 'identify business requirements', 'plan software development initiatives'], 'years': 0.92, 'job_id': 'SoftwareDeveloper|CIT|0.92'}, {'skill': ['Defined infrastructure strategies', 'ensure continuous improvements', 'production platforms'], 'years': 0.92, 'job_id': 'SoftwareDeveloper|CIT|0.92'}, {'skill': ['Applied infrastructure strategies', 'ensure continuous improvements', 'production platforms'], 'years': 0.92, 'job_id': 'SoftwareDeveloper|CIT|0.92'}, {'skill': ['Implemented NYPD Counter-terrorism and Domain Awareness System', 'analyze data', 'detect threats'], 'years': 3.42, 'job_id': 'SoftwareDeveloper|Microsoft|3.42'}, {'skill': ['Implemented a large cluster of FAST search indexes', 'ensured high availability for records'], 'years': 3.42, 'job_id': 'SoftwareDeveloper|Microsoft|3.42'}, {'skill': ['Implemented enterprise solutions', 'MVC', 'jQuery', 'WPF', 'WCF', 'WF', 'EF', 'SQL'], 'years': 3.42, 'job_id': 'SoftwareDeveloper|Microsoft|3.42'}, {'skill': ['Assessed product needs', 'communicated requirements', 'development groups'], 'years': 3.42, 'job_id': 'SoftwareDeveloper|Microsoft|3.42'}, {'skill': ['Assessed product needs', 'communicated requirements', 'testing groups'], 'years': 3.42, 'job_id': 'SoftwareDeveloper|Microsoft|3.42'}, {'skill': ['Conducted software engineering', 'multiple projects'], 'years': 0.58, 'job_id': 'SoftwareDeveloper|Bowne&Co|0.58'}, {'skill': ['Conducted software development', 'multiple projects'], 'years': 0.58, 'job_id': 'SoftwareDeveloper|Bowne&Co|0.58'}, {'skill': ['Designed a distributed order management system', 'SPA web interface'], 'years': 0.58, 'job_id': 'SoftwareDeveloper|Bowne&Co|0.58'}, {'skill': ['Developed an advanced Distributed Notification System'], 'years': 0.58, 'job_id': 'SoftwareDeveloper|Bowne&Co|0.58'}, {'skill': ['Created a Distributed Business Rules Engine'], 'years': 0.58, 'job_id': 'SoftwareDeveloper|Bowne&Co|0.58'}, {'skill': ['Created a Distributed Business Rules Engine', 'C#', 'WCF'], 'years': 0.67, 'job_id': 'SoftwareDeveloper|KPMGInternational|0.67'}, {'skill': ['Developed SQL Server queries'], 'years': 0.67, 'job_id': 'SoftwareDeveloper|KPMGInternational|0.67'}, {'skill': ['Enhanced SQL Server queries'], 'years': 0.67, 'job_id': 'SoftwareDeveloper|KPMGInternational|0.67'}, {'skill': ['Developed SQL Server stored procedures'], 'years': 0.67, 'job_id': 'SoftwareDeveloper|KPMGInternational|0.67'}, {'skill': ['Enhanced SQL Server stored procedures'], 'years': 0.67, 'job_id': 'SoftwareDeveloper|KPMGInternational|0.67'}, {'skill': ['Implemented ASP.NET components', 'Ajax'], 'years': 0.67, 'job_id': 'SoftwareDeveloper|KPMGInternational|0.67'}, {'skill': ['Worked with a globally-based architecture team', 'reengineer connected systems'], 'years': 0.5, 'job_id': 'SoftwareDeveloper|GettyImages|0.5'}, {'skill': ['Designed various software UI components'], 'years': 0.5, 'job_id': 'SoftwareDeveloper|GettyImages|0.5'}, {'skill': ['Collaborated with global analysts', 'engineer a Distributed Electronic Publishing System'], 'years': 0.42, 'job_id': 'SoftwareDeveloper|MoodysInvestorsService|0.42'}, {'skill': ['Developed an ASP.NET application', 'system management', 'administration'], 'years': 0.42, 'job_id': 'SoftwareDeveloper|MoodysInvestorsService|0.42'}, {'skill': ['Implemented Active Directory-based security', 'user authentication', 'authorization'], 'years': 0.42, 'job_id': 'SoftwareDeveloper|MoodysInvestorsService|0.42'}, {'skill': ['Supported cross-functional teams', 'define requirements', 'complete the development of a Risk Evaluation and Management System'], 'years': 0.67, 'job_id': 'SoftwareDeveloper|KPMGInternational|0.67'}, {'skill': ['Visual Studio'], 'years': 0.0, 'job_id': ''}, {'skill': ['JetBrains Rider'], 'years': 0.0, 'job_id': ''}, {'skill': ['VS Code'], 'years': 0.0, 'job_id': ''}, {'skill': ['Spider'], 'years': 0.0, 'job_id': ''}, {'skill': ['Database Tools'], 'years': 0.0, 'job_id': ''}, {'skill': ['Eclipse'], 'years': 0.0, 'job_id': ''}, {'skill': ['IntelliJ'], 'years': 0.0, 'job_id': ''}, {'skill': ['C#'], 'years': 0.0, 'job_id': ''}, {'skill': ['Java'], 'years': 0.0, 'job_id': ''}, {'skill': ['Go'], 'years': 0.0, 'job_id': ''}, {'skill': ['Python'], 'years': 0.0, 'job_id': ''}, {'skill': ['JavaScript'], 'years': 0.0, 'job_id': ''}, {'skill': ['Microsoft Azure'], 'years': 0.0, 'job_id': ''}, {'skill': ['Linux'], 'years': 0.0, 'job_id': ''}, {'skill': ['Windows'], 'years': 0.0, 'job_id': ''}, {'skill': ['MongoDB'], 'years': 0.0, 'job_id': ''}, {'skill': ['SQL'], 'years': 0.0, 'job_id': ''}, {'skill': ['Oracle'], 'years': 0.0, 'job_id': ''}, {'skill': ['RavenDB'], 'years': 0.0, 'job_id': ''}, {'skill': ['ElasticSearch'], 'years': 0.0, 'job_id': ''}, {'skill': ['Parallel/Multi-threaded Programming'], 'years': 0.0, 'job_id': ''}, {'skill': ['Continuous Integration'], 'years': 0.0, 'job_id': ''}, {'skill': ['Service-Oriented Architecture'], 'years': 0.0, 'job_id': ''}, {'skill': ['SaaS'], 'years': 0.0, 'job_id': ''}, {'skill': ['Design Patterns'], 'years': 0.0, 'job_id': ''}, {'skill': ['Automated Testing'], 'years': 0.0, 'job_id': ''}, {'skill': ['Documentation'], 'years': 0.0, 'job_id': ''}]\n"
     ]
    }
   ],
   "source": [
    "from utils.mandatory_skill_score import extract_job_mandatory_skills\n",
    "from utils.mandatory_skill_score import extract_resume_skills\n",
    "\n",
    "job_skills = extract_job_mandatory_skills(job_desc_json[1])\n",
    "resume_skills = extract_resume_skills(resume_json[1])\n",
    "\n",
    "print(job_skills)\n",
    "print(resume_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################\n",
      "BEGIN: calculate_mandatory_skill_scores\n",
      "##################################\n",
      "\n",
      "======================\n",
      "PROCESSING JOB_ID: Salesforce_Dev_Job\n",
      "======================\n",
      "\n",
      "======================\n",
      "BEGIN: calculate_skill_match_score\n",
      "======================\n",
      "\n",
      "********** REQUIREMENT #1 **********\n",
      "\n",
      "=== Processing Single Skill Requirement ===\n",
      "Required skill: [['Apex'], ['Salesforce development', 'Apex']]\n",
      "Min years required: 4\n",
      "\n",
      "-- Sorted Skill Entries (desc by sim) --\n",
      " 1) job_id='[EMPTY]', sim=1.000, yrs=4.00\n",
      " 2) job_id='MyPastJob|Company|2.0', sim=0.861, yrs=3.00\n",
      " 3) job_id='MyPastJob|Company|3.0', sim=0.826, yrs=3.00\n",
      "Chose empty job_id skill alone: yrs=4, sim=1.000, coverage_used=4.00\n",
      "=> Full coverage. Weighted sum = 1.000\n",
      "[REQUIREMENT #1] Weighted Similarity Score = 1.000\n",
      "\n",
      "=> Overall Mandatory Skill Match Score = 1.000\n",
      "\n",
      "########## FINAL RESULTS ##########\n",
      "  job_id = Salesforce_Dev_Job => {'mandatory_skill_score': 1.0}\n",
      "###################################\n",
      "\n",
      "=== DONE ===\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from utils.semantic_similarity import nlp_similarity_cached\n",
    "\n",
    "\n",
    "def safe_average(values):\n",
    "    valid = [v for v in values if v is not None]\n",
    "    return sum(valid) / len(valid) if valid else None\n",
    "\n",
    "\n",
    "def extract_job_mandatory_skills(job_json):\n",
    "    return job_json.get(\"mandatory\", {}).get(\"hard_skills\", [])\n",
    "\n",
    "\n",
    "def extract_resume_skills(resume_json):\n",
    "    return resume_json.get(\"skills\", [])\n",
    "\n",
    "\n",
    "def compute_group_similarity(candidate_group, required_group):\n",
    "    \"\"\"\n",
    "    For a multi-term required_group (e.g. [\"Salesforce dev\", \"Apex\"]),\n",
    "    find the best match for each required term among candidate_group,\n",
    "    then average those best matches.\n",
    "    \"\"\"\n",
    "    if not candidate_group or not required_group:\n",
    "        return 0.0\n",
    "\n",
    "    sims_for_required_terms = []\n",
    "    for req_term in required_group:\n",
    "        best_for_req_term = 0.0\n",
    "        for cand_term in candidate_group:\n",
    "            sim = nlp_similarity_cached(cand_term, req_term)\n",
    "            if sim > best_for_req_term:\n",
    "                best_for_req_term = sim\n",
    "        sims_for_required_terms.append(best_for_req_term)\n",
    "    return sum(sims_for_required_terms) / len(sims_for_required_terms)\n",
    "\n",
    "\n",
    "def compute_required_skill_similarity(candidate_skill_item, job_required_skill):\n",
    "    \"\"\"\n",
    "    Each job_required_skill can be a list of multiple sub-groups\n",
    "    e.g. [ [\"Salesforce dev\",\"Apex\"], [\"Salesforce.com development\",\"Apex\"] ].\n",
    "    We find the best among them.\n",
    "    \"\"\"\n",
    "    if not job_required_skill:\n",
    "        return 0.0\n",
    "\n",
    "    # If the job_required_skill is a single group, wrap it for uniform iteration\n",
    "    if isinstance(job_required_skill[0], str):\n",
    "        job_required_skill = [job_required_skill]\n",
    "\n",
    "    candidate_group = candidate_skill_item.get(\"skill\", [])\n",
    "    if not candidate_group:\n",
    "        return 0.0\n",
    "\n",
    "    best_sim = 0.0\n",
    "    for req_group in job_required_skill:\n",
    "        sim_score = compute_group_similarity(candidate_group, req_group)\n",
    "        if sim_score > best_sim:\n",
    "            best_sim = sim_score\n",
    "    return best_sim\n",
    "\n",
    "\n",
    "def aggregate_best_entries(resume_skills, job_required_skill):\n",
    "    \"\"\"\n",
    "    Returns a list of dicts, each dict having:\n",
    "        {\n",
    "          \"job_id\": ...,\n",
    "          \"sim\": <best similarity for that job_id>,\n",
    "          \"years\": <max years for that job_id>\n",
    "        }\n",
    "\n",
    "    We do NOT sum multiple lines from the same job_id; we take whichever line\n",
    "    has the highest similarity, and whichever has the maximum years, for that job_id.\n",
    "    \"\"\"\n",
    "    # Temporary map of job_id -> {\"sim\": float, \"years\": float}\n",
    "    by_job_id = {}\n",
    "\n",
    "    for cand_skill_item in resume_skills:\n",
    "        jbid = cand_skill_item.get(\"job_id\", \"\")\n",
    "        cand_years = cand_skill_item.get(\"years\", 0.0)\n",
    "        sim = compute_required_skill_similarity(cand_skill_item, job_required_skill)\n",
    "\n",
    "        if jbid not in by_job_id:\n",
    "            by_job_id[jbid] = {\"sim\": sim, \"years\": cand_years}\n",
    "        else:\n",
    "            if sim > by_job_id[jbid][\"sim\"]:\n",
    "                by_job_id[jbid][\"sim\"] = sim\n",
    "            if cand_years > by_job_id[jbid][\"years\"]:\n",
    "                by_job_id[jbid][\"years\"] = cand_years\n",
    "\n",
    "    # Convert to a list\n",
    "    result = []\n",
    "    for jbid, vals in by_job_id.items():\n",
    "        # Only keep if similarity > 0\n",
    "        if vals[\"sim\"] > 0.0:\n",
    "            result.append({\n",
    "                \"job_id\": jbid,\n",
    "                \"sim\": vals[\"sim\"],\n",
    "                \"years\": vals[\"years\"]\n",
    "            })\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_single_requirement_score(resume_skills, job_required_skill, min_years_required):\n",
    "    \"\"\"\n",
    "    Core function that:\n",
    "\n",
    "    1) Aggregates the best similarity & max years per job_id.\n",
    "    2) Sorts them by similarity desc.\n",
    "    3) Iterates in descending similarity order:\n",
    "       a) If coverageUsed=0 and we encounter an empty job_id skill:\n",
    "          - If it alone meets min_years_required => done\n",
    "          - Else skip it\n",
    "       b) If coverageUsed=0 and we encounter a real job_id skill => start summation from real job_ids\n",
    "          until min_years_required is met or exhausted\n",
    "       c) Once we pick coverage from empty or real, we do NOT mix them.\n",
    "\n",
    "    Returns the final weighted similarity score for this requirement.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Processing Single Skill Requirement ===\")\n",
    "    print(f\"Required skill: {job_required_skill}\")\n",
    "    print(f\"Min years required: {min_years_required}\")\n",
    "\n",
    "    if not resume_skills or not job_required_skill:\n",
    "        return 0.0\n",
    "\n",
    "    # Gather best skill lines (one per job_id)\n",
    "    best_entries = aggregate_best_entries(resume_skills, job_required_skill)\n",
    "\n",
    "    if not best_entries:\n",
    "        print(\"No nonzero similarity entries. Returning 0.0\")\n",
    "        return 0.0\n",
    "\n",
    "    # Sort by similarity desc\n",
    "    best_entries.sort(key=lambda x: x[\"sim\"], reverse=True)\n",
    "\n",
    "    coverage_used = 0.0\n",
    "    weighted_sum = 0.0\n",
    "    coverage_mode = None  # can be \"real\" or \"empty\"\n",
    "    needed = float(min_years_required)\n",
    "\n",
    "    print(\"\\n-- Sorted Skill Entries (desc by sim) --\")\n",
    "    for i, e in enumerate(best_entries, 1):\n",
    "        print(f\" {i}) job_id='{e['job_id'] or '[EMPTY]'}', sim={e['sim']:.3f}, yrs={e['years']:.2f}\")\n",
    "\n",
    "    # Now iterate in sorted order\n",
    "    for item in best_entries:\n",
    "        jbid = item[\"job_id\"]\n",
    "        sim  = item[\"sim\"]\n",
    "        yrs  = item[\"years\"]\n",
    "\n",
    "        if coverage_used >= min_years_required:\n",
    "            print(\"Already met coverage. Break.\")\n",
    "            break\n",
    "\n",
    "        # If we haven't chosen coverage yet (coverage_mode=None):\n",
    "        if coverage_mode is None:\n",
    "            if jbid.strip() == \"\":\n",
    "                # It's an empty job_id skill\n",
    "                if yrs >= min_years_required:\n",
    "                    # Use it alone => done\n",
    "                    fraction = min_years_required / float(min_years_required)\n",
    "                    weighted_sum += sim * fraction\n",
    "                    coverage_used += min_years_required\n",
    "                    coverage_mode = \"empty\"\n",
    "                    print(f\"Chose empty job_id skill alone: yrs={yrs}, sim={sim:.3f}, coverage_used={coverage_used:.2f}\")\n",
    "                    break\n",
    "                else:\n",
    "                    # Skip it, because it doesn't meet min years alone\n",
    "                    print(f\"Skipping empty job_id skill with yrs={yrs}, sim={sim:.3f}, doesn't meet min_years={min_years_required}.\")\n",
    "                    continue\n",
    "            else:\n",
    "                # It's a real job_id => start real coverage accumulation\n",
    "                coverage_mode = \"real\"\n",
    "                use_years = min(yrs, needed)\n",
    "                fraction = use_years / float(min_years_required)\n",
    "                weighted_sum += sim * fraction\n",
    "                coverage_used += use_years\n",
    "                needed -= use_years\n",
    "                print(f\"Starting real coverage with job_id={jbid}, sim={sim:.3f}, used_yrs={use_years:.2f}, coverage_used={coverage_used:.2f}\")\n",
    "        else:\n",
    "            # We already picked a mode\n",
    "            if coverage_mode == \"empty\":\n",
    "                # We used an empty job_id skill that meets coverage alone => we won't accumulate more\n",
    "                # So we just break or skip\n",
    "                print(\"Already satisfied coverage with an empty job_id skill. Not adding more.\")\n",
    "                break\n",
    "            else:\n",
    "                # coverage_mode == \"real\"\n",
    "                if jbid.strip() == \"\":\n",
    "                    # skip empty job_id lines\n",
    "                    print(f\"Skipping empty job_id skill because we already started real coverage: sim={sim:.3f}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    # same coverage_mode=real => accumulate partial coverage\n",
    "                    use_years = min(yrs, needed)\n",
    "                    fraction = use_years / float(min_years_required)\n",
    "                    weighted_sum += sim * fraction\n",
    "                    coverage_used += use_years\n",
    "                    needed -= use_years\n",
    "                    print(f\"Continuing real coverage with job_id={jbid}, sim={sim:.3f}, used_yrs={use_years:.2f}, coverage_used={coverage_used:.2f}\")\n",
    "\n",
    "    # If coverage_used < min_years_required, that's partial coverage\n",
    "    if coverage_used <= 0:\n",
    "        print(\"No coverage used => 0.0 final.\")\n",
    "        return 0.0\n",
    "\n",
    "    if coverage_used < min_years_required:\n",
    "        # partial coverage scenario\n",
    "        print(f\"=> Partial coverage: used {coverage_used} out of {min_years_required}\")\n",
    "        # Usually weighted_sum is already scaled fractionally, so we can just return it\n",
    "        return weighted_sum\n",
    "\n",
    "    # coverage_used >= min_years_required => full coverage\n",
    "    print(f\"=> Full coverage. Weighted sum = {weighted_sum:.3f}\")\n",
    "    return weighted_sum\n",
    "\n",
    "\n",
    "def calculate_skill_match_score(job_json, resume_json):\n",
    "    \"\"\"\n",
    "    Iterates over each mandatory skill requirement in the job JSON,\n",
    "    calls compute_single_requirement_score, and returns their average.\n",
    "    \"\"\"\n",
    "    print(\"\\n======================\")\n",
    "    print(\"BEGIN: calculate_skill_match_score\")\n",
    "    print(\"======================\")\n",
    "\n",
    "    job_skills = extract_job_mandatory_skills(job_json)\n",
    "    if not job_skills:\n",
    "        print(\"No mandatory skill requirements found. Returning None.\")\n",
    "        return None\n",
    "\n",
    "    resume_skills = extract_resume_skills(resume_json)\n",
    "    requirement_scores = []\n",
    "    for idx, req in enumerate(job_skills, start=1):\n",
    "        print(f\"\\n********** REQUIREMENT #{idx} **********\")\n",
    "        job_required_skill = req.get(\"skill\", [])\n",
    "        min_years_required = req.get(\"minyears\", [0])[0]\n",
    "\n",
    "        score_for_this_req = compute_single_requirement_score(\n",
    "            resume_skills,\n",
    "            job_required_skill,\n",
    "            min_years_required\n",
    "        )\n",
    "        print(f\"[REQUIREMENT #{idx}] Weighted Similarity Score = {score_for_this_req:.3f}\")\n",
    "        requirement_scores.append(score_for_this_req)\n",
    "\n",
    "    overall_skill = safe_average(requirement_scores)\n",
    "    if overall_skill is None:\n",
    "        print(\"No valid scores found at all. Returning None.\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"\\n=> Overall Mandatory Skill Match Score = {overall_skill:.3f}\")\n",
    "        return overall_skill\n",
    "\n",
    "\n",
    "def calculate_mandatory_skill_score(job_json, resume_json):\n",
    "    score = calculate_skill_match_score(job_json, resume_json)\n",
    "    return {\"mandatory_skill_score\": score}\n",
    "\n",
    "\n",
    "def calculate_mandatory_skill_scores(job_json_list, resume_json):\n",
    "    \"\"\"\n",
    "    Accepts a list of job JSON objects and returns a dictionary\n",
    "    mapping each job's job_id to its mandatory skill score.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    print(\"\\n##################################\")\n",
    "    print(\"BEGIN: calculate_mandatory_skill_scores\")\n",
    "    print(\"##################################\")\n",
    "\n",
    "    for i, job_json in enumerate(job_json_list, start=1):\n",
    "        job_id = job_json.get(\"job_id\", f\"job_{i}\")\n",
    "        print(f\"\\n======================\")\n",
    "        print(f\"PROCESSING JOB_ID: {job_id}\")\n",
    "        print(f\"======================\")\n",
    "        score_dict = calculate_mandatory_skill_score(job_json, resume_json)\n",
    "        results[job_id] = score_dict\n",
    "\n",
    "    print(\"\\n########## FINAL RESULTS ##########\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"  job_id = {k} => {v}\")\n",
    "    print(\"###################################\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# -------------------- Example Usage --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    job_json_list = [\n",
    "        {\n",
    "            \"job_id\": \"Salesforce_Dev_Job\",\n",
    "            \"mandatory\": {\n",
    "                \"hard_skills\": [\n",
    "                    {\n",
    "                        \"skill\": [\n",
    "                            [\"Apex\"],\n",
    "                            [\"Salesforce development\", \"Apex\"]\n",
    "                        ],\n",
    "                        \"minyears\": [4]\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Resume: The empty job_id line has 2 years (with 1.0 similarity), not enough for min=4\n",
    "    # So we'll skip that line, then accumulate coverage from real job_ids that sum to >= 4.\n",
    "    resume_json = {\n",
    "        \"skills\": [\n",
    "            {\n",
    "                \"skill\": [\"Salesforce.com development\", \"Apex\"],\n",
    "                \"years\": 4,\n",
    "                \"job_id\": \"\"  # perfect similarity but only 2 yrs\n",
    "            },\n",
    "            {\n",
    "                \"skill\": [\"Apex development\", \"Salesforce integrations\"],\n",
    "                \"years\": 3,\n",
    "                \"job_id\": \"MyPastJob|Company|2.0\"\n",
    "            },\n",
    "            {\n",
    "                \"skill\": [\"Apex triggers\", \"Salesforce deployments\"],\n",
    "                \"years\": 3,\n",
    "                \"job_id\": \"MyPastJob|Company|3.0\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    results = calculate_mandatory_skill_scores(job_json_list, resume_json)\n",
    "    print(\"\\n=== DONE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirra_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
