{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Anonymization Script\n",
    "\n",
    "## Overview\n",
    "This script is designed to **anonymize Personally Identifiable Information (PII)** from resumes. It reads in a CSV file containing resumes, detects sensitive information, and replaces it with anonymized placeholders to protect candidates' privacy.\n",
    "\n",
    "## Features\n",
    "- **Reads resume data from a CSV file**.\n",
    "- **Identifies PII elements** such as names, emails, phone numbers, and addresses.\n",
    "- **Replaces PII with generic placeholders** to ensure confidentiality.\n",
    "- **Exports the anonymized data** into a new CSV file for further processing or sharing.\n",
    "\n",
    "## Why Anonymization?\n",
    "Protecting PII is crucial in resume processing, especially when handling large datasets for **machine learning models, recruitment analysis, or compliance with data privacy regulations (e.g., GDPR, CCPA)**.\n",
    "\n",
    "## Installation & Setup\n",
    "1. **Clone the Repository**:\n",
    "   ```bash\n",
    "   git clone https://github.com/hantayc/mirra_matcher.git\n",
    "   cd mirra_matcher\n",
    "\n",
    "2. ** Set up a Virtual Env (if needed) ** \n",
    "   ```bash\n",
    "   python -m venv mirra_env\n",
    "   source mirra_env/bin/activate  # Windows: mirra_env\\Scripts\\Activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/than/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_anonymizer.entities import OperatorConfig\n",
    "\n",
    "# Download word list (only required once)\n",
    "nltk.download('words')\n",
    "english_words = set(words.words())\n",
    "\n",
    "# Initialize Presidio components\n",
    "analyzer = AnalyzerEngine()\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "def clean_text_spacing(text):\n",
    "    \"\"\"Fixes missing spaces between words, numbers, and punctuation, including emails.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    text = text.strip()  # Remove extra leading/trailing spaces\n",
    "    \n",
    "    # Add space between lowercase and uppercase transitions (e.g., ProjectManagement → Project Management)\n",
    "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
    "\n",
    "    # Add space before numbers that are stuck to letters (e.g., \"1049E-mail\" → \"1049 E-mail\")\n",
    "    text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', text)\n",
    "\n",
    "    # Add space after numbers that are stuck to letters (e.g., \"June2022\" → \"June 2022\")\n",
    "    text = re.sub(r'(\\d)(\\D)', r'\\1 \\2', text)\n",
    "\n",
    "    # Normalize multiple spaces to a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def anonymize_first_words(text, num_words=3):\n",
    "    \"\"\"Anonymizes the first `num_words` words if they are not real English words.\"\"\"\n",
    "    words_list = text.split()\n",
    "\n",
    "    for i in range(min(num_words, len(words_list))):\n",
    "        if words_list[i].lower() not in english_words:  \n",
    "            words_list[i] = \"[REDACTED NAME]\"\n",
    "\n",
    "    return \" \".join(words_list)\n",
    "\n",
    "def anonymize_resume(text):\n",
    "    \"\"\"Applies Presidio anonymization after fixing spacing and first-word checks.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    # Preprocess text to fix spacing issues\n",
    "    text = clean_text_spacing(text)\n",
    "\n",
    "    # Aggressively redact the first three words if they are not real English words\n",
    "    text = anonymize_first_words(text, num_words=3)\n",
    "\n",
    "    # Analyze text with Presidio\n",
    "    analyzer_results = analyzer.analyze(\n",
    "        text=text, \n",
    "        entities=[\"PERSON\", \"PHONE_NUMBER\", \"EMAIL_ADDRESS\", \"URL\"], \n",
    "        language=\"en\"\n",
    "    )\n",
    "\n",
    "    # Define anonymization rules\n",
    "    operators = {\n",
    "        \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED]\"}),  \n",
    "        \"PHONE_NUMBER\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED PHONE]\"}),\n",
    "        \"EMAIL_ADDRESS\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED EMAIL]\"}),\n",
    "        \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED NAME]\"}),\n",
    "        \"URL\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED LINK]\"})  \n",
    "    }\n",
    "\n",
    "    # Apply Presidio anonymization\n",
    "    anonymized_result = anonymizer.anonymize(text=text, analyzer_results=analyzer_results, operators=operators)\n",
    "\n",
    "    return anonymized_result.text\n",
    "\n",
    "# Load Resume Data\n",
    "df = pd.read_csv('1200 Resumes 2024.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Cleans text by removing BOM, fixing spaces, and ensuring name recognition.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Remove BOM (Byte Order Mark) if present\n",
    "    text = text.replace(\"\\ufeff\", \"\").strip()\n",
    "\n",
    "    # Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 1. Apply fix before anonymization\n",
    "df[\"resume_clean\"] = df[\"resume_clean\"].apply(preprocess_text)\n",
    "\n",
    "# 2. Apply Cleaning Space Function to Entire Dataset \n",
    "df[\"cleaned_resume\"] = df[\"resume_clean\"].apply(clean_text_spacing)\n",
    "\n",
    "# 3. Apply Anonymization Function to Entire Dataset (Presidio now handles everything)\n",
    "df[\"anonymized_resume\"] = df[\"cleaned_resume\"].apply(anonymize_resume)\n",
    "\n",
    "# 4. Save Anonymized Data\n",
    "df.to_csv('1200 Resumes 2024 Anonymized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirra_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
