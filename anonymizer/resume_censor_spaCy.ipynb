{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Anonymization Script\n",
    "\n",
    "## Overview\n",
    "This script is designed to **anonymize Personally Identifiable Information (PII)** from resumes. It reads in a CSV file containing resumes, detects sensitive information, and replaces it with anonymized placeholders to protect candidates' privacy.\n",
    "\n",
    "## Features\n",
    "- **Reads resume data from a CSV file**.\n",
    "- **Identifies PII elements** such as names, emails, phone numbers, and addresses.\n",
    "- **Replaces PII with generic placeholders** to ensure confidentiality.\n",
    "- **Exports the anonymized data** into a new CSV file for further processing or sharing.\n",
    "\n",
    "## Why Anonymization?\n",
    "Protecting PII is crucial in resume processing, especially when handling large datasets for **machine learning models, recruitment analysis, or compliance with data privacy regulations (e.g., GDPR, CCPA)**.\n",
    "\n",
    "## Installation & Setup\n",
    "1. **Clone the Repository**:\n",
    "   ```bash\n",
    "   git clone https://github.com/hantayc/mirra_matcher.git\n",
    "   cd mirra_matcher\n",
    "\n",
    "2. ** Set up a Virtual Env (if needed) ** \n",
    "   ```bash\n",
    "   python -m venv mirra_env\n",
    "   source mirra_env/bin/activate  # Windows: mirra_env\\Scripts\\Activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define regex patterns for PII\n",
    "PHONE_PATTERN = r\"(\\+?1[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4})\"\n",
    "EMAIL_PATTERN = r\"([a-zA-Z0-9._%+-]+@\\S+\\.[a-zA-Z]{2,7})\"\n",
    "NAME_PATTERN = r\"\\b[A-Z][a-zA-Z]+\\b(?:\\s[A-Z][a-zA-Z]+)?\"\n",
    "\n",
    "def clean_text_spacing(text):\n",
    "    \"\"\"Fixes spacing issues like missing spaces after names and numbers.\"\"\"\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", text)  # Space between lowercase-uppercase transitions\n",
    "    text = re.sub(r\"(\\D)(\\d)\", r\"\\1 \\2\", text)  # Space before numbers\n",
    "    text = re.sub(r\"(\\d)(\\D)\", r\"\\1 \\2\", text)  # Space after numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "JOB_TITLES = {\n",
    "    \"Cybersecurity Specialist\", \"Data Engineer\", \"Software Engineer\", \"Project Manager\",\n",
    "    \"Senior Manager\", \"Business Analyst\", \"Product Manager\", \"Consultant\", \"Data Scientist\"\n",
    "}  # Expand this list based on real job titles\n",
    "\n",
    "def anonymize_names(text):\n",
    "    \"\"\"Replaces detected names in the first four words with [REDACTED NAME], but skips job titles.\"\"\"\n",
    "    text = clean_text_spacing(text)\n",
    "    words = text.split()\n",
    "    first_four_words = \" \".join(words[:4]) if len(words) >= 4 else \" \".join(words)\n",
    "\n",
    "    doc = nlp(first_four_words)\n",
    "\n",
    "    detected_names = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\" and ent.text.strip() not in JOB_TITLES:\n",
    "            detected_names.append(ent.text.strip())\n",
    "\n",
    "    # Backup regex for names\n",
    "    potential_names = re.findall(NAME_PATTERN, first_four_words)\n",
    "    for name in potential_names:\n",
    "        if name not in JOB_TITLES:\n",
    "            detected_names.append(name)\n",
    "\n",
    "    # Remove duplicates and redact detected names only if they are not job titles\n",
    "    for name in set(detected_names):\n",
    "        text = re.sub(rf\"\\b{re.escape(name)}\\b\", \"[REDACTED NAME]\", text, count=1)\n",
    "\n",
    "    return text\n",
    "\n",
    "def anonymize_phone_numbers(text):\n",
    "    \"\"\"Replaces phone numbers with [REDACTED PHONE]\"\"\"\n",
    "    return re.sub(PHONE_PATTERN, \"[REDACTED PHONE]\", text)\n",
    "\n",
    "def anonymize_emails(text):\n",
    "    \"\"\"Replaces email addresses with [REDACTED EMAIL]\"\"\"\n",
    "    return re.sub(EMAIL_PATTERN, \"[REDACTED EMAIL]\", text)\n",
    "\n",
    "def anonymize_resume(text):\n",
    "    \"\"\"Master function to anonymize PII\"\"\"\n",
    "    text = text.strip()\n",
    "    text = anonymize_phone_numbers(text)\n",
    "    text = anonymize_emails(text)\n",
    "    text = anonymize_names(text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces caused by redactions\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Resume Data\n",
    "df = pd.read_csv('1200 Resumes 2024.csv')\n",
    "\n",
    "# Specify the row numbers you want to test\n",
    "selected_rows = [16, 19, 25, 42]  # Change these row indices as needed\n",
    "\n",
    "# Select the chosen rows\n",
    "sample_resumes = df.loc[selected_rows, \"resume_clean\"]\n",
    "\n",
    "# Apply anonymization function\n",
    "df_sample = pd.DataFrame({\n",
    "    \"Original Resume\": sample_resumes,\n",
    "    \"Anonymized Resume\": sample_resumes.apply(anonymize_resume)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ORIGINAL RESUME (Row 16) ===\n",
      "﻿Shikha MalikSr. Enterprise Data Architect , USA    215-313-1722SUMMARY\tAccomplished data leader with a robust background spanning over 21 years, specializing in the establishment and institutionalization of data strategies, policies, and frameworks. Acknowledged for effectively managing data to mitigate operational risks and ensuring strict regulatory compliance through innovative solutions. Skilled in stakeholder management and fostering strong relationships, leading teams to high levels of achievement. Recognized for a sharp ability to identify and streamline inefficiencies, with demonstrated strengths in data governance, strategy formulation, and meeting business needs. Eager to apply this extensive background in a role that drives organizational growth and sets new benchmarks for success.KEY COMPETENCIES· Data Strategy· Enterprise Data Architecture· Policy and Standards· Data Governance· Road-mapping· Regulatory Compliance· Data Analytics· Strategic Planning, Execution· Data Warehousing· Data Management· Stakeholder Management· Data Mining· Data Privacy· Cross-Functional Leadership · Data Modeling · Data Quality· Innovation· Data Visualization· Data Retention· Data-Driven Decision-Making· Metadata Management· Data Migration· Data Lifecycle Analysis· Cloud ImplementationTECHNICAL PROFICIENCIES· Microsoft SQL Server· AWS S3 (Data Lake)· R· T-SQL· AWS Redshift· · SSRS· AWS Athena· SVN· SSIS· AWS Glue· Sharepoint· Microsoft PowerBI· AWS Glue Data Catalog· GitHub· · Data.World· Confluence· Oracle Warehouse Builder· Alation· · Oracle SQL Developer· · Scrum· PL/SQL· Atlan MS· SAFe Agile· · · OCM· Informatica MDM· MS Visio· MS Excel· Erwin Data Modeling· Lucid Charts· Microsoft OfficePROFESSIONAL EXPERIENCEOSS Inc, U.S.Sr. Enterprise Architect / Data Strategy LeaderSept 2019 - PresentAs a Senior Enterprise Architect and Strategic Data Leader at OSS Inc, I have driven transformative outcomes for esteemed clients such as KinderCare Learning Centers, Johnson & Johnson, Collins Aerospace, and Vertiv by:· Spearheading the development of target state data architecture and strategies.· Establishing and enforcing Data Quality standards across diverse datasets, ensuring enterprise-wide data integrity.· Formulating comprehensive data governance strategies, initiating programs, and defining roles like data stewardship and ownership.· Developing rigorous standards and policies for efficient master data management, selecting cutting-edge tools (e.g., data catalog, visualization, and master data management tools), and documenting governance strategies encompassing business rules and data lifecycle management.· Directing the technical aspects of data and information management for application portfolios, emphasizing secure data architecture delivery.· Aligning data architecture with key portfolio initiatives in collaboration with stakeholders, focusing on cost-effectiveness and practicality.· Leading big teams comprising of BI architects, project managers, business analysts, IT leads, developers, and test engineers.· Developing documentation and presentations, and facilitating discussions with business and technology stakeholders to secure buy-in.· Ensuring successful deployment of robust and scalable data solutions across various products and projects.· Assisting in evaluating tools and selecting vendors to meet expanding organizational data requirements. · Overseeing vendor partner resources and Database Analysts to ensure project alignment and delivery excellence.Publicis Sapient, USData Warehouse Architect / Business Intelligence Manager\t\t           Dec 2010 – Sep 2019I worked extensively with multiple clients, each presenting unique challenges and opportunities. Some of the key engagements include:· Client - Publicis Sapient(In house); Project - Deal Desk Costing Engine (\"The Engine\")· Led as chief architect and technical lead for \"The Engine\" team.· Collaborated with stakeholders to model the Engine Data Warehouse (Inmon) using Erwin data modeler.· Designed and implemented ETL processes for data integration using SSIS.· Managed an agile development team, ensuring timely deliveries to senior management.· Addressed Reporting and Data visualization needs in tandem with ongoing ETL development.· Self-taught R for dynamic business rule implementation and Revenue forecasting using Quadratic Regression.· Conducted workshops and demos for stakeholders and end users.· Client- Citibank; Project- Pricing Exception Management system (PrEM) Client Billing· Architected Business Intelligence solutions to optimize vendor selection based on client invoices, billing contracts, and Price Exception data.· Conducted data analysis and designed the data warehouse structure for the Billing Intelligence module.· Developed ETL processes aligned with client-specific business rules using SSIS. · Managed daily tracking and reporting using JIRA.· Created and presented reports using SQL Server Reporting Services (SSRS) in client workshops.· Client- Macquarie Bank; Project- Prophet· Collaborated with business analysts and stakeholders to integrate heterogeneous data sources.· Designed the Data Warehouse using Power Designer.·  Developed and implemented ETL processes to populate the Data Warehouse.· Partnered with the client's SSIS developer in agile environments to deliver the final product.· Provided guidance and conducted workshops for the MicroStrategy team to enhance reporting capabilities.· Client-Royal Bank of Scotland; Project- Ratings Trigger Risk (RTR)· Collaborated with a Senior Architect on complex design and solution brainstorming.· Designed logical and physical data models using Erwin for various modules.· Developed ETL processes using Oracle Warehouse Builder and created complex Oracle views with analytical functions.· Conducted workshops and demos for stakeholders and end users.· Contributed to ongoing maintenance and post-delivery enhancements of the product.Sopra Group, IndiaAssociate Architect\t\t           \t\t\t\t\tJune 2009 – Dec 2010· Designed and implemented comprehensive High-level and Low-level data warehouse designs across multiple projects for Orange Business Services (OBS), enhancing project execution efficiency and ensuring alignment with client objectives.· Improved system performance by implementing rigorous code reviews and SQL optimizations, resulting in enhanced operational efficiency and client satisfaction.· Recognized for leadership in managing complex projects and delivering solutions that met stringent quality and timeline requirements.· Coordinated and supervised project activities, encompassing Workflow Management and CDR processing for billing.· Developed detailed project plans, monitored progress, and ensured adherence to budget and timeline constraints.· Acted as a key liaison between technical teams and client stakeholders, facilitating clear communication and resolution of project issues.· Played a pivotal role in enhancing project delivery processes and methodologies, contributing to overall team efficiency and client satisfaction.GlobalLogic, IndiaSr. Data engineer/Tech lead\t\t\t\t\t\tMay 2006 - May 2009· Led the data migration initiative for Telarix, transitioning from SQL Server to Oracle, ensuring seamless integration and optimal performance.· Conducted a comprehensive feasibility study for the migration project, assessing technical requirements and potential challenges.· Senior Developer in the migration project's development team, overseeing the transition of CDR processing from SQL Server to Oracle.· Contributed to the development and design team of Billing software, enabling real-time traffic intelligence, settlement charge tracking, and partner invoice reconciliation for telecom giants.TATA Consultancy ServicesData Engineer\t\t\t\t\t\t\tJune 2003 - May 2006· Designed and developed scalable data pipelines for efficient data processing.· Created and managed data warehouses and databases for storage and retrieval.· Implemented ETL processes and optimized data workflows.· Developed and maintained data infrastructure and architecture.· Ensured data quality and integrity through validation and cleaning.· Managed and monitored database performance and security.· Collaborated with cross-functional teams to support data analytics and reporting.· Stayed updated with industry trends and best practices in data engineering.· Documented data processes, architecture, and workflows for knowledge sharing.\n",
      "\n",
      "=== ANONYMIZED RESUME ===\n",
      "﻿[REDACTED NAME] [REDACTED NAME]. [REDACTED NAME] Data Architect , USA [REDACTED PHONE]SUMMARY Accomplished data leader with a robust background spanning over 21 years, specializing in the establishment and institutionalization of data strategies, policies, and frameworks. Acknowledged for effectively managing data to mitigate operational risks and ensuring strict regulatory compliance through innovative solutions. Skilled in stakeholder management and fostering strong relationships, leading teams to high levels of achievement. Recognized for a sharp ability to identify and streamline inefficiencies, with demonstrated strengths in data governance, strategy formulation, and meeting business needs. Eager to apply this extensive background in a role that drives organizational growth and sets new benchmarks for success.KEY COMPETENCIES· Data Strategy· Enterprise Data Architecture· Policy and Standards· Data Governance· Road-mapping· Regulatory Compliance· Data Analytics· Strategic Planning, Execution· Data Warehousing· Data Management· Stakeholder Management· Data Mining· Data Privacy· Cross-Functional Leadership · Data Modeling · Data Quality· Innovation· Data Visualization· Data Retention· Data-Driven Decision-Making· Metadata Management· Data Migration· Data Lifecycle Analysis· Cloud Implementation TECHNICAL PROFICIENCIES· Microsoft SQL Server· AWS S 3 (Data Lake)· R· T-SQL· AWS Redshift· · SSRS· AWS Athena· SVN· SSIS· AWS Glue· Sharepoint· Microsoft Power BI· AWS Glue Data Catalog· Git Hub· · Data.World· Confluence· Oracle Warehouse Builder· Alation· · Oracle SQL Developer· · Scrum· PL/SQL· Atlan MS· SAFe Agile· · · OCM· Informatica MDM· MS Visio· MS Excel· Erwin Data Modeling· Lucid Charts· Microsoft Office PROFESSIONAL EXPERIENCEOSS Inc, U.S.Sr. Enterprise Architect / Data Strategy Leader Sept 2019 - Present As a Senior Enterprise Architect and Strategic Data Leader at OSS Inc, I have driven transformative outcomes for esteemed clients such as Kinder Care Learning Centers, Johnson & Johnson, Collins Aerospace, and Vertiv by:· Spearheading the development of target state data architecture and strategies.· Establishing and enforcing Data Quality standards across diverse datasets, ensuring enterprise-wide data integrity.· Formulating comprehensive data governance strategies, initiating programs, and defining roles like data stewardship and ownership.· Developing rigorous standards and policies for efficient master data management, selecting cutting-edge tools (e.g., data catalog, visualization, and master data management tools), and documenting governance strategies encompassing business rules and data lifecycle management.· Directing the technical aspects of data and information management for application portfolios, emphasizing secure data architecture delivery.· Aligning data architecture with key portfolio initiatives in collaboration with stakeholders, focusing on cost-effectiveness and practicality.· Leading big teams comprising of BI architects, project managers, business analysts, IT leads, developers, and test engineers.· Developing documentation and presentations, and facilitating discussions with business and technology stakeholders to secure buy-in.· Ensuring successful deployment of robust and scalable data solutions across various products and projects.· Assisting in evaluating tools and selecting vendors to meet expanding organizational data requirements. · Overseeing vendor partner resources and Database Analysts to ensure project alignment and delivery excellence.Publicis Sapient, USData Warehouse Architect / Business Intelligence Manager Dec 2010 – Sep 2019 I worked extensively with multiple clients, each presenting unique challenges and opportunities. Some of the key engagements include:· Client - Publicis Sapient(In house); Project - Deal Desk Costing Engine (\"The Engine\")· Led as chief architect and technical lead for \"The Engine\" team.· Collaborated with stakeholders to model the Engine Data Warehouse (Inmon) using Erwin data modeler.· Designed and implemented ETL processes for data integration using SSIS.· Managed an agile development team, ensuring timely deliveries to senior management.· Addressed Reporting and Data visualization needs in tandem with ongoing ETL development.· Self-taught R for dynamic business rule implementation and Revenue forecasting using Quadratic Regression.· Conducted workshops and demos for stakeholders and end users.· Client- Citibank; Project- Pricing Exception Management system (Pr EM) Client Billing· Architected Business Intelligence solutions to optimize vendor selection based on client invoices, billing contracts, and Price Exception data.· Conducted data analysis and designed the data warehouse structure for the Billing Intelligence module.· Developed ETL processes aligned with client-specific business rules using SSIS. · Managed daily tracking and reporting using JIRA.· Created and presented reports using SQL Server Reporting Services (SSRS) in client workshops.· Client- Macquarie Bank; Project- Prophet· Collaborated with business analysts and stakeholders to integrate heterogeneous data sources.· Designed the Data Warehouse using Power Designer.· Developed and implemented ETL processes to populate the Data Warehouse.· Partnered with the client's SSIS developer in agile environments to deliver the final product.· Provided guidance and conducted workshops for the Micro Strategy team to enhance reporting capabilities.· Client-Royal Bank of Scotland; Project- Ratings Trigger Risk (RTR)· Collaborated with a Senior Architect on complex design and solution brainstorming.· Designed logical and physical data models using Erwin for various modules.· Developed ETL processes using Oracle Warehouse Builder and created complex Oracle views with analytical functions.· Conducted workshops and demos for stakeholders and end users.· Contributed to ongoing maintenance and post-delivery enhancements of the product.Sopra Group, India Associate Architect June 2009 – Dec 2010 · Designed and implemented comprehensive High-level and Low-level data warehouse designs across multiple projects for Orange Business Services (OBS), enhancing project execution efficiency and ensuring alignment with client objectives.· Improved system performance by implementing rigorous code reviews and SQL optimizations, resulting in enhanced operational efficiency and client satisfaction.· Recognized for leadership in managing complex projects and delivering solutions that met stringent quality and timeline requirements.· Coordinated and supervised project activities, encompassing Workflow Management and CDR processing for billing.· Developed detailed project plans, monitored progress, and ensured adherence to budget and timeline constraints.· Acted as a key liaison between technical teams and client stakeholders, facilitating clear communication and resolution of project issues.· Played a pivotal role in enhancing project delivery processes and methodologies, contributing to overall team efficiency and client satisfaction.Global Logic, India Sr. Data engineer/Tech lead May 2006 - May 2009 · Led the data migration initiative for Telarix, transitioning from SQL Server to Oracle, ensuring seamless integration and optimal performance.· Conducted a comprehensive feasibility study for the migration project, assessing technical requirements and potential challenges.· Senior Developer in the migration project's development team, overseeing the transition of CDR processing from SQL Server to Oracle.· Contributed to the development and design team of Billing software, enabling real-time traffic intelligence, settlement charge tracking, and partner invoice reconciliation for telecom giants.TATA Consultancy Services Data Engineer June 2003 - May 2006 · Designed and developed scalable data pipelines for efficient data processing.· Created and managed data warehouses and databases for storage and retrieval.· Implemented ETL processes and optimized data workflows.· Developed and maintained data infrastructure and architecture.· Ensured data quality and integrity through validation and cleaning.· Managed and monitored database performance and security.· Collaborated with cross-functional teams to support data analytics and reporting.· Stayed updated with industry trends and best practices in data engineering.· Documented data processes, architecture, and workflows for knowledge sharing.\n",
      "================================================================================\n",
      "\n",
      "=== ORIGINAL RESUME (Row 19) ===\n",
      "﻿ IDAH ENYONG Contact Address  678-499-1049E-mail ienyong@hotmail.comLinkedIn://bold.pro/my/idah-enyong-230915144007/297 Skills Project ManagementExcellentBudget administrationExcellentSoftware Development LifecycleExcellentProject estimation and biddingExcellentBusiness IntelligenceExcellentBusiness process re-engineeringExcellentData AnalyticsExcellentProject Planning And DevelopmentExcellentMulti-Site OperationsExcellentStrategic planningExcellentFinancial ManagementExcellent Software Microsoft ProjectExcellentJIRAExcellentConfluenceExcellentMicrosoft ExcelExcellentAxureExcellentMicrosoft VisioExcellent Change Management Consultant with over 15 years of experience in organizing business operations, financial oversight and resource management.Proven experience supporting operational business areas and facilitating senior level teams in change management strategy, execution, and planning for both internal employees and external customersDemonstrated cross-organizational project management skills and success, including familiarity with project management approaches and applying change methodologies to support change in both agile and waterfall environments.Proven ability to develop strong, collaborative working relationships and establish a high level of credibility across functions, lines of business and organizational levels, skilled at resolving conflict and negotiating effectively and tactfully.Strong business acumen, with proven ability to leverage knowledge base to quickly come up to speed in new business areas and new types of projectsDemonstrated critical thinking and problem-solving skills and the ability to balance the need to gather detail with the need to solve the problem. Relevant Experience  2022-09 – CurrentMay 2024 Organizational Change Management ConsultantACA Risk Assessment Senior Consultant managing OCM (Organizational Change Management) for customer initiatives designed to increase operational efficiency, ensure regulatory compliance and transform organization.· Analyzed problematic areas to provide recommendations and solutions.· Specialized in implementing MachOne methodologies, emphasizing rapid adaptation, agility, and efficiency· Helped meet changing demands by recommending improvements to business systems or procedures.· Spearheaded MachOne change initiatives aimed at enhancing operational efficiency and ensuring regulatory compliance.· Developed and executed Agile change management strategies, fostering rapid adaptation and flexibility in response to evolving business needs.· Devised and implemented processes and procedures to streamline operations.· Assessed change readiness and created communication plans, stakeholder analyses and alignment initiatives· Taking a broad view of the business and varied degrees of appreciation for strategies, processes, technologies, and governance· Worked with SMEs to develop End User training using Enable Now· Applying change management methodologies during agile, waterfall, and hybrid development efforts· Built methodology and tools for supporting organizational change management across the full change lifecycle· Provided thought leadership around challenges and developed solutions across the MachOne program team\t· Used metrics and measures show real value and justify continued investment in learning and development for global implementations (WalkMe, Enable Now, etc.)· Empathizing with how people are affected by change and how they cycle through the change process while applying strategies and tactics to maximize change adoption within reasonable timelines· A natural inclination for problem solving with the ability to see the implications of actions on the end result· Design and develop training using SAP Enable Now· Experience in creating business processes with the aid of various tools and techniques· Excellent written and verbal communication skills with the ability to communicate well at all levels of the organization· The ability for teamwork at all levels of the organization· Strong decision-making abilities· Ability to influence others towards agreeable decision making 2021-06 - 2022-07 Change Management ConsultantOtis Elevator International Senior Consultant managing OCM (Organizational Change Management) for customer initiatives designed to increase operational efficiency, ensure regulatory compliance and transform organization.· Detected workforce collaboration use cases and problems from employees and business partners through interviews, focus groups and surveys.· Worked with SMEs to develop End User training using Enable Now· Implemented MachOne methodologies to accelerate change initiatives, focusing on rapid execution and agile project management practices.· Identified impacted parties, business partners and resources required for planned changes.· Managed internal and external client-facing relationships through transitional periods.· Provided advisory services for organizational change management· Built support for change throughout business unit through direct outreach strategies.· Created methods to integrate functions, optimize processes and prepare staff through proactive training.· Implemented change management tools and processes to streamline project execution and enhance team collaboration, resulting in improved project outcomes and client deliverables.· Partnered with business teams to understand needs and mitigate potential problems.· Directed changes to project scope and cost and implemented appropriate change management processes to keep project on track.· Developed and maintained relationships with key stakeholders to meet objectives and boost rapport.· Worked with SMEs to develop End User training using Enable Now· Liaised with customers, management, and sales team to better understand customer needs and recommend appropriate solutions. 2019-01 - 2021-06 SAP Integration ConsultantErnst & Young, LLP, , GeorgiaProject: Automated Web Interface Phase 1Desc: Automated Results Web Delivery ImplementationBudget: $1.5MMTime Frame: 18 Months· Evaluated and selecting an enterprise level solution addressing the need for analyzing and aggregating large volumes of data· Developed implementation methodologies to rein in project costs while meeting key milestones.· Managed MachOne projects focused on SAP integration, delivering rapid solutions to meet tight deadlines and aggressive timelines.· Rapidly prototyped new data processing capabilities to confirm integration feasibility into existing systems.· Use SAP Enable Now to develop training documentation.· Analyzed work to generate logic for new systems, procedures and tests.· Developed conversion and system implementation plans.· Estimated work hours and tracked progress using Scrum methodology. 2018-01 - 2019-01 Project Management ConsultantMAETRICS, LLC, Indiahoma, INProject: HP QC ImplementationDesc: Software validation and defect tracking solutionBudget: $100,000Time Frame: 6 Months· Established project goals and milestones and managed schedule throughout project.· Tracked project progress and updates and monitored deliverables, milestones and issues for accurate reporting. 2016-01 - 2018-01 Project Manager, BiometricsPRA HEALTH SCIENCES, , PAProject: Health IT Dev OpsDesc: Agile Implementation for Development TeamBudget: $250,000Time Frame: 9 Months· Achieved project deadlines by coordinating with contractors to manage performance.· Developed executive presentations and reports to facilitate project evaluation and process improvement. 2014-01 - 2016-01 IT Project ManagerUNITED HEALTH GROUP, , MNProject: Work Management SystemDesc: Design and Implementation of Predictive Analytical ToolBudget: $125,000Time Frame: 12 Months· Led Project Integration of UHG's OPTUM platform after acquisition of new business entity.· Ensured success of project by managing the customer experience following proof of concept, pairing strategic solutions unique to specific needs of key accounts. 2012-01 - 2014-01 Project ManagerHEALTH TECH ASSOCIATES, , MIProject: Data Management Process ImplementationBudget: $225,000Time Frame: 12 Months· Assigned to client initiatives focused on enhanced patient care, increased operational efficiency, ensured regulatory compliance and transformed organizations.· Achieved project deadlines by coordinating with contractors to manage performance. 2008-01 - 2012-01 Project Manager, Data ManagementIQVIA, , · Created a robust departmental framework ensuring consistency in performance as well as timely delivery on commitments.· Orchestrated completion of projects within strict time frames reducing project completion rates by 40% while working closely with senior leadership.· Conducted complex data management with SQL server and T-SQL· Developed and initiated projects, managed costs and monitored performance 2005-01 - 2008-01 Project ManagerQUALITY SYSTEMS INC, , · Controlled costs reducing spending by 37% optimizing spending via restructuring of budgets for labor, capital assets, inventory purchasing and technology upgrades.· Expanded cross-functional organizational capacity by collaborating across departments on priorities, functions and common goals. Education  2016-01 - 2020-12 Business Administration And ManagementGeorgia State University - ,   Lean Projects Project  - Automated Web Interface Phase 1Description-Automated Results Web Delivery ImplementationTimeline -18 monthsBudget -$1.5MM Project -Automated Web Interface Phase 2Description -Design and Implementation of User   InterfaceTimeline  -1 yearBudget - $500,000 Project -Quality Systems Implementation – Lean Description -Software validation and defect tracking   solutionTimeline - 6 monthsBudget - $100,000 Project - Agile Implementation – Health IT Dev OpsDescription - Agile Implementation for Development   TeamTimeline - 9 monthsBudget - $250,000 Project - Agile Implementation – Life Sciences - ITDescription - Agile Implementation for Development   TeamTimeline - 4 monthsBudget - $75,000Project - Work Management System – LeanDescription - Design and Implementation of Predictive   Analytical ToolTimeline -1 yearBudget - $125,000Project - Lean Process ImprovementDescription - Clinical Data Management Ops Process ImprovementTimeline -1 yearBudget - $500,000.\n",
      "\n",
      "=== ANONYMIZED RESUME ===\n",
      "﻿ [REDACTED NAME] [REDACTED NAME] Address [REDACTED PHONE]E-mail [REDACTED EMAIL]/my/idah-enyong-[REDACTED PHONE] 07 / 297 Skills Project Management Excellent Budget administration Excellent Software Development Lifecycle Excellent Project estimation and bidding Excellent Business Intelligence Excellent Business process re-engineering Excellent Data Analytics Excellent Project Planning And Development Excellent Multi-Site Operations Excellent Strategic planning Excellent Financial Management Excellent Software Microsoft Project Excellent JIRAExcellent Confluence Excellent Microsoft Excel Excellent Axure Excellent Microsoft Visio Excellent Change Management Consultant with over 15 years of experience in organizing business operations, financial oversight and resource management.Proven experience supporting operational business areas and facilitating senior level teams in change management strategy, execution, and planning for both internal employees and external customers Demonstrated cross-organizational project management skills and success, including familiarity with project management approaches and applying change methodologies to support change in both agile and waterfall environments.Proven ability to develop strong, collaborative working relationships and establish a high level of credibility across functions, lines of business and organizational levels, skilled at resolving conflict and negotiating effectively and tactfully.Strong business acumen, with proven ability to leverage knowledge base to quickly come up to speed in new business areas and new types of projects Demonstrated critical thinking and problem-solving skills and the ability to balance the need to gather detail with the need to solve the problem. Relevant Experience 2022 - 09 – Current May 2024 Organizational Change Management Consultant ACA Risk Assessment Senior Consultant managing OCM (Organizational Change Management) for customer initiatives designed to increase operational efficiency, ensure regulatory compliance and transform organization.· Analyzed problematic areas to provide recommendations and solutions.· Specialized in implementing Mach One methodologies, emphasizing rapid adaptation, agility, and efficiency· Helped meet changing demands by recommending improvements to business systems or procedures.· Spearheaded Mach One change initiatives aimed at enhancing operational efficiency and ensuring regulatory compliance.· Developed and executed Agile change management strategies, fostering rapid adaptation and flexibility in response to evolving business needs.· Devised and implemented processes and procedures to streamline operations.· Assessed change readiness and created communication plans, stakeholder analyses and alignment initiatives· Taking a broad view of the business and varied degrees of appreciation for strategies, processes, technologies, and governance· Worked with SMEs to develop End User training using Enable Now· Applying change management methodologies during agile, waterfall, and hybrid development efforts· Built methodology and tools for supporting organizational change management across the full change lifecycle· Provided thought leadership around challenges and developed solutions across the Mach One program team · Used metrics and measures show real value and justify continued investment in learning and development for global implementations (Walk Me, Enable Now, etc.)· Empathizing with how people are affected by change and how they cycle through the change process while applying strategies and tactics to maximize change adoption within reasonable timelines· A natural inclination for problem solving with the ability to see the implications of actions on the end result· Design and develop training using SAP Enable Now· Experience in creating business processes with the aid of various tools and techniques· Excellent written and verbal communication skills with the ability to communicate well at all levels of the organization· The ability for teamwork at all levels of the organization· Strong decision-making abilities· Ability to influence others towards agreeable decision making 2021 - 06 - 2022 - 07 Change Management Consultant Otis Elevator International Senior Consultant managing OCM (Organizational Change Management) for customer initiatives designed to increase operational efficiency, ensure regulatory compliance and transform organization.· Detected workforce collaboration use cases and problems from employees and business partners through interviews, focus groups and surveys.· Worked with SMEs to develop End User training using Enable Now· Implemented Mach One methodologies to accelerate change initiatives, focusing on rapid execution and agile project management practices.· Identified impacted parties, business partners and resources required for planned changes.· Managed internal and external client-facing relationships through transitional periods.· Provided advisory services for organizational change management· Built support for change throughout business unit through direct outreach strategies.· Created methods to integrate functions, optimize processes and prepare staff through proactive training.· Implemented change management tools and processes to streamline project execution and enhance team collaboration, resulting in improved project outcomes and client deliverables.· Partnered with business teams to understand needs and mitigate potential problems.· Directed changes to project scope and cost and implemented appropriate change management processes to keep project on track.· Developed and maintained relationships with key stakeholders to meet objectives and boost rapport.· Worked with SMEs to develop End User training using Enable Now· Liaised with customers, management, and sales team to better understand customer needs and recommend appropriate solutions. 2019 - 01 - 2021 - 06 SAP Integration Consultant Ernst & Young, LLP, , Georgia Project: Automated Web Interface Phase 1 Desc: Automated Results Web Delivery Implementation Budget: $ 1 . 5 MMTime Frame: 18 Months· Evaluated and selecting an enterprise level solution addressing the need for analyzing and aggregating large volumes of data· Developed implementation methodologies to rein in project costs while meeting key milestones.· Managed Mach One projects focused on SAP integration, delivering rapid solutions to meet tight deadlines and aggressive timelines.· Rapidly prototyped new data processing capabilities to confirm integration feasibility into existing systems.· Use SAP Enable Now to develop training documentation.· Analyzed work to generate logic for new systems, procedures and tests.· Developed conversion and system implementation plans.· Estimated work hours and tracked progress using Scrum methodology. 2018 - 01 - 2019 - 01 Project Management Consultant MAETRICS, LLC, Indiahoma, INProject: HP QC Implementation Desc: Software validation and defect tracking solution Budget: $ 100 , 000 Time Frame: 6 Months· Established project goals and milestones and managed schedule throughout project.· Tracked project progress and updates and monitored deliverables, milestones and issues for accurate reporting. 2016 - 01 - 2018 - 01 Project Manager, Biometrics PRA HEALTH SCIENCES, , PAProject: Health IT Dev Ops Desc: Agile Implementation for Development Team Budget: $ 250 , 000 Time Frame: 9 Months· Achieved project deadlines by coordinating with contractors to manage performance.· Developed executive presentations and reports to facilitate project evaluation and process improvement. 2014 - 01 - 2016 - 01 IT Project Manager UNITED HEALTH GROUP, , MNProject: Work Management System Desc: Design and Implementation of Predictive Analytical Tool Budget: $ 125 , 000 Time Frame: 12 Months· Led Project Integration of UHG's OPTUM platform after acquisition of new business entity.· Ensured success of project by managing the customer experience following proof of concept, pairing strategic solutions unique to specific needs of key accounts. 2012 - 01 - 2014 - 01 Project Manager HEALTH TECH ASSOCIATES, , MIProject: Data Management Process Implementation Budget: $ 225 , 000 Time Frame: 12 Months· Assigned to client initiatives focused on enhanced patient care, increased operational efficiency, ensured regulatory compliance and transformed organizations.· Achieved project deadlines by coordinating with contractors to manage performance. 2008 - 01 - 2012 - 01 Project Manager, Data Management IQVIA, , · Created a robust departmental framework ensuring consistency in performance as well as timely delivery on commitments.· Orchestrated completion of projects within strict time frames reducing project completion rates by 40 % while working closely with senior leadership.· Conducted complex data management with SQL server and T-SQL· Developed and initiated projects, managed costs and monitored performance 2005 - 01 - 2008 - 01 Project Manager QUALITY SYSTEMS INC, , · Controlled costs reducing spending by 37 % optimizing spending via restructuring of budgets for labor, capital assets, inventory purchasing and technology upgrades.· Expanded cross-functional organizational capacity by collaborating across departments on priorities, functions and common goals. Education 2016 - 01 - 2020 - 12 Business Administration And Management Georgia State University - , Lean Projects Project - Automated Web Interface Phase 1 Description-Automated Results Web Delivery Implementation Timeline - 18 months Budget -$ 1 . 5 MM Project -Automated Web Interface Phase 2 Description -Design and Implementation of User Interface Timeline - 1 year Budget - $ 500 , 000 Project -Quality Systems Implementation – Lean Description -Software validation and defect tracking solution Timeline - 6 months Budget - $ 100 , 000 Project - Agile Implementation – Health IT Dev Ops Description - Agile Implementation for Development Team Timeline - 9 months Budget - $ 250 , 000 Project - Agile Implementation – Life Sciences - ITDescription - Agile Implementation for Development Team Timeline - 4 months Budget - $ 75 , 000 Project - Work Management System – Lean Description - Design and Implementation of Predictive Analytical Tool Timeline - 1 year Budget - $ 125 , 000 Project - Lean Process Improvement Description - Clinical Data Management Ops Process Improvement Timeline - 1 year Budget - $ 500 , 000 .\n",
      "================================================================================\n",
      "\n",
      "=== ORIGINAL RESUME (Row 25) ===\n",
      "﻿Rishablok Singh Sardar+1 ‪‬‬reachrishablok@gmail.comSenior Data EngineerPROFESSIONAL SUMMARY:· With over 9+ years of experience as a Senior Data Engineer.· Spearheaded big data projects utilizing Apache Hadoop to manage vast datasets and improve data processing efficiency.· Designed and deployed Apache Spark solutions to accelerate big data analytics and streamline processing workflows.· Implemented Apache Hive to enhance data query and management capabilities across various data-intensive projects.· Developed complex data pipelines using Apache NiFi, ensuring robust data flow and integration across systems.· Managed PostgreSQL databases to support both transactional and analytical operations, optimizing data storage and retrieval.· Engineered ETL processes leveraging Talend, enhancing data transformation and integration for various business applications.· Utilized Docker to create and manage containers, ensuring consistent environments and streamlined deployment processes.· Administered Azure SQL Database setups, providing reliable and scalable database management solutions.· Integrated Azure Data Factory to automate and optimize data flows, improving efficiency and reducing manual overhead.· Configured Apache Kafka for real-time data processing and streaming, enhancing data availability and system responsiveness.· Employed Jenkins for continuous integration and deployment, facilitating faster and more reliable project delivery.· Orchestrated Kubernetes clusters to manage containerized applications, improving scalability and resource utilization.· Developed data analytics solutions using Python, leveraging libraries like Pandas and NumPy for data manipulation and analysis.· Created interactive data visualizations and reports using Power BI, delivering critical insights to decision-makers.· Managed Oracle databases, ensuring high availability and performance for enterprise-level applications.· Implemented TensorFlow for machine learning projects, enhancing predictive analytics and data-driven decision-making capabilities.· Utilized Azure Active Directory for secure cloud-based identity and access management, strengthening system security.· Designed data warehousing solutions using various technologies, including ADLS and Azure Cosmos DB, to support complex data queries.· Applied Terraform for infrastructure as code, automating and managing cloud infrastructure efficiently.· Integrated Azure DevOps to streamline project management and collaboration across development teams.· Automated data integration and management tasks using AWS Glue, simplifying complex ETL processes.· Engineered Apache Beam applications for advanced stream processing, facilitating real-time data analytics.· Enhanced security measures and application performance using Azure Key Vault for managing secrets and encryption keys.· Administered Azure HDInsight for big data services, optimizing data processing and analysis capabilities.· Implemented agile methodologies in all project phases, ensuring adaptability and timely delivery of technology solutions.TECHNICAL SKILLS:· Big Data Processing : Apache Hadoop, Apache Spark, Apache Hive, Apache Flink· Data Integration : Apache NiFi, Apache Airflow, Apache Beam, Talend, ADF· Database Management : PostgreSQL, Oracle Database, Azure SQL Database, Azure Cosmos DB· Analytics : Python, SQL, TensorFlow, Pandas, NumPy· DevOps : Docker, Jenkins, Azure DevOps, Kubernetes, Terraform· Visualization : Power BI· Security : Azure Active Directory, Azure Key Vault· Agile Methodologies : Agile, DocumentationPROFESSIONAL EXPERIENCE:Client:  , ,                                                                                               Aug 2023 to till dateRole: Senior Data EngineerRoles & Responsibilities:   · Optimized data retrieval and analysis processes by employing Apache Spark, significantly enhancing performance.· Managed and configured Azure SQL Database integrations, ensuring seamless operations within data-driven workflows.· Directed the design and implementation of ETL processes utilizing Azure Data Factory, optimizing data management.· Developed robust data warehousing solutions incorporating ADLS to support scalable analytics platforms.· Engineered Docker containers to create consistent environments, streamlining deployment processes across projects.· Administered Azure DevOps for streamlined continuous integration and deployment, adopting agile methodologies.· Implemented TensorFlow and Azure Key Vault in data projects to secure data and enhance machine learning capabilities.· Utilized Python and SQL for advanced data modeling and predictive analytics, improving business decision-making.· Automated routine data operations with sophisticated scripting, enhancing system efficiency and reliability.· Ensured high availability and robust disaster recovery strategies, maintaining continuous data accessibility.· Managed large-scale data with Hive and HBase, optimizing data storage and retrieval processes.· Spearheaded analytics initiatives that significantly increased data-driven decision-making capabilities within the organization.· Coordinated with cross-functional teams to ensure technical solutions aligned with strategic business objectives.· Authored comprehensive documentation to maintain project clarity and ensure continuity in data operations.· Integrated agile practices to enhance project flexibility and responsiveness to change.· Conducted regular system audits to ensure compliance with industry standards and security protocols.· Developed and maintained scalable and secure data architectures, supporting enterprise-wide data initiatives.· Provided training and technical support to team members, enhancing skills in data management and analytics.· Analyzed and refined data workflows, identifying and implementing improvements to increase efficiency.· Facilitated the transition of data processes to the cloud, leveraging Azure services for enhanced scalability and performance.· Designed and executed data migration strategies to move large volumes of data with minimal downtime.· Monitored system performance and implemented optimizations to handle increased data loads effectively.· Engaged with stakeholders to define business requirements and translate them into technical solutions.· Evaluated new technologies and tools to stay ahead of industry trends and incorporate cutting-edge solutions.· Led project meetings and presentations to communicate technical concepts and progress to non-technical stakeholders.Environment:  Apache Spark, Azure SQL Database, Azure Data Factory, ADLS, Docker, Azure DevOps, TensorFlow, Azure Key Vault, Python, SQL, Hive, HBase, Agile methodologies.Client: Accelerant Insurance Limited, ,                                                                     May 2021 to Jul 2023Role: Data EngineerRoles & Responsibilities:· Implemented Apache Beam for advanced stream processing, significantly improving real-time data analytics capabilities.· Configured and managed Talend jobs to facilitate efficient data transformation and integration within the insurance domain.· Oversaw the administration of Azure SQL Database, ensuring optimal performance and scalability for data storage needs.· Leveraged Azure Data Factory and Azure HDInsight to develop and optimize ETL pipelines for large-scale data processing.· Developed a comprehensive data warehouse architecture using Azure Cosmos DB, supporting complex analytical queries and data storage.· Orchestrated Docker container deployments to enhance development consistency and operational efficiency across projects.· Integrated Azure DevOps into project workflows to streamline continuous integration and deployment processes.· Applied Agile methodologies to maintain project flexibility and adaptability, ensuring timely deliveries and team alignment.· Employed TensorFlow to build and deploy machine learning models, enhancing predictive analytics and decision support systems.· Secured data transactions and sensitive information using Azure Key Vault, improving overall data security posture.· Drafted extensive documentation to support data engineering processes, ensuring clarity and continuity in operations.· Designed and implemented robust ETL processes, enhancing data integration and automation using Azure Data Factory.· Utilized Python and SQL for developing sophisticated data models, enabling detailed analysis and reporting.· Facilitated data-driven decision-making by creating interactive dashboards and reports with Power BI.· Conducted thorough data quality assessments to ensure accuracy and reliability of insurance data.· Collaborated closely with business analysts and stakeholders to translate business needs into scalable data solutions.· Monitored and optimized data system performance to handle an increasing volume of data efficiently.· Provided technical leadership and guidance to the data engineering team, fostering a culture of continuous improvement.· Engaged in proactive risk management practices to mitigate potential data security and compliance issues.· Managed cloud-based infrastructure using Azure services, ensuring cost-effective scalability and high availability.· Spearheaded the migration of legacy data systems to modern cloud platforms, reducing operational costs and improving agility.· Developed custom data processing scripts using Python, enhancing functionality and automation within data workflows.· Advocated for the adoption of new technologies and practices that significantly advanced the company’s data capabilities. Environment: Apache Beam, Talend, Azure SQL Database, Azure Data Factory, Azure HDInsight, Azure Cosmos DB, Docker, Azure DevOps, TensorFlow, Azure Key Vault, Python, SQL, Power BI, Agile methodologies.Client: HP Inc, ,                                                                                                            May 2020 to Apr 2021Role:  Big Data Engineer      Roles & Responsibilities:· Developed and maintained Hadoop clusters, enhancing data storage and processing capabilities across multiple IT projects.· Utilized Databricks for collaborative data science projects, significantly improving team productivity and data analysis efficiency.· Configured and managed Apache Flink for real-time data streaming and processing, enhancing operational responsiveness.· Administered AWS EMR clusters to optimize the performance and scalability of data processing operations.· Designed comprehensive data pipelines using Apache Airflow, streamlining workflow management and data integration.· Employed Kubernetes for orchestration of containerized applications, improving deployment speeds and system reliability.· Managed PostgreSQL databases, ensuring robust data storage solutions and efficient data access for transactional systems.· Automated infrastructure management and deployment using Terraform, reducing manual efforts and increasing deployment reliability.· Leveraged AWS Glue for serverless data integration, which enhanced data connectivity and reduced integration times.· Implemented comprehensive data security and compliance measures using Apache NiFi, ensuring data integrity and protection.· Developed SQL and Python scripts to perform complex data analysis and reporting, providing key insights into business metrics.· Orchestrated the transition of data systems to cloud-based environments, leveraging AWS services to improve scalability and performance.· Conducted regular system audits and performance optimizations to ensure efficient operation and cost-effectiveness.· Collaborated with cross-functional teams to ensure that data solutions met business needs and supported strategic objectives.· Provided technical leadership and expertise in big data technologies, guiding project directions and technology choices.· Designed and executed data migration strategies that minimized downtime and maintained data integrity across systems.· Trained and mentored team members in best practices for data management and usage of big data tools.· Evaluated and integrated new data technologies and tools, keeping the company at the forefront of data innovations.· Led the development of data governance frameworks to standardize data handling and ensure regulatory compliance.· Delivered detailed technical presentations to stakeholders to illustrate the benefits and progress of data initiatives.Environment: Hadoop, Databricks, Apache Flink, AWS EMR, Apache Airflow, Kubernetes, PostgreSQL, Terraform, AWS Glue, Apache NiFi, SQL, Python.Client: Aufait Technologies Pvt. Ltd, ,                                                                      Apr 2017 to Dec 2018Role: Data Visualization AnalystRoles& Responsibilities: · Developed interactive and dynamic dashboards using Power BI, enhancing business intelligence capabilities and user engagement.· Managed Oracle Database implementations, ensuring efficient data storage, retrieval, and security across multiple projects.· Utilized Python, specifically Pandas and NumPy, for data analysis and manipulation, providing deeper insights into business trends.· Configured and managed Apache Kafka for real-time data streaming, improving data availability and decision-making processes.· Employed Subversion (SVN) for version control, enhancing collaboration and code management within the data team.· Executed complex SQL queries to extract, analyze, and report data, supporting strategic business decisions.· Automated data processes using Python scripts, reducing manual effort and increasing process efficiency.· Conducted data quality checks and validation to ensure accuracy and reliability of reports and dashboards.· Collaborated with business stakeholders to identify key performance indicators and visualize them effectively.· Trained end-users on dashboard interaction, maximizing the value of BI tools within the organization.· Resolved data discrepancies and implemented improvements to data ingestion and processing workflows.· Monitored and optimized database performance to handle increased loads and complex queries.· Developed documentation for all data visualization projects, ensuring knowledge transfer and sustainability.· Participated in the migration of data systems to newer technologies, enhancing system capabilities and performance.· Advocated for the use of advanced analytics techniques to uncover hidden patterns and opportunities.· Led meetings and presentations to demonstrate new reports and dashboards to management and clients.· Ensured compliance with data governance and security policies throughout the data visualization processes.· Kept abreast of the latest trends in data visualization to continually improve the tools and techniques used. Environment: Power BI, Oracle Database, Python (Pandas, NumPy), Apache Kafka, Subversion (SVN), SQL.Client: Excellent WebWorld, ,                                                                             Nov 2015 to Mar 2017Role: Spark Engineer       Roles & Responsibilities:· Engineered data processing solutions using Apache Hadoop and Apache Hive, improving data storage and query capabilities.· Developed and fine-tuned Apache Spark applications to enhance big data processing efficiency and performance.· Integrated Apache Flume for data collection and aggregation, streamlining the data ingestion process.· Managed continuous integration and deployment using Jenkins, enhancing development operations and team productivity.· Containerized applications using Docker, improving scalability and consistency across development environments.· Wrote and optimized SQL scripts for data manipulation and querying, increasing data accessibility and usability.· Conducted performance tuning of big data applications to ensure optimal execution times and resource usage.· Collaborated with development teams to design scalable big data architectures, supporting growing data demands.· Provided technical support and troubleshooting for big data applications, ensuring high availability and minimal downtime.· Led training sessions for new team members on big data technologies and best practices, fostering skill development.· Participated in project planning and scope definition to align technical solutions with business objectives.· Documented all development processes and system configurations, ensuring clear understanding and future reference.· Implemented security measures to protect data integrity and prevent unauthorized access.· Evaluated new big data tools and technologies, recommending implementations that improve system performance.· Reported regularly to management on project status, challenges, and outcomes, ensuring transparency and accountability. Environment: Apache Hadoop, Apache Hive, Apache Spark, Apache Flume, Jenkins, Docker, SQL.Education:· Bachelor of Technology (B.Tech) in Information Technology from , , , . - 2015\n",
      "\n",
      "=== ANONYMIZED RESUME ===\n",
      "﻿[REDACTED NAME] [REDACTED NAME]+ 1 ‪‬‬[REDACTED EMAIL]or Data Engineer PROFESSIONAL SUMMARY:· With over 9 + years of experience as a Senior Data Engineer.· Spearheaded big data projects utilizing Apache Hadoop to manage vast datasets and improve data processing efficiency.· Designed and deployed Apache Spark solutions to accelerate big data analytics and streamline processing workflows.· Implemented Apache Hive to enhance data query and management capabilities across various data-intensive projects.· Developed complex data pipelines using Apache Ni Fi, ensuring robust data flow and integration across systems.· Managed Postgre SQL databases to support both transactional and analytical operations, optimizing data storage and retrieval.· Engineered ETL processes leveraging Talend, enhancing data transformation and integration for various business applications.· Utilized Docker to create and manage containers, ensuring consistent environments and streamlined deployment processes.· Administered Azure SQL Database setups, providing reliable and scalable database management solutions.· Integrated Azure Data Factory to automate and optimize data flows, improving efficiency and reducing manual overhead.· Configured Apache Kafka for real-time data processing and streaming, enhancing data availability and system responsiveness.· Employed Jenkins for continuous integration and deployment, facilitating faster and more reliable project delivery.· Orchestrated Kubernetes clusters to manage containerized applications, improving scalability and resource utilization.· Developed data analytics solutions using Python, leveraging libraries like Pandas and Num Py for data manipulation and analysis.· Created interactive data visualizations and reports using Power BI, delivering critical insights to decision-makers.· Managed Oracle databases, ensuring high availability and performance for enterprise-level applications.· Implemented Tensor Flow for machine learning projects, enhancing predictive analytics and data-driven decision-making capabilities.· Utilized Azure Active Directory for secure cloud-based identity and access management, strengthening system security.· Designed data warehousing solutions using various technologies, including ADLS and Azure Cosmos DB, to support complex data queries.· Applied Terraform for infrastructure as code, automating and managing cloud infrastructure efficiently.· Integrated Azure Dev Ops to streamline project management and collaboration across development teams.· Automated data integration and management tasks using AWS Glue, simplifying complex ETL processes.· Engineered Apache Beam applications for advanced stream processing, facilitating real-time data analytics.· Enhanced security measures and application performance using Azure Key Vault for managing secrets and encryption keys.· Administered Azure HDInsight for big data services, optimizing data processing and analysis capabilities.· Implemented agile methodologies in all project phases, ensuring adaptability and timely delivery of technology solutions.TECHNICAL SKILLS:· Big Data Processing : Apache Hadoop, Apache Spark, Apache Hive, Apache Flink· Data Integration : Apache Ni Fi, Apache Airflow, Apache Beam, Talend, ADF· Database Management : Postgre SQL, Oracle Database, Azure SQL Database, Azure Cosmos DB· Analytics : Python, SQL, Tensor Flow, Pandas, Num Py· Dev Ops : Docker, Jenkins, Azure Dev Ops, Kubernetes, Terraform· Visualization : Power BI· Security : Azure Active Directory, Azure Key Vault· Agile Methodologies : Agile, Documentation PROFESSIONAL EXPERIENCE:Client: , , Aug 2023 to till date Role: Senior Data Engineer Roles & Responsibilities: · Optimized data retrieval and analysis processes by employing Apache Spark, significantly enhancing performance.· Managed and configured Azure SQL Database integrations, ensuring seamless operations within data-driven workflows.· Directed the design and implementation of ETL processes utilizing Azure Data Factory, optimizing data management.· Developed robust data warehousing solutions incorporating ADLS to support scalable analytics platforms.· Engineered Docker containers to create consistent environments, streamlining deployment processes across projects.· Administered Azure Dev Ops for streamlined continuous integration and deployment, adopting agile methodologies.· Implemented Tensor Flow and Azure Key Vault in data projects to secure data and enhance machine learning capabilities.· Utilized Python and SQL for advanced data modeling and predictive analytics, improving business decision-making.· Automated routine data operations with sophisticated scripting, enhancing system efficiency and reliability.· Ensured high availability and robust disaster recovery strategies, maintaining continuous data accessibility.· Managed large-scale data with Hive and HBase, optimizing data storage and retrieval processes.· Spearheaded analytics initiatives that significantly increased data-driven decision-making capabilities within the organization.· Coordinated with cross-functional teams to ensure technical solutions aligned with strategic business objectives.· Authored comprehensive documentation to maintain project clarity and ensure continuity in data operations.· Integrated agile practices to enhance project flexibility and responsiveness to change.· Conducted regular system audits to ensure compliance with industry standards and security protocols.· Developed and maintained scalable and secure data architectures, supporting enterprise-wide data initiatives.· Provided training and technical support to team members, enhancing skills in data management and analytics.· Analyzed and refined data workflows, identifying and implementing improvements to increase efficiency.· Facilitated the transition of data processes to the cloud, leveraging Azure services for enhanced scalability and performance.· Designed and executed data migration strategies to move large volumes of data with minimal downtime.· Monitored system performance and implemented optimizations to handle increased data loads effectively.· Engaged with stakeholders to define business requirements and translate them into technical solutions.· Evaluated new technologies and tools to stay ahead of industry trends and incorporate cutting-edge solutions.· Led project meetings and presentations to communicate technical concepts and progress to non-technical stakeholders.Environment: Apache Spark, Azure SQL Database, Azure Data Factory, ADLS, Docker, Azure Dev Ops, Tensor Flow, Azure Key Vault, Python, SQL, Hive, HBase, Agile methodologies.Client: Accelerant Insurance Limited, , May 2021 to Jul 2023 Role: Data Engineer Roles & Responsibilities:· Implemented Apache Beam for advanced stream processing, significantly improving real-time data analytics capabilities.· Configured and managed Talend jobs to facilitate efficient data transformation and integration within the insurance domain.· Oversaw the administration of Azure SQL Database, ensuring optimal performance and scalability for data storage needs.· Leveraged Azure Data Factory and Azure HDInsight to develop and optimize ETL pipelines for large-scale data processing.· Developed a comprehensive data warehouse architecture using Azure Cosmos DB, supporting complex analytical queries and data storage.· Orchestrated Docker container deployments to enhance development consistency and operational efficiency across projects.· Integrated Azure Dev Ops into project workflows to streamline continuous integration and deployment processes.· Applied Agile methodologies to maintain project flexibility and adaptability, ensuring timely deliveries and team alignment.· Employed Tensor Flow to build and deploy machine learning models, enhancing predictive analytics and decision support systems.· Secured data transactions and sensitive information using Azure Key Vault, improving overall data security posture.· Drafted extensive documentation to support data engineering processes, ensuring clarity and continuity in operations.· Designed and implemented robust ETL processes, enhancing data integration and automation using Azure Data Factory.· Utilized Python and SQL for developing sophisticated data models, enabling detailed analysis and reporting.· Facilitated data-driven decision-making by creating interactive dashboards and reports with Power BI.· Conducted thorough data quality assessments to ensure accuracy and reliability of insurance data.· Collaborated closely with business analysts and stakeholders to translate business needs into scalable data solutions.· Monitored and optimized data system performance to handle an increasing volume of data efficiently.· Provided technical leadership and guidance to the data engineering team, fostering a culture of continuous improvement.· Engaged in proactive risk management practices to mitigate potential data security and compliance issues.· Managed cloud-based infrastructure using Azure services, ensuring cost-effective scalability and high availability.· Spearheaded the migration of legacy data systems to modern cloud platforms, reducing operational costs and improving agility.· Developed custom data processing scripts using Python, enhancing functionality and automation within data workflows.· Advocated for the adoption of new technologies and practices that significantly advanced the company’s data capabilities. Environment: Apache Beam, Talend, Azure SQL Database, Azure Data Factory, Azure HDInsight, Azure Cosmos DB, Docker, Azure Dev Ops, Tensor Flow, Azure Key Vault, Python, SQL, Power BI, Agile methodologies.Client: HP Inc, , May 2020 to Apr 2021 Role: Big Data Engineer Roles & Responsibilities:· Developed and maintained Hadoop clusters, enhancing data storage and processing capabilities across multiple IT projects.· Utilized Databricks for collaborative data science projects, significantly improving team productivity and data analysis efficiency.· Configured and managed Apache Flink for real-time data streaming and processing, enhancing operational responsiveness.· Administered AWS EMR clusters to optimize the performance and scalability of data processing operations.· Designed comprehensive data pipelines using Apache Airflow, streamlining workflow management and data integration.· Employed Kubernetes for orchestration of containerized applications, improving deployment speeds and system reliability.· Managed Postgre SQL databases, ensuring robust data storage solutions and efficient data access for transactional systems.· Automated infrastructure management and deployment using Terraform, reducing manual efforts and increasing deployment reliability.· Leveraged AWS Glue for serverless data integration, which enhanced data connectivity and reduced integration times.· Implemented comprehensive data security and compliance measures using Apache Ni Fi, ensuring data integrity and protection.· Developed SQL and Python scripts to perform complex data analysis and reporting, providing key insights into business metrics.· Orchestrated the transition of data systems to cloud-based environments, leveraging AWS services to improve scalability and performance.· Conducted regular system audits and performance optimizations to ensure efficient operation and cost-effectiveness.· Collaborated with cross-functional teams to ensure that data solutions met business needs and supported strategic objectives.· Provided technical leadership and expertise in big data technologies, guiding project directions and technology choices.· Designed and executed data migration strategies that minimized downtime and maintained data integrity across systems.· Trained and mentored team members in best practices for data management and usage of big data tools.· Evaluated and integrated new data technologies and tools, keeping the company at the forefront of data innovations.· Led the development of data governance frameworks to standardize data handling and ensure regulatory compliance.· Delivered detailed technical presentations to stakeholders to illustrate the benefits and progress of data initiatives.Environment: Hadoop, Databricks, Apache Flink, AWS EMR, Apache Airflow, Kubernetes, Postgre SQL, Terraform, AWS Glue, Apache Ni Fi, SQL, Python.Client: Aufait Technologies Pvt. Ltd, , Apr 2017 to Dec 2018 Role: Data Visualization Analyst Roles& Responsibilities: · Developed interactive and dynamic dashboards using Power BI, enhancing business intelligence capabilities and user engagement.· Managed Oracle Database implementations, ensuring efficient data storage, retrieval, and security across multiple projects.· Utilized Python, specifically Pandas and Num Py, for data analysis and manipulation, providing deeper insights into business trends.· Configured and managed Apache Kafka for real-time data streaming, improving data availability and decision-making processes.· Employed Subversion (SVN) for version control, enhancing collaboration and code management within the data team.· Executed complex SQL queries to extract, analyze, and report data, supporting strategic business decisions.· Automated data processes using Python scripts, reducing manual effort and increasing process efficiency.· Conducted data quality checks and validation to ensure accuracy and reliability of reports and dashboards.· Collaborated with business stakeholders to identify key performance indicators and visualize them effectively.· Trained end-users on dashboard interaction, maximizing the value of BI tools within the organization.· Resolved data discrepancies and implemented improvements to data ingestion and processing workflows.· Monitored and optimized database performance to handle increased loads and complex queries.· Developed documentation for all data visualization projects, ensuring knowledge transfer and sustainability.· Participated in the migration of data systems to newer technologies, enhancing system capabilities and performance.· Advocated for the use of advanced analytics techniques to uncover hidden patterns and opportunities.· Led meetings and presentations to demonstrate new reports and dashboards to management and clients.· Ensured compliance with data governance and security policies throughout the data visualization processes.· Kept abreast of the latest trends in data visualization to continually improve the tools and techniques used. Environment: Power BI, Oracle Database, Python (Pandas, Num Py), Apache Kafka, Subversion (SVN), SQL.Client: Excellent Web World, , Nov 2015 to Mar 2017 Role: Spark Engineer Roles & Responsibilities:· Engineered data processing solutions using Apache Hadoop and Apache Hive, improving data storage and query capabilities.· Developed and fine-tuned Apache Spark applications to enhance big data processing efficiency and performance.· Integrated Apache Flume for data collection and aggregation, streamlining the data ingestion process.· Managed continuous integration and deployment using Jenkins, enhancing development operations and team productivity.· Containerized applications using Docker, improving scalability and consistency across development environments.· Wrote and optimized SQL scripts for data manipulation and querying, increasing data accessibility and usability.· Conducted performance tuning of big data applications to ensure optimal execution times and resource usage.· Collaborated with development teams to design scalable big data architectures, supporting growing data demands.· Provided technical support and troubleshooting for big data applications, ensuring high availability and minimal downtime.· Led training sessions for new team members on big data technologies and best practices, fostering skill development.· Participated in project planning and scope definition to align technical solutions with business objectives.· Documented all development processes and system configurations, ensuring clear understanding and future reference.· Implemented security measures to protect data integrity and prevent unauthorized access.· Evaluated new big data tools and technologies, recommending implementations that improve system performance.· Reported regularly to management on project status, challenges, and outcomes, ensuring transparency and accountability. Environment: Apache Hadoop, Apache Hive, Apache Spark, Apache Flume, Jenkins, Docker, SQL.Education:· Bachelor of Technology (B.Tech) in Information Technology from , , , . - 2015\n",
      "================================================================================\n",
      "\n",
      "=== ORIGINAL RESUME (Row 42) ===\n",
      "Cybersecurity Specialist ,  |  |  Professional Summary Dedicated Cybersecurity and IT graduate with comprehensive experience in system security, compliance, and network management. Expertise in policy implementation, incident response, and systems analysis, with a strong understanding of the NIST 800-53 framework and risk management practices. Technical Skills - OS: Linux, Windows (Server & Workstation), Mac OSX - Cloud: AWS, Azure, VMware ESXi - Tools: Ansible, Nessus, NMAP, Wireshark - Security & Compliance: PCI DSS, GDPR, HIPAA, SOX; IAM, DevOps - Networking & Databases: LAN/WAN, DNS, DHCP, TCP/IP, VLANs, SSL/VPN; SQL, MongoDB - Programming: Python, PowerShell, BASH - Frameworks: NIST CSF, CMMC, SDLC, MITRE ATT&CK Project Experience - Compliance Analysis: Enhanced security for a local eyecare provider through PCI DSS and NIST frameworks. - Policy Development: Authored security policies for an ecommerce entity, aligning with NIST 800-53 standards. - Vulnerability Testing: Conducted vulnerability scans and penetration tests using Nessus and Metasploit. - IT Setup for Law Firm: Led IT infrastructure overhaul, from network design to staff training and system deployment. Relevant Coursework Identity & Access Management, Network Security & Software, Security Compliance & Privacy, Threat Intelligence & Defense, Software Security, Threat Protection, Cyber Crime & Incident Response Education B.S. in Cybersecurity, Full , , Expected Dec 2024 A.S. in Information Technology, Full , , 2023 A.S. in Criminal Justice, , , 2022 Military Experience Medical Specialist (68J), U.S. Army, 2017-2021\n",
      "\n",
      "=== ANONYMIZED RESUME ===\n",
      "Cybersecurity Specialist , | | Professional Summary Dedicated Cybersecurity and IT graduate with comprehensive experience in system security, compliance, and network management. Expertise in policy implementation, incident response, and systems analysis, with a strong understanding of the NIST 800 - 53 framework and risk management practices. Technical Skills - OS: Linux, Windows (Server & Workstation), Mac OSX - Cloud: AWS, Azure, VMware ESXi - Tools: Ansible, Nessus, NMAP, Wireshark - Security & Compliance: PCI DSS, GDPR, HIPAA, SOX; IAM, Dev Ops - Networking & Databases: LAN/WAN, DNS, DHCP, TCP/IP, VLANs, SSL/VPN; SQL, Mongo DB - Programming: Python, Power Shell, BASH - Frameworks: NIST CSF, CMMC, SDLC, MITRE ATT&CK Project Experience - Compliance Analysis: Enhanced security for a local eyecare provider through PCI DSS and NIST frameworks. - Policy Development: Authored security policies for an ecommerce entity, aligning with NIST 800 - 53 standards. - Vulnerability Testing: Conducted vulnerability scans and penetration tests using Nessus and Metasploit. - IT Setup for Law Firm: Led IT infrastructure overhaul, from network design to staff training and system deployment. Relevant Coursework Identity & Access Management, Network Security & Software, Security Compliance & Privacy, Threat Intelligence & Defense, Software Security, Threat Protection, Cyber Crime & Incident Response Education B.S. in Cybersecurity, Full , , Expected Dec 2024 A.S. in Information Technology, Full , , 2023 A.S. in Criminal Justice, , , 2022 Military Experience Medical Specialist ( 68 J), U.S. Army, 2017 - 2021\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display anonymized examples in a readable format\n",
    "for i, row in df_sample.iterrows():\n",
    "    print(f\"\\n=== ORIGINAL RESUME (Row {i}) ===\")\n",
    "    print(row[\"Original Resume\"])\n",
    "    print(\"\\n=== ANONYMIZED RESUME ===\")\n",
    "    print(row[\"Anonymized Resume\"])\n",
    "    print(\"=\" * 80)  # Separator line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirra_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
