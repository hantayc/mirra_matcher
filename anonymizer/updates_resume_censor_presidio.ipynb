{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Anonymization Script\n",
        "\n",
        "## Overview\n",
        "This script is designed to **anonymize Personally Identifiable Information (PII)** from resumes. It reads in a CSV file containing resumes, detects sensitive information, and replaces it with anonymized placeholders to protect candidates' privacy.\n",
        "\n",
        "## Features\n",
        "- **Reads resume data from a CSV file**.\n",
        "- **Identifies PII elements** such as names, emails, phone numbers, and addresses.\n",
        "- **Replaces PII with generic placeholders** to ensure confidentiality.\n",
        "- **Exports the anonymized data** into a new CSV file for further processing or sharing.\n",
        "\n",
        "## Why Anonymization?\n",
        "Protecting PII is crucial in resume processing, especially when handling large datasets for **machine learning models, recruitment analysis, or compliance with data privacy regulations (e.g., GDPR, CCPA)**.\n",
        "\n",
        "## Installation & Setup\n",
        "1. **Clone the Repository**:\n",
        "   ```bash\n",
        "   git clone https://github.com/hantayc/mirra_matcher.git\n",
        "   cd mirra_matcher\n",
        "\n",
        "2. ** Set up a Virtual Env (if needed) **\n",
        "   ```bash\n",
        "   python -m venv mirra_env\n",
        "   source mirra_env/bin/activate  # Windows: mirra_env\\Scripts\\Activate\n"
      ],
      "metadata": {
        "id": "3vb3lEDpt8_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "id": "QJetuNyRuLor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install presidio-analyzer presidio-anonymizer"
      ],
      "outputs": [],
      "metadata": {
        "id": "0MBNsaP3wKlA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import presidio_analyzer\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import OperatorConfig"
      ],
      "outputs": [],
      "metadata": {
        "id": "uhbB0qOdwM9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "!pip show presidio-anonymizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: presidio_anonymizer\n",
            "Version: 2.2.357\n",
            "Summary: Presidio Anonymizer package - replaces analyzed text with desired values.\n",
            "Home-page: https://github.com/Microsoft/presidio\n",
            "Author: Presidio\n",
            "Author-email: presidio@microsoft.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: azure-core, pycryptodome\n",
            "Required-by: \n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AW_Z6bTxKMf",
        "outputId": "0238fcd7-de12-4981-a11d-e6f93deb83b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import OperatorConfig\n",
        "\n",
        "# download word list\n",
        "nltk.download('words')\n",
        "english_words = set(words.words())\n",
        "\n",
        "# initialize Presidio components\n",
        "analyzer = AnalyzerEngine()\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "def normalize_spaced_text(text):\n",
        "    \"\"\"\n",
        "    Handles cases where letters are spaced out like \"L o w a s d\"\n",
        "    Returns both normalized and original versions for comparison\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\", \"\"\n",
        "\n",
        "    # remove spaces between single letters that likely form a word\n",
        "    normalized = re.sub(r'(?<=\\b\\w)\\s+(?=\\w\\b)', '', text)\n",
        "    # handle cases where there might be multiple words\n",
        "    normalized = re.sub(r'(?<=\\b\\w)\\s+(?=\\w)(?=.*?\\b)', '', normalized)\n",
        "\n",
        "    return normalized, text\n",
        "\n",
        "def clean_text_spacing(text):\n",
        "    \"\"\"Enhanced version that handles various edge cases\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    # first normalize any spaced out text\n",
        "    normalized, original = normalize_spaced_text(text)\n",
        "    text = normalized if normalized else original\n",
        "\n",
        "    # basic cleaning\n",
        "    text = text.strip()\n",
        "\n",
        "    # handle various phone number formats\n",
        "    phone_patterns = [\n",
        "        r'\\b\\d{3}\\s*-\\s*\\d{3,4}\\b',  # partial numbers like \"443 - 4532\"\n",
        "        r'\\b\\d{3}\\s*\\d{3,4}\\b',      # numbers without separator\n",
        "        r'\\b\\d{3}[\\s-]+\\d{3}[\\s-]+\\d{4}\\b',  # standard format with flexible spacing\n",
        "        r'\\(\\s*\\d{3}\\s*\\)\\s*\\d{3}\\s*-?\\s*\\d{4}\\b'  # (123) 456-7890 format\n",
        "    ]\n",
        "\n",
        "    for pattern in phone_patterns:\n",
        "        text = re.sub(pattern, '[REDACTED PHONE]', text)\n",
        "\n",
        "    # handle names with unusual spacing or punctuation\n",
        "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)  # Fix camelCase\n",
        "    text = re.sub(r'[\\,\\.\\;\\:\\|\\/\\\\](?=\\S)', r'\\g<0> ', text)  # Add space after punctuation\n",
        "    text = re.sub(r'(?<=\\S)[\\,\\.\\;\\:\\|\\/\\\\]', r' \\g<0>', text)  # Add space before punctuation\n",
        "\n",
        "    # handle numbers stuck to text\n",
        "    text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', text)\n",
        "    text = re.sub(r'(\\d)(\\D)', r'\\1 \\2', text)\n",
        "\n",
        "    # normalize multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # handle social media handles with various formats\n",
        "    text = re.sub(r'@[\\w\\.\\-_]+', '[REDACTED HANDLE]', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def anonymize_first_words(text, num_words=3):\n",
        "    \"\"\"Anonymizes the first `num_words` words if they are not real English words.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    words_list = text.split()\n",
        "\n",
        "    # first normalize any spaced out words\n",
        "    normalized_text = \"\"\n",
        "    current_position = 0\n",
        "\n",
        "    for i in range(min(num_words, len(words_list))):\n",
        "        word = words_list[i]\n",
        "        normalized_word, _ = normalize_spaced_text(word)\n",
        "\n",
        "        if normalized_word and normalized_word.lower() not in english_words:\n",
        "            words_list[i] = \"[REDACTED NAME]\"\n",
        "\n",
        "    return \" \".join(words_list)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Cleans text by removing BOM, fixing spaces, and ensuring name recognition.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    text = text.replace(\"\\ufeff\", \"\").strip()\n",
        "\n",
        "    # normalize spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def anonymize_resume(text):\n",
        "    \"\"\"Enhanced anonymization with better edge case handling\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    try:\n",
        "        # initial cleaning with enhanced spacing fixes\n",
        "        text = clean_text_spacing(text)\n",
        "\n",
        "        # check for and handle spaced out text that might be names\n",
        "        words = text.split()\n",
        "        potential_spaced_name = ' '.join(words[:3])  # Look at first three words\n",
        "        normalized_name, _ = normalize_spaced_text(potential_spaced_name)\n",
        "\n",
        "        if normalized_name and normalized_name.lower() not in english_words:\n",
        "            text = text.replace(potential_spaced_name, '[REDACTED NAME]', 1)\n",
        "\n",
        "        # enhanced regex patterns for PII detection\n",
        "        patterns = {\n",
        "            'phone': [\n",
        "                r'\\b\\d{3}[\\s-]*\\d{3,4}\\b',  # partial numbers\n",
        "                r'\\b\\d{3}[\\s-]*\\d{3}[\\s-]*\\d{4}\\b',  # full numbers\n",
        "                r'\\(\\s*\\d{3}\\s*\\)[\\s-]*\\d{3}[\\s-]*\\d{4}\\b'  # (123) 456-7890 format\n",
        "            ],\n",
        "            'address': [\n",
        "                r'\\b\\d{1,5}\\s+[A-Za-z\\s]+(?:street|st|avenue|ave|road|rd|boulevard|blvd|lane|ln|drive|dr)\\b',\n",
        "                r'\\b\\d{1,5}\\s[A-Za-z]+\\s[A-Za-z]+\\b'\n",
        "            ],\n",
        "            'email': [\n",
        "                r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b',\n",
        "                r'\\b[\\w\\.-]+\\s*@\\s*[\\w\\.-]+\\s*\\.\\s*\\w+\\b'  # handles spaced email addresses\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # apply all patterns\n",
        "        for category, pattern_list in patterns.items():\n",
        "            for pattern in pattern_list:\n",
        "                replacement = f'[REDACTED {category.upper()}]'\n",
        "                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "\n",
        "        # proceed with Presidio analysis\n",
        "        analyzer_results = analyzer.analyze(\n",
        "            text=text,\n",
        "            entities=[\"PERSON\", \"PHONE_NUMBER\", \"EMAIL_ADDRESS\", \"URL\", \"LOCATION\"],\n",
        "            language=\"en\"\n",
        "        )\n",
        "\n",
        "        # validate results\n",
        "        text_length = len(text)\n",
        "        valid_results = [\n",
        "            result for result in analyzer_results\n",
        "            if 0 <= result.start < text_length and 0 < result.end <= text_length\n",
        "            and result.start < result.end\n",
        "        ]\n",
        "\n",
        "        # apply anonymization\n",
        "        if valid_results:\n",
        "            operators = {\n",
        "                \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED]\"}),\n",
        "                \"PHONE_NUMBER\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED PHONE]\"}),\n",
        "                \"EMAIL_ADDRESS\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED EMAIL]\"}),\n",
        "                \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED NAME]\"}),\n",
        "                \"URL\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED LINK]\"}),\n",
        "                \"LOCATION\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED LOCATION]\"})\n",
        "            }\n",
        "\n",
        "            anonymized_result = anonymizer.anonymize(\n",
        "                text=text,\n",
        "                analyzer_results=valid_results,\n",
        "                operators=operators\n",
        "            )\n",
        "            return anonymized_result.text\n",
        "\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error anonymizing text (length {len(text)}): {str(e)}\")\n",
        "        return text\n",
        "\n",
        "def test_anonymization(text):\n",
        "    \"\"\"Helper function to test anonymization on specific cases\"\"\"\n",
        "    print(\"Original:\", text)\n",
        "    cleaned = clean_text_spacing(text)\n",
        "    print(\"Cleaned:\", cleaned)\n",
        "    anonymized = anonymize_resume(text)\n",
        "    print(\"Anonymized:\", anonymized)\n",
        "    print()\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # test edge cases first\n",
        "        print(\"Testing edge cases...\")\n",
        "        test_cases = [\n",
        "            \"L o w a s d R i l e m, 443 - 4532\",\n",
        "            \"j.o.h.n.d.o.e@e.m.a.i.l.com\",\n",
        "            \"J o h n D o e, Software Engineer\"\n",
        "        ]\n",
        "\n",
        "        for case in test_cases:\n",
        "            test_anonymization(case)\n",
        "\n",
        "        # load Resume Data\n",
        "        print(\"\\nLoading resume data...\")\n",
        "        df = pd.read_csv('1200 Resumes 2024.csv')\n",
        "\n",
        "        # 1. apply initial preprocessing\n",
        "        print(\"Applying initial preprocessing...\")\n",
        "        df[\"resume_clean\"] = df[\"resume_clean\"].apply(preprocess_text)\n",
        "\n",
        "        # 2. apply Cleaning Space Function\n",
        "        print(\"Cleaning text spacing...\")\n",
        "        df[\"cleaned_resume\"] = df[\"resume_clean\"].apply(clean_text_spacing)\n",
        "\n",
        "        # 3. apply Anonymization Function\n",
        "        print(\"Anonymizing resumes...\")\n",
        "        df[\"anonymized_resume\"] = df[\"cleaned_resume\"].apply(anonymize_resume)\n",
        "\n",
        "        # 4. save Anonymized Data\n",
        "        print(\"Saving anonymized data...\")\n",
        "        df.to_csv('1200 Resumes 2024 Anonymized.csv', index=False)\n",
        "\n",
        "        print(\"Processing completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during processing: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "metadata": {
        "id": "cQxX2yNmt8_f"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mirra_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}