{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vb3lEDpt8_f"
      },
      "source": [
        "# Resume Anonymization Script\n",
        "\n",
        "## Overview\n",
        "This script is designed to **anonymize Personally Identifiable Information (PII)** from resumes. It reads in a CSV file containing resumes, detects sensitive information, and replaces it with anonymized placeholders to protect candidates' privacy.\n",
        "\n",
        "## Features\n",
        "- **Reads resume data from a CSV file**.\n",
        "- **Identifies PII elements** such as names, emails, phone numbers, and addresses.\n",
        "- **Replaces PII with generic placeholders** to ensure confidentiality.\n",
        "- **Exports the anonymized data** into a new CSV file for further processing or sharing.\n",
        "\n",
        "## Why Anonymization?\n",
        "Protecting PII is crucial in resume processing, especially when handling large datasets for **machine learning models, recruitment analysis, or compliance with data privacy regulations (e.g., GDPR, CCPA)**.\n",
        "\n",
        "## Installation & Setup\n",
        "1. **Clone the Repository**:\n",
        "   ```bash\n",
        "   git clone https://github.com/hantayc/mirra_matcher.git\n",
        "   cd mirra_matcher\n",
        "\n",
        "2. ** Set up a Virtual Env (if needed) **\n",
        "   ```bash\n",
        "   python -m venv mirra_env\n",
        "   source mirra_env/bin/activate  # Windows: mirra_env\\Scripts\\Activate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QJetuNyRuLor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install presidio-anonymizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MBNsaP3wKlA",
        "outputId": "0833b4b9-92f0-4448-9f67-c2b7055f1036"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting presidio-anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.357-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting azure-core (from presidio-anonymizer)\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting pycryptodome>=3.10.1 (from presidio-anonymizer)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from azure-core->presidio-anonymizer) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core->presidio-anonymizer) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-core->presidio-anonymizer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core->presidio-anonymizer) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core->presidio-anonymizer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core->presidio-anonymizer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core->presidio-anonymizer) (2025.1.31)\n",
            "Downloading presidio_anonymizer-2.2.357-py3-none-any.whl (31 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome, azure-core, presidio-anonymizer\n",
            "Successfully installed azure-core-1.32.0 presidio-anonymizer-2.2.357 pycryptodome-3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import OperatorConfig\n",
        "\n",
        "print(\"Presidio Anonymizer is installed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhbB0qOdwM9K",
        "outputId": "c2d7f86b-9b96-4d5c-9005-a0e473ee1f2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presidio Anonymizer is installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show presidio-anonymizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AW_Z6bTxKMf",
        "outputId": "23046612-5c18-4a2e-d05d-06444a12e51d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: presidio_anonymizer\n",
            "Version: 2.2.357\n",
            "Summary: Presidio Anonymizer package - replaces analyzed text with desired values.\n",
            "Home-page: https://github.com/Microsoft/presidio\n",
            "Author: Presidio\n",
            "Author-email: presidio@microsoft.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: azure-core, pycryptodome\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQxX2yNmt8_f",
        "outputId": "4b68ce3c-4a67-4bc1-8ef3-32bb59f267a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing edge cases...\n",
            "Original: L o w a s d R i l e m, 443 - 4532\n",
            "Cleaned: Lowasd Rilem , [REDACTED PHONE]\n",
            "Anonymized: [REDACTED NAME] [REDACTED PHONE]\n",
            "\n",
            "Original: j.o.h.n.d.o.e@e.m.a.i.l.com\n",
            "Cleaned: j . o . h . n . d . o . e[REDACTED HANDLE] . m . a . i . l . com\n",
            "Anonymized: [REDACTED NAME] . h . n . d . o . e[REDACTED HANDLE] . m . a . i . l . com\n",
            "\n",
            "Original: 1 2 3 - 4 5 6 - 7 8 9 0\n",
            "Cleaned: [REDACTED PHONE] - 7890\n",
            "Anonymized: [REDACTED NAME] 7890\n",
            "\n",
            "Original: J o h n D o e, Software Engineer\n",
            "Cleaned: John Doe , Software Engineer\n",
            "Anonymized: [REDACTED NAME] Software Engineer\n",
            "\n",
            "Original: 1 2 3 Main Street, Apt 4B\n",
            "Cleaned: 123 Main Street , Apt 4 B\n",
            "Anonymized: [REDACTED NAME] , Apt 4 B\n",
            "\n",
            "\n",
            "Loading resume data...\n",
            "Applying initial preprocessing...\n",
            "Cleaning text spacing...\n",
            "Anonymizing resumes...\n",
            "Saving anonymized data...\n",
            "Processing completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import OperatorConfig\n",
        "\n",
        "# download word list\n",
        "nltk.download('words')\n",
        "english_words = set(words.words())\n",
        "\n",
        "# initialize Presidio components\n",
        "analyzer = AnalyzerEngine()\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "def normalize_spaced_text(text):\n",
        "    \"\"\"\n",
        "    Handles cases where letters are spaced out like \"L o w a s d\"\n",
        "    Returns both normalized and original versions for comparison\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\", \"\"\n",
        "\n",
        "    # remove spaces between single letters that likely form a word\n",
        "    normalized = re.sub(r'(?<=\\b\\w)\\s+(?=\\w\\b)', '', text)\n",
        "    # handle cases where there might be multiple words\n",
        "    normalized = re.sub(r'(?<=\\b\\w)\\s+(?=\\w)(?=.*?\\b)', '', normalized)\n",
        "\n",
        "    return normalized, text\n",
        "\n",
        "def clean_text_spacing(text):\n",
        "    \"\"\"Enhanced version that handles various edge cases\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    # first normalize any spaced out text\n",
        "    normalized, original = normalize_spaced_text(text)\n",
        "    text = normalized if normalized else original\n",
        "\n",
        "    # basic cleaning\n",
        "    text = text.strip()\n",
        "\n",
        "    # handle various phone number formats\n",
        "    phone_patterns = [\n",
        "        r'\\b\\d{3}\\s*-\\s*\\d{3,4}\\b',  # partial numbers like \"443 - 4532\"\n",
        "        r'\\b\\d{3}\\s*\\d{3,4}\\b',      # numbers without separator\n",
        "        r'\\b\\d{3}[\\s-]+\\d{3}[\\s-]+\\d{4}\\b',  # standard format with flexible spacing\n",
        "        r'\\(\\s*\\d{3}\\s*\\)\\s*\\d{3}\\s*-?\\s*\\d{4}\\b'  # (123) 456-7890 format\n",
        "    ]\n",
        "\n",
        "    for pattern in phone_patterns:\n",
        "        text = re.sub(pattern, '[REDACTED PHONE]', text)\n",
        "\n",
        "    # handle names with unusual spacing or punctuation\n",
        "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)  # Fix camelCase\n",
        "    text = re.sub(r'[\\,\\.\\;\\:\\|\\/\\\\](?=\\S)', r'\\g<0> ', text)  # Add space after punctuation\n",
        "    text = re.sub(r'(?<=\\S)[\\,\\.\\;\\:\\|\\/\\\\]', r' \\g<0>', text)  # Add space before punctuation\n",
        "\n",
        "    # handle numbers stuck to text\n",
        "    text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', text)\n",
        "    text = re.sub(r'(\\d)(\\D)', r'\\1 \\2', text)\n",
        "\n",
        "    # normalize multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # handle social media handles with various formats\n",
        "    text = re.sub(r'@[\\w\\.\\-_]+', '[REDACTED HANDLE]', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def anonymize_first_words(text, num_words=3):\n",
        "    \"\"\"Anonymizes the first `num_words` words if they are not real English words.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    words_list = text.split()\n",
        "\n",
        "    # first normalize any spaced out words\n",
        "    normalized_text = \"\"\n",
        "    current_position = 0\n",
        "\n",
        "    for i in range(min(num_words, len(words_list))):\n",
        "        word = words_list[i]\n",
        "        normalized_word, _ = normalize_spaced_text(word)\n",
        "\n",
        "        if normalized_word and normalized_word.lower() not in english_words:\n",
        "            words_list[i] = \"[REDACTED NAME]\"\n",
        "\n",
        "    return \" \".join(words_list)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Cleans text by removing BOM, fixing spaces, and ensuring name recognition.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    text = text.replace(\"\\ufeff\", \"\").strip()\n",
        "\n",
        "    # normalize spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def anonymize_resume(text):\n",
        "    \"\"\"Enhanced anonymization with better edge case handling\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    try:\n",
        "        # initial cleaning with enhanced spacing fixes\n",
        "        text = clean_text_spacing(text)\n",
        "\n",
        "        # check for and handle spaced out text that might be names\n",
        "        words = text.split()\n",
        "        potential_spaced_name = ' '.join(words[:3])  # Look at first three words\n",
        "        normalized_name, _ = normalize_spaced_text(potential_spaced_name)\n",
        "\n",
        "        if normalized_name and normalized_name.lower() not in english_words:\n",
        "            text = text.replace(potential_spaced_name, '[REDACTED NAME]', 1)\n",
        "\n",
        "        # enhanced regex patterns for PII detection\n",
        "        patterns = {\n",
        "            'phone': [\n",
        "                r'\\b\\d{3}[\\s-]*\\d{3,4}\\b',  # partial numbers\n",
        "                r'\\b\\d{3}[\\s-]*\\d{3}[\\s-]*\\d{4}\\b',  # full numbers\n",
        "                r'\\(\\s*\\d{3}\\s*\\)[\\s-]*\\d{3}[\\s-]*\\d{4}\\b'  # (123) 456-7890 format\n",
        "            ],\n",
        "            'address': [\n",
        "                r'\\b\\d{1,5}\\s+[A-Za-z\\s]+(?:street|st|avenue|ave|road|rd|boulevard|blvd|lane|ln|drive|dr)\\b',\n",
        "                r'\\b\\d{1,5}\\s[A-Za-z]+\\s[A-Za-z]+\\b'\n",
        "            ],\n",
        "            'email': [\n",
        "                r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b',\n",
        "                r'\\b[\\w\\.-]+\\s*@\\s*[\\w\\.-]+\\s*\\.\\s*\\w+\\b'  # handles spaced email addresses\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # apply all patterns\n",
        "        for category, pattern_list in patterns.items():\n",
        "            for pattern in pattern_list:\n",
        "                replacement = f'[REDACTED {category.upper()}]'\n",
        "                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "\n",
        "        # proceed with Presidio analysis\n",
        "        analyzer_results = analyzer.analyze(\n",
        "            text=text,\n",
        "            entities=[\"PERSON\", \"PHONE_NUMBER\", \"EMAIL_ADDRESS\", \"URL\", \"LOCATION\"],\n",
        "            language=\"en\"\n",
        "        )\n",
        "\n",
        "        # validate results\n",
        "        text_length = len(text)\n",
        "        valid_results = [\n",
        "            result for result in analyzer_results\n",
        "            if 0 <= result.start < text_length and 0 < result.end <= text_length\n",
        "            and result.start < result.end\n",
        "        ]\n",
        "\n",
        "        # apply anonymization\n",
        "        if valid_results:\n",
        "            operators = {\n",
        "                \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED]\"}),\n",
        "                \"PHONE_NUMBER\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED PHONE]\"}),\n",
        "                \"EMAIL_ADDRESS\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED EMAIL]\"}),\n",
        "                \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED NAME]\"}),\n",
        "                \"URL\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED LINK]\"}),\n",
        "                \"LOCATION\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED LOCATION]\"})\n",
        "            }\n",
        "\n",
        "            anonymized_result = anonymizer.anonymize(\n",
        "                text=text,\n",
        "                analyzer_results=valid_results,\n",
        "                operators=operators\n",
        "            )\n",
        "            return anonymized_result.text\n",
        "\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error anonymizing text (length {len(text)}): {str(e)}\")\n",
        "        return text\n",
        "\n",
        "def test_anonymization(text):\n",
        "    \"\"\"Helper function to test anonymization on specific cases\"\"\"\n",
        "    print(\"Original:\", text)\n",
        "    cleaned = clean_text_spacing(text)\n",
        "    print(\"Cleaned:\", cleaned)\n",
        "    anonymized = anonymize_resume(text)\n",
        "    print(\"Anonymized:\", anonymized)\n",
        "    print()\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # test edge cases first\n",
        "        print(\"Testing edge cases...\")\n",
        "        test_cases = [\n",
        "            \"L o w a s d R i l e m, 443 - 4532\",\n",
        "            \"j.o.h.n.d.o.e@e.m.a.i.l.com\",\n",
        "            \"1 2 3 - 4 5 6 - 7 8 9 0\",\n",
        "            \"J o h n D o e, Software Engineer\",\n",
        "            \"1 2 3 Main Street, Apt 4B\",\n",
        "        ]\n",
        "\n",
        "        for case in test_cases:\n",
        "            test_anonymization(case)\n",
        "\n",
        "        # load Resume Data\n",
        "        print(\"\\nLoading resume data...\")\n",
        "        df = pd.read_csv('1200 Resumes 2024.csv')\n",
        "\n",
        "        # 1. apply initial preprocessing\n",
        "        print(\"Applying initial preprocessing...\")\n",
        "        df[\"resume_clean\"] = df[\"resume_clean\"].apply(preprocess_text)\n",
        "\n",
        "        # 2. apply Cleaning Space Function\n",
        "        print(\"Cleaning text spacing...\")\n",
        "        df[\"cleaned_resume\"] = df[\"resume_clean\"].apply(clean_text_spacing)\n",
        "\n",
        "        # 3. apply Anonymization Function\n",
        "        print(\"Anonymizing resumes...\")\n",
        "        df[\"anonymized_resume\"] = df[\"cleaned_resume\"].apply(anonymize_resume)\n",
        "\n",
        "        # 4. save Anonymized Data\n",
        "        print(\"Saving anonymized data...\")\n",
        "        df.to_csv('1200 Resumes 2024 Anonymized.csv', index=False)\n",
        "\n",
        "        print(\"Processing completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during processing: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mirra_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}