{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#03_embedding_generation\n",
    "- Sets up the embedding generator using either Jina API or SageMaker\n",
    "- Loads job descriptions from files\n",
    "- Creates chunks from job descriptions using a custom chunker\n",
    "- Generates embeddings for each chunk\n",
    "- Uploads the embedded vectors to Pinecone\n",
    "- Includes batch processing for efficiency"
   ],
   "metadata": {
    "id": "dynvT9cEdx4s"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install jinaai"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from jinaai import JinaAI\n",
    "client = JinaAI()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import modules\n",
    "from src.chunking.job_chunker import chunk_job_description\n",
    "from src.embedding.jina_embedder import JinaEmbedder"
   ],
   "outputs": [],
   "metadata": {
    "id": "Eh1Rdi4NVCIP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 1: SageMaker endpoint configuration\n",
    "SAGEMAKER_ENDPOINT_NAME = \"jina-embeddings-v3-endpoint-325\"\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "# alt option 2: Direct Jina API configuration\n",
    "USE_JINA_API = False  # Set to True to use direct Jina API instead of SageMaker, need to add API key\n",
    "JINA_API_HOST = \"grpc://api.jina.ai:443\"  # Jina API endpoint\n",
    "\n",
    "# Set Pinecone credentials directly\n",
    "PINECONE_API_KEY = \"redacted\"\n",
    "PINECONE_ENVIRONMENT = \"us-east-1\" # matched with AWS region\n",
    "PINECONE_INDEX_NAME = \"mirra\"\n",
    "\n",
    "EMBEDDING_DIMENSION = 1024\n",
    "\n",
    "print(f\"Embedding method: {'Direct Jina API' if USE_JINA_API else 'SageMaker Endpoint'}\")\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIMENSION}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding method: SageMaker Endpoint\n",
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "metadata": {
    "id": "7rXs4HpmWK-w"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set variables - skipping because endpoint is already created\n",
    "\"\"\"\n",
    "region = \"us-east-1\" \n",
    "model_name = \"jina-embeddings-v3-model\"\n",
    "endpoint_name = \"jina-embeddings-v3-endpoint-325\"\n",
    "instance_type = \"ml.g5.xlarge\" # limited to compatible options\n",
    "model_package_arn = \"redacted\"\n",
    "\n",
    "# Initialize boto3 clients\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "sm_runtime = boto3.client('sagemaker-runtime', region_name=region)\n",
    "\n",
    "# Create model\n",
    "try:\n",
    "    model_response = sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        PrimaryContainer={\n",
    "            'ModelPackageName': model_package_arn\n",
    "        },\n",
    "        ExecutionRoleArn=\"redacted\"\n",
    "    )\n",
    "    print(f\"Model created: {model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating model: {str(e)}\")\n",
    "    # If model already exists, continue\n",
    "    print(\"Continuing with existing model if available.\")\n",
    "\n",
    "# Create endpoint configuration\n",
    "try:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_name,\n",
    "        ProductionVariants=[{\n",
    "            'VariantName': 'default',\n",
    "            'ModelName': model_name,\n",
    "            'InstanceType': instance_type,\n",
    "            'InitialInstanceCount': 1\n",
    "        }]\n",
    "    )\n",
    "    print(f\"Endpoint configuration created: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating endpoint configuration: {str(e)}\")\n",
    "    # If config already exists, continue\n",
    "    print(\"Continuing with existing endpoint configuration if available.\")\n",
    "\n",
    "# Check if endpoint exists\n",
    "try:\n",
    "    endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"Endpoint already exists: {endpoint_name}\")\n",
    "    print(f\"Current status: {endpoint_response['EndpointStatus']}\")\n",
    "except sm_client.exceptions.ClientError:\n",
    "    # Create endpoint if it doesn't exist\n",
    "    try:\n",
    "        create_endpoint_response = sm_client.create_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_name\n",
    "        )\n",
    "        print(f\"Creating endpoint: {endpoint_name}\")\n",
    "        print(\"Endpoint creation initiated. This will take several minutes...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating endpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# wait for endpoint to be in service\n",
    "wait_for_endpoint = True\n",
    "if wait_for_endpoint:\n",
    "    print(\"Waiting for endpoint to be ready... (this may take 5-10 minutes)\")\n",
    "    waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "    waiter.wait(EndpointName=endpoint_name)\n",
    "    print(f\"Endpoint {endpoint_name} is now ready for use!\")\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "SAGEMAKER_ENDPOINT_NAME = \"jina-embeddings-v3-endpoint-325\" \n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"Unified class for embedding generation using either SageMaker or Jina API\"\"\"\n",
    "    \n",
    "    def __init__(self, use_jina_api=True, jina_api_key=None):\n",
    "        \"\"\"\n",
    "        Initialize with embedding method.\n",
    "        \n",
    "        Args:\n",
    "            use_jina_api (bool): If True, use direct Jina API; otherwise use SageMaker.\n",
    "            jina_api_key: API key for Jina. Must be provided if using the Jina API.\n",
    "        \"\"\"\n",
    "        self.use_jina_api = use_jina_api\n",
    "        \n",
    "        if use_jina_api:\n",
    "            try:\n",
    "                if not jina_api_key:\n",
    "                    print(\"Warning: Jina API key not provided. Some functionality may be limited.\")\n",
    "                \n",
    "                # Initialize the Jina API client and configure it with the API key if provided\n",
    "                self.jina_client = JinaAI()\n",
    "                if jina_api_key:\n",
    "                    self.jina_client.configure(api_key=jina_api_key)\n",
    "                print(\"Initialized Jina API client\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing Jina API client: {str(e)}\")\n",
    "                raise\n",
    "        else:\n",
    "            # Initialize the SageMaker embedder\n",
    "            self.embedder = SageMakerEmbedder(\n",
    "                endpoint_name=SAGEMAKER_ENDPOINT_NAME, \n",
    "                region=AWS_REGION\n",
    "            )\n",
    "            print(f\"Initialized SageMaker embedder for endpoint: {SAGEMAKER_ENDPOINT_NAME}\")\n",
    "            \n",
    "    def generate_embeddings(self, texts, instructions=None):\n",
    "        \"\"\"Generate embeddings using the configured method\"\"\"\n",
    "        # Ensure texts is a list\n",
    "        if not isinstance(texts, list):\n",
    "            texts = [texts]\n",
    "        # Process using the appropriate method\n",
    "        if self.use_jina_api:\n",
    "            return self._generate_with_jina_api(texts)\n",
    "        else:\n",
    "            return self._generate_with_sagemaker(texts)\n",
    "            \n",
    "    def _generate_with_jina_api(self, texts):\n",
    "        \"\"\"Generate embeddings using Jina API\"\"\"\n",
    "        try:\n",
    "            # Call the embeddings API using the JinaAI client\n",
    "            embeddings_response = self.jina_client.embeddings(\n",
    "                texts=texts,\n",
    "                model=\"jina-embeddings-v3-base-en\"\n",
    "            )\n",
    "            \n",
    "            if isinstance(embeddings_response, dict) and 'embeddings' in embeddings_response:\n",
    "                # If response is {embeddings: [[values], [values]]}\n",
    "                embeddings = embeddings_response['embeddings']\n",
    "            elif isinstance(embeddings_response, list):\n",
    "                # If response is a list of objects with 'embedding' field\n",
    "                embeddings = [item['embedding'] for item in embeddings_response]\n",
    "            else:\n",
    "                # Fallback case\n",
    "                print(f\"Unexpected response format: {type(embeddings_response)}\")\n",
    "                print(f\"Response sample: {str(embeddings_response)[:100]}...\")\n",
    "                raise ValueError(\"Could not parse embedding response\")\n",
    "                \n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embeddings with Jina API: {str(e)}\")\n",
    "            raise \n",
    "            \n",
    "    def _generate_with_sagemaker(self, texts, instructions=None):\n",
    "        \"\"\"Generate embeddings using SageMaker endpoint\"\"\"\n",
    "        try:\n",
    "            # Format the payload directly here rather than in SageMakerEmbedder\n",
    "            payload = {\n",
    "                \"data\": [{\"text\": text} for text in texts],\n",
    "                \"parameters\": {\n",
    "                    \"task\": \"text-matching\",\n",
    "                    \"late_chunking\": False,\n",
    "                    \"dimensions\": 1024\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Pass the properly formatted payload to the embedder\n",
    "            embeddings = self.embedder.generate_embeddings(payload)\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"Error with SageMaker embedding: {str(e)}\")\n",
    "            # Return zero vectors as fallback\n",
    "            return [[0.0] * EMBEDDING_DIMENSION] * len(texts)"
   ],
   "outputs": [],
   "metadata": {
    "id": "zyFuKnf-WNul"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Initialize Pinecone with credentials\n",
    "from pinecone import Pinecone\n",
    "\n",
    "def initialize_pinecone():\n",
    "    \"\"\"Initialize Pinecone and return the index\"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone \n",
    "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        \n",
    "        # Check if the index exists\n",
    "        existing_indexes = pc.list_indexes().names()\n",
    "        print(f\"Available Pinecone indexes: {existing_indexes}\")\n",
    "        \n",
    "        if PINECONE_INDEX_NAME not in existing_indexes:\n",
    "            print(f\"Creating new index '{PINECONE_INDEX_NAME}'...\")\n",
    "            # Create the index\n",
    "            pc.create_index(\n",
    "                name=PINECONE_INDEX_NAME,\n",
    "                dimension=EMBEDDING_DIMENSION,\n",
    "                metric=\"cosine\",\n",
    "                metadata_config={\n",
    "                    \"indexed\": [\n",
    "                        \"source_type\",\n",
    "                        \"chunk_type\",\n",
    "                        \"requirement_level\",\n",
    "                        \"job_id\",\n",
    "                        \"resume_id\"\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            print(f\"Index '{PINECONE_INDEX_NAME}' created successfully\")\n",
    "        \n",
    "        # Connect to the index\n",
    "        index = pc.Index(PINECONE_INDEX_NAME)\n",
    "        print(f\"Connected to Pinecone index: {PINECONE_INDEX_NAME}\")\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Pinecone: {str(e)}\")\n",
    "        print(\"Please check your API key and environment settings.\")\n",
    "        # Return None to indicate initialization failed\n",
    "        return None\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone_index = initialize_pinecone()\n",
    "if pinecone_index:\n",
    "    # Check index stats\n",
    "    index_stats = pinecone_index.describe_index_stats()\n",
    "    # Convert to dictionary for JSON serialization\n",
    "    index_stats_dict = index_stats.to_dict()\n",
    "    print(f\"Index statistics: {json.dumps(index_stats_dict, indent=2)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Available Pinecone indexes: ['mirra']\n",
      "Connected to Pinecone index: mirra\n",
      "Index statistics: {\n",
      "  \"namespaces\": {},\n",
      "  \"index_fullness\": 0.0,\n",
      "  \"total_vector_count\": 0,\n",
      "  \"dimension\": 1024,\n",
      "  \"metric\": \"cosine\",\n",
      "  \"vector_type\": \"dense\"\n",
      "}\n"
     ]
    }
   ],
   "metadata": {
    "id": "ZIFlvOu_WURm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Check how JinaEmbedder is defined\n",
    "print(JinaEmbedder.__init__.__code__.co_varnames)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('self', 'api_key', 'Embeddings')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "print(\"Payload:\", json.dumps(payload, indent=2))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# update\n",
    "class SageMakerEmbedder:\n",
    "    def __init__(self, endpoint_name, region=\"us-east-1\"):\n",
    "        self.endpoint_name = endpoint_name\n",
    "        self.region = region\n",
    "        self.client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "        \n",
    "    def generate_embeddings(self, texts_or_payload):\n",
    "        \"\"\"\n",
    "        Generate embeddings using SageMaker endpoint.\n",
    "        \n",
    "        Args:\n",
    "            texts_or_payload: Either a string, list of strings, or pre-formatted payload\n",
    "            \n",
    "        Returns:\n",
    "            List of embedding vectors\n",
    "        \"\"\"\n",
    "        # Check if texts_or_payload is already formatted as a payload\n",
    "        if isinstance(texts_or_payload, dict) and \"data\" in texts_or_payload:\n",
    "            payload = texts_or_payload\n",
    "        else:\n",
    "            # Convert input to proper format\n",
    "            if isinstance(texts_or_payload, str):\n",
    "                texts = [texts_or_payload]\n",
    "            else:\n",
    "                texts = texts_or_payload\n",
    "                \n",
    "            # Format as Jina Embeddings v3 payload\n",
    "            payload = {\n",
    "                \"data\": [{\"text\": text} for text in texts],\n",
    "                \"parameters\": {\n",
    "                    \"task\": \"text-matching\",\n",
    "                    \"late_chunking\": False,\n",
    "                    \"dimensions\": 1024\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Call the SageMaker endpoint\n",
    "        response = self.client.invoke_endpoint(\n",
    "            EndpointName=self.endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Handle the specific response format we've observed\n",
    "        if isinstance(result, list) and all(\"embedding\" in item for item in result):\n",
    "            # Response contains a list of objects with 'embedding' key\n",
    "            embeddings = [item[\"embedding\"] for item in result]\n",
    "            return embeddings\n",
    "        \n",
    "        # Fallback to previous handling methods if format changes\n",
    "        if \"embeddings\" in result:\n",
    "            return result[\"embeddings\"]\n",
    "        elif \"data\" in result:\n",
    "            return result[\"data\"]\n",
    "        else:\n",
    "            # Try to find embeddings in the result structure\n",
    "            for key in result:\n",
    "                if isinstance(result[key], list) and len(result[key]) > 0:\n",
    "                    return result[key]\n",
    "        \n",
    "        raise ValueError(\"Could not find embeddings in response\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Use the SageMaker embedder\n",
    "embedder = SageMakerEmbedder(endpoint_name=SAGEMAKER_ENDPOINT_NAME, region=AWS_REGION)\n",
    "\n",
    "try:\n",
    "    test_text = \"Required skill: Python programming with 3 years experience\"\n",
    "    # Correct payload matching the required JSON format:\n",
    "    payload = {\n",
    "        \"data\": [{\"text\": test_text}],\n",
    "        \"parameters\": {\n",
    "            \"task\": \"text-matching\",\n",
    "            \"late_chunking\": False,\n",
    "            \"dimensions\": 1024\n",
    "        }\n",
    "    }\n",
    "    print(\"Payload:\", json.dumps(payload, indent=2))  # Debug output\n",
    "\n",
    "    result = embedder.generate_embeddings(payload)\n",
    "    \n",
    "    print(\"Full embedding result:\", result)\n",
    "    \n",
    "    # Extract the embedding vector from the first document in the returned list\n",
    "    embedding_vector = result[0].get(\"embedding\")\n",
    "    if not embedding_vector:\n",
    "        raise ValueError(\"No embedding vector found in the result.\")\n",
    "    \n",
    "    # calculate its dimension; print a preview\n",
    "    embedding_dim = len(embedding_vector)\n",
    "    print(\"Embedding generation successful!\")\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "    print(f\"Embedding preview (first 5 values): {embedding_vector[:5]}\")\n",
    "    \n",
    "    if 'EMBEDDING_DIMENSION' in globals() and embedding_dim != EMBEDDING_DIMENSION:\n",
    "        print(f\"Warning: Expected dimension {EMBEDDING_DIMENSION}, but got {embedding_dim}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error testing embedding generation: {str(e)}\")\n",
    "    print(\"Please check your configuration and try again\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Payload: {\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"text\": \"Required skill: Python programming with 3 years experience\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameters\": {\n",
      "    \"task\": \"text-matching\",\n",
      "    \"late_chunking\": false,\n",
      "    \"dimensions\": 1024\n",
      "  }\n",
      "}\n",
      "Full embedding result: [{'id': '285a6bd41a2db6ba675bebc53577806b', 'embedding': [0.042495023, -0.100973584, 0.13122457, 0.09683984, 0.010602621, 0.029769432, -0.11279018, -0.03456933, 0.005282447, -0.07970909, 0.01447604, 0.049952693, 0.035989024, 0.020272836, 0.070766844, 0.0012989584, -0.01198133, 0.08423315, -0.05487654, 0.031116141, -0.07024854, -0.008453575, 0.09742766, 0.11486971, 0.002564517, -0.044930875, 0.0024241956, 0.048844982, -0.05904031, -0.016179081, -0.015846059, 0.0410697, -0.06578453, -0.08232428, 0.06688908, 0.021171479, 0.05903241, -0.007505971, -0.025006961, -0.078260064, 0.0702359, 0.01094404, 0.01820606, 0.042301454, -0.0039463546, 0.01971612, 0.023533441, 0.006535729, 0.074573494, -0.0012242949, 0.014283259, -0.05642985, 0.007336387, -0.033324443, 0.056659576, -0.014966786, 0.070384435, 0.0052306964, -0.078392796, -0.060712148, -0.034851294, 0.040063124, 0.018525502, 0.047081504, 0.027381431, 0.046021324, -0.004920783, -0.03273464, 0.025062367, -0.0265587, 0.015320055, -0.035983495, -0.0013892263, 0.0241029, -0.027820671, -0.02815567, 0.055894174, 0.011467573, -0.06769299, -0.00939319, 0.016119257, 0.04227617, 0.027897706, 0.052159414, 0.047639303, 0.0083459, -0.0020873456, 0.040867046, -0.06913135, 0.03607665, 0.041794214, 0.008470561, 0.060432456, 0.011392811, -0.035879005, -0.087374546, -0.0750997, -0.0002143121, 0.03256675, -0.040297784, -0.0013873498, 0.065593325, -0.064670496, -0.044848505, -0.018402692, 0.007809651, -0.0752988, -0.016742762, -0.039874297, -0.048637982, 0.009684685, 0.041413393, 0.027772874, -0.00584035, 0.006856111, 0.0027697058, 0.024162157, 0.012294205, 0.07818263, 0.012221418, -0.028164016, 0.050703276, -0.03983163, 0.059532538, -0.06731098, -0.04820817, -0.09890987, -0.010855846, 0.011616456, -0.021758504, 0.0042696116, 0.008301779, -0.0077858986, 0.062617846, -0.011616308, -0.035374332, 0.0055988785, -0.012492124, -0.043574587, -0.005170551, 0.023792395, -0.014969058, -0.054603167, 0.017728351, 0.04869961, -0.046347506, -0.03597026, 0.0064286464, -0.003423364, 0.016038395, 0.056625795, 0.0019438206, -0.014067959, -0.01507019, -0.06840447, -0.054169405, -0.050685108, -0.014034775, 0.006522445, -0.043261416, -0.020599268, 0.044094957, -0.03210257, 0.015777469, 0.005292422, -0.03552445, 0.02072793, -0.036046304, -0.014218866, -0.052607395, -0.0039839954, -0.020520432, 0.017278563, 0.0142911095, -0.006391636, 0.024680557, -0.024917984, 0.086470686, 0.07649658, -0.027595496, -0.035217106, 0.051308487, -1.2740212e-05, 0.033152994, 0.0153807625, 0.05282625, -0.0056401365, 0.019401861, -0.022719083, 0.028744388, -0.03181932, -0.051180493, 0.0014678033, 0.033314172, -0.03146516, 0.05969135, 0.018168826, -0.026737507, -0.0078031328, 0.012310451, -0.0038755923, 0.007905647, -0.05716464, -0.085193895, 0.007744271, 0.07513604, 0.01666084, -0.037914474, -0.08246018, -0.0011470141, -0.0135109285, -0.0049781143, -0.061423227, -0.02384474, -0.07027698, 0.013157182, -0.0075049787, 0.02561632, -0.02970741, -0.028797222, 0.017425844, 0.017384266, -0.029756729, 0.0012946129, -0.056349266, -0.106643274, -0.025035998, 0.026160939, 0.023199826, -0.043955904, 0.036178254, -0.07061198, 0.0142560005, -0.028493186, 0.02227621, -0.0050497656, -0.028088119, 0.037635177, -0.02924323, 0.08252971, 0.024934074, 0.00011772351, -0.008886149, -0.027731393, 0.013002424, 0.010549574, -0.040945165, 0.00856004, -0.0382396, 0.085193895, 0.006056489, 0.034059227, -0.032403495, 0.02827379, 0.0077219508, -0.0105976835, 0.06640238, -0.00844841, 0.014027072, -0.032258216, 0.044252187, 0.04009552, 0.00088322256, 0.0057289656, 0.033802446, 0.026243653, 0.005516536, -0.015461012, -0.0005411133, 0.0054907594, -0.031031204, -0.0022565976, -0.03218039, 0.013954581, 0.0065014586, 0.014585764, 0.0018716259, -0.011910913, -0.0033046282, -0.0327378, -0.055198893, -0.05120103, -0.043255884, -0.03564968, -0.030050702, -0.03218237, -0.016032606, -0.023237456, 0.007052448, 0.017080575, 0.032054372, 0.030982813, 0.0077667404, -0.0475919, -0.01035199, 0.0023338783, -0.0006193138, 0.015873712, -0.0007192541, -0.03863859, 0.061050303, 0.05786466, -0.018339386, -0.0070180297, 0.01259744, -0.04580946, -0.026607882, -0.0046885153, -0.0041913074, 0.017348021, -0.010981816, -0.02941468, 0.011768194, 0.03249801, 0.01708897, 0.010896116, -0.04226195, 0.051305328, 0.017959155, 0.038876016, 0.00013482156, 0.06375874, -0.01658657, 0.03903206, -0.030651962, -0.025969885, 0.034965463, -0.013105432, -0.008826843, 0.01633216, -0.03610635, -0.013133627, -0.035857476, 0.01819475, -0.049543425, 0.012613599, -0.01631063, 0.032423344, 0.035753973, 0.06856881, 0.032358162, -0.022662269, 0.008159463, 0.0066780685, 0.057380334, 0.027155021, -0.002749179, -0.033280198, -0.0005200772, -0.029714126, -0.0056135943, 0.006489529, -0.021851735, 0.013414554, -0.023994066, 0.027456835, 0.024205292, -0.029841725, 0.013814438, -0.040398914, -0.006454571, 0.0181788, 0.018564364, 0.07413579, 0.03040654, 0.00686827, -0.008649567, 0.030923752, 0.022723403, -0.048147332, 0.0050135204, 0.026202962, 0.0074726185, 0.029897818, -0.035612546, -0.026207305, 0.023977518, 0.043129466, 0.041729428, 0.013394407, -0.019221226, -0.023377992, -0.019079505, 0.04460536, -0.037815712, 0.052122284, 0.080266885, -0.04226985, -0.030727414, 0.045799974, 0.025870334, -0.065274134, -0.04028277, -0.013677259, 0.01109989, -0.0009780334, 0.044592716, -0.044578493, 0.007066275, -0.028233098, 0.049794674, -0.00027890198, 0.04479656, -0.007964064, 0.015348843, 0.043535575, 0.0059533822, 0.010688639, 0.06503118, 0.035565536, 0.039602503, -0.011065689, 0.00090734503, 0.03381193, -0.05978616, -0.009268356, -0.012080214, 0.033247802, 0.031088043, 0.009075475, 0.050494693, -0.0043931296, 0.043259043, -0.02692313, -0.010897399, -0.010515699, 0.00137219, -0.0191715, -0.031660117, -0.02704263, 0.036935158, 0.025694935, -0.010136962, -0.04087534, -0.031191988, 0.00016253647, -0.03467313, -0.04068888, -0.019930629, 0.038226165, 0.06125731, 0.022343367, -0.045102425, -0.04790438, -0.014195164, 0.0020281628, 0.016108468, -0.024569744, 0.029656054, 0.015958814, 0.010225847, -0.006810483, -0.019841349, -0.010693482, -0.023954166, -0.038490057, 0.022426723, 0.020856615, -0.016232733, -0.038494796, 0.020594405, 0.047235172, 0.014213731, -0.030867264, 0.009099573, -0.0038552473, 0.023537194, 0.051777802, 0.006480521, -0.0019958182, 0.039523493, -0.031473298, -0.023503099, 0.012323043, -0.011041714, -0.039528236, -0.028218681, 0.00921942, -0.005444317, -0.062086903, -0.003079971, 0.0042318488, 0.024589993, 0.01905427, -0.046718057, 0.0014853951, -0.011471623, 0.0008362122, 0.05332638, 0.01788153, 0.011022061, -0.006962279, -0.02580199, 0.014910393, 0.031211546, -0.037136633, 0.018761888, 0.016504401, -0.008871138, -0.048503663, -0.005763119, -0.0065850164, 0.010165702, 0.005366493, -0.060353443, -0.021174664, 0.028277343, 0.00881119, -0.032315496, -0.027968813, -0.0036915503, -0.020829555, -0.01798839, 0.008608631, 0.06419013, -0.013133973, 0.00717364, -0.01414966, 0.0465632, 0.017154448, -0.026660794, 0.02706258, 0.035887495, -0.007616375, 0.06801733, 0.006739177, -0.021772528, -0.030992884, 0.0028950712, -0.031971037, 0.003298505, -0.006441683, 0.030606532, -0.03762017, 0.035464007, -0.0041361987, 0.015813565, -0.0043683373, 0.030875286, -0.034063917, -0.016113602, -0.002871881, -0.01956304, 0.0027995936, -0.0066453046, 0.023717137, -0.0065870844, -0.03513375, -0.0066106888, 0.031458054, -0.037236184, 0.013327151, -0.05270853, 0.004853231, -0.016240314, 0.0078057996, 0.042208225, 0.015480937, 0.06778662, 0.040566415, 0.008052702, 0.034583848, -0.028124068, 0.028478028, -0.021554068, -0.019096885, -0.010828192, -0.0020008553, -0.023091681, 0.026598401, -0.016345, -0.062031597, 0.031396225, 0.02683306, 0.011431723, -0.04499882, -0.013614843, 0.04236782, 0.0018992791, 0.006454448, 0.008434909, -0.010442134, -0.029381102, -0.03675423, 0.015530257, 0.00852493, 0.018513206, 0.014674588, -0.0065468396, -0.052533127, -0.013372136, -0.011397551, -0.023427965, 0.026513468, 0.008475007, 0.017390981, -0.041987788, -0.0582439, 0.013280832, -0.014252446, 0.010152566, 0.022982946, 0.026208492, -0.014353576, 0.028226877, -0.006172287, 0.007937251, 0.03408056, -0.033577275, -0.013945891, 0.010243475, 0.04096304, 0.03485643, -0.029157111, -0.015069251, 0.01728429, 0.013677309, 0.023257207, -0.031046808, 0.02556015, 0.001913365, 0.0397862, -0.015430927, -0.027572388, -0.0064147464, 0.0037405854, -0.003452764, 0.072002545, -0.009226657, 0.01354613, -0.018053373, -0.035531167, 0.032771382, 0.04592323, 0.014789263, 0.032436926, -0.009271195, -0.038289376, 0.0055981874, 0.019073183, 0.001051973, 0.0041091545, 0.002999579, -0.010985896, 0.019655086, 0.026771685, 0.0449767, -0.022204213, -0.029535873, -0.0060967347, -0.030221758, -0.007690249, 0.01610906, -0.05732108, -0.00020809013, -0.03662702, -0.05739851, -0.021484936, -0.028348058, 0.0056162607, 0.0073458673, -0.035439122, 0.029380705, -0.041982256, 0.02732884, 0.013827277, 0.014514632, 0.049128626, 0.0024722924, -0.020886391, -0.019511683, 0.004054301, -0.048340905, -0.0017850983, 0.021365039, -0.04871383, -0.0075140586, 0.00044309272, -0.04044356, -0.008320543, -0.009704092, 0.0079910755, -0.031372525, -0.014096008, -0.04592876, -0.010030497, -0.051777802, -0.010376261, 0.03436657, 0.018522492, -0.022016766, -0.0061470037, -0.018645745, 0.031615626, 0.0033017888, -0.0059103966, -0.010450282, -0.029074768, -0.020304935, 0.011098798, -0.0026732718, 0.01151404, 0.008307383, 0.0105963005, 0.007529354, 0.0068182354, 0.011166277, 0.02380148, 0.005774884, -0.050790187, -0.011678331, 0.020296441, 0.0037766828, 0.003984995, -0.03443215, -0.032514602, -0.02813671, -0.022544445, 0.021462813, -0.005384665, 0.022491906, 0.012893095, 0.047334332, 0.009069549, 0.038832165, -0.012095275, 0.045853704, -0.031826235, 0.032712124, -0.049706973, 0.00025150037, -0.05684702, -0.040090777, -0.043982767, 0.027154624, -0.033134032, 0.003777374, 0.0058625713, -0.016049506, -0.0017383599, -0.015281144, 0.04764247, -0.018379088, 0.010027386, -0.0010053163, -0.026232885, -0.03800257, 0.033105586, 0.058627885, 0.0006897738, 0.0019025137, 0.040598016, -0.013421221, -0.015445877, -0.0016699554, 0.008404392, -0.009171175, -0.0013115999, 0.0369636, 0.020449422, -0.0044343346, 0.039965946, -0.016773032, -0.007650448, 0.0034035624, -0.015105058, -0.06796834, 0.0031098956, -0.0037443878, -0.011017716, 0.022610739, 5.0121376e-05, -0.04728218, 0.020990338, -0.008418613, 0.020655734, 0.03818449, -0.030528512, 0.016867448, -0.0075285533, -0.025005382, -0.021540044, 0.022214089, 0.0047383714, -0.011671219, -0.007365916, -0.016791204, 0.039070774, -0.028080562, -0.00037400916, -0.0026313846, 0.017764991, 0.028108265, -0.0032396184, -0.016402282, 0.018701939, -0.021408297, -0.00391406, 0.00949363, 0.026709806, -0.006607528, -0.010854463, -0.0012577502, -0.018163987, 0.00610424, 0.02048784, -0.022119083, 0.009821469, -0.018716063, -0.053108312, 0.012857436, -0.007900956, -0.00089890097, -0.0049422393, -0.01756885, 0.03495361, 0.008524621, 0.005245807, -0.0198613, 0.038281474, 0.029385053, -0.004774876, -0.030336322, -0.017407203, -0.016541205, 0.051024053, -0.008610112, -6.518248e-06, -0.03031973, 0.024757886, 0.018962571, -0.012892798, -0.009085302, 0.019739231, -0.008910396, 0.016474327, -0.009826048, 0.021165146, -0.030313408, 0.03704261, 0.006643082, 0.021609843, -0.039014675, 0.018986076, 0.022358874, -0.01255533, -0.035995834, -0.012131742, -0.013217031, -0.015655054, -0.00846671, 0.0022066615, 0.03456884, -0.011293161, 0.014707265, 0.007170813, -0.015302673, 0.03407977, -0.01747562, 0.014168893, 0.022221103, -0.009129201, -0.027563892, 0.008546682, -0.0026264095, 0.014787337, -0.01150609, 0.013559536, -0.008898001, 0.03118804, -0.0034660534, -0.028385391, -0.0016763748, 0.026261229, -0.013727133, -0.0048458236, -0.010358014, 0.0066727973, -0.017142992, 0.008351554, 0.026404435, -0.0051104054, -0.011803954, 0.013847129, 0.017126992, -0.009369512, 0.015118386, -0.03973682, -0.0062125074, 0.0180035, 0.0031914478, -0.034196705, 0.055623963, 0.0020350267, -0.013412975, -0.027290551, 0.024507822, 0.005175884, 0.04610653, -0.0047531854, 0.013119258, -0.028346874, -0.0040103523, 0.006709944, -0.00051822537, -0.017142251, -0.010078051, 0.028008517, 0.045116547, -0.013331991, 0.005691023, 0.015359066, 0.025152534, 0.004866489, -0.008376985, -0.018213565, 0.0060684765, 0.05778723, -0.01136496, 0.021700937, -0.015636487, 0.013452649, 0.0030876496, -0.007872426, 0.0047555557, -0.006734239, -0.06230813, -0.036132425, 0.015871143, -0.031526197, 0.03844265, 0.027008854, 0.0061059194, 0.010292313, 0.03512743, 0.011795756, -0.026776567, 0.01168233, 0.037545107, 0.011863235, -0.03513217, -0.012273861, -0.021850253, -0.01089688, 0.0089069605, -0.033383306, -0.029186936, -0.02612751, 0.005296175, 0.004691262, 0.017273752, 0.010638817, 0.0035204093, 0.03847307, -0.021516934, -0.017887652, 0.014704325, 0.014788521, -0.027537424, 0.0046625715, 0.011277013, 0.0040909904, -0.01780857, 0.00783644, 0.004683793, -0.0022868186, -0.017704748, 0.0063631427, -0.024620805, 0.039907478, -0.026451446, -0.01875695, 0.009637624, 0.026333325, -0.0049995454, -0.003414772, 0.018437259, -0.00746248, -0.014964317, -0.00047577193, -0.014795633, -0.01130837, 0.023122791, -0.01053497, -0.021992965, 0.0061070183, 0.020760817, 0.004615117, 0.06892435, 0.002411011, -0.00086386537, 0.023648106, -0.011993823, 0.025132783, 0.0057477118, 0.004122267, 0.028886206, -0.00048215283, 0.008833769, 0.01368526, 0.0006675525, 4.098595e-06, 0.014153561, -0.0126887085, -0.0008737415, 0.017107092, -0.013705085, -0.010913127, -0.03438593, -0.003961885, -0.016732737, 0.010757824, -0.025162807, -0.007605116, 0.0037755962, -0.06571184, -0.0013288091, -0.009515309, 0.0038065582, -0.052095417, -0.008815782, 0.007712644, -0.023777777, 0.0022099824], 'usage': {'id': 'a8a5174dddc64dd089fdb016ad785c5a', 'total_tokens': 14}}]\n",
      "Embedding generation successful!\n",
      "Embedding dimension: 1024\n",
      "Embedding preview (first 5 values): [0.042495023, -0.100973584, 0.13122457, 0.09683984, 0.010602621]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def load_job_descriptions(source_type=\"local\", limit=10):\n",
    "    \"\"\"\n",
    "    Load job descriptions from local storage or S3.\n",
    "\n",
    "    Args:\n",
    "        source_type: 'local' or 's3'\n",
    "        limit: Maximum number of jobs to load\n",
    "\n",
    "    Returns:\n",
    "        List of job description dictionaries\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "\n",
    "    if source_type == \"local\":\n",
    "        # Load from local directory\n",
    "        job_dir = \"../data/processed/jobs\"\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(job_dir, exist_ok=True)\n",
    "\n",
    "        # Check if directory contains files\n",
    "        if not os.path.exists(job_dir) or not os.listdir(job_dir):\n",
    "            print(f\"No job files found in {job_dir}\")\n",
    "\n",
    "            # Create a sample job for testing if no files found\n",
    "            print(\"Creating a sample job for testing...\")\n",
    "            sample_job = {\n",
    "                \"job_id\": \"sample_job_001\",\n",
    "                \"details\": {\n",
    "                    \"job_title\": [\"Software Engineer\"],\n",
    "                    \"job_title_base\": [\"Software Engineer\"],\n",
    "                    \"company_name\": [\"Sample Company\"],\n",
    "                    \"employment_type\": [\"Full-time\"],\n",
    "                    \"location\": [{\"city\": \"New York\", \"state\": \"NY\", \"country\": \"US\"}]\n",
    "                },\n",
    "                \"mandatory\": {\n",
    "                    \"hard_skills\": [\n",
    "                        {\"skill\": [\"Python\"], \"minyears\": [3]},\n",
    "                        {\"skill\": [\"Machine Learning\"], \"minyears\": [1]}\n",
    "                    ],\n",
    "                    \"education\": [\n",
    "                        {\"education_level\": [\"Bachelor's\"], \"field_of_study\": [\"Computer Science\"]}\n",
    "                    ],\n",
    "                    \"credentials\": [\n",
    "                        {\"credential\": [\"AWS Certified Developer\"]}\n",
    "                    ],\n",
    "                    \"professional_background\": [\n",
    "                        {\"background\": [\"Software Development\"], \"minyears\": [2], \"industry\": [\"Technology\"]}\n",
    "                    ]\n",
    "                },\n",
    "                \"preferred\": {\n",
    "                    \"hard_skills\": [\n",
    "                        {\"skill\": [\"AWS\"], \"minyears\": [1]},\n",
    "                        {\"skill\": [\"Docker\"], \"minyears\": [1]}\n",
    "                    ],\n",
    "                    \"education\": [],\n",
    "                    \"credentials\": [],\n",
    "                    \"professional_background\": []\n",
    "                },\n",
    "                \"responsibility\": {\n",
    "                    \"hard_skills\": [\n",
    "                        {\"skill\": [\"Develop and maintain software applications\"]}\n",
    "                    ],\n",
    "                    \"professional_background\": [\n",
    "                        {\"background\": [\"Work in a collaborative team environment\"]}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Save the sample job\n",
    "            os.makedirs(job_dir, exist_ok=True)\n",
    "            with open(os.path.join(job_dir, \"sample_job_001.json\"), 'w') as f:\n",
    "                json.dump(sample_job, f, indent=2)\n",
    "\n",
    "            # Add to jobs list\n",
    "            jobs.append(sample_job)\n",
    "            return jobs\n",
    "\n",
    "        # Load job files\n",
    "        job_files = os.listdir(job_dir)[:limit]\n",
    "\n",
    "        for filename in job_files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                with open(os.path.join(job_dir, filename), 'r') as f:\n",
    "                    job_data = json.load(f)\n",
    "                    # Add job_id if not present\n",
    "                    if \"job_id\" not in job_data:\n",
    "                        job_data[\"job_id\"] = filename.replace(\".json\", \"\")\n",
    "                    jobs.append(job_data)\n",
    "\n",
    "    elif source_type == \"s3\":\n",
    "        # Load from S3\n",
    "        s3_client = boto3.client('s3')\n",
    "        bucket = \"mirra-matcher-325\"\n",
    "        prefix = \"processed/jobs/\"\n",
    "\n",
    "        try:\n",
    "            response = s3_client.list_objects_v2(\n",
    "                Bucket=bucket,\n",
    "                Prefix=prefix,\n",
    "                MaxKeys=limit\n",
    "            )\n",
    "\n",
    "            if 'Contents' in response:\n",
    "                for obj in response['Contents']:\n",
    "                    key = obj['Key']\n",
    "                    if key.endswith(\".json\"):\n",
    "                        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                        job_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "                        # Add job_id if not present\n",
    "                        if \"job_id\" not in job_data:\n",
    "                            job_data[\"job_id\"] = key.split(\"/\")[-1].replace(\".json\", \"\")\n",
    "                        jobs.append(job_data)\n",
    "            else:\n",
    "                print(f\"No job files found in S3 bucket {bucket}/{prefix}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading files from S3: {str(e)}\")\n",
    "\n",
    "    print(f\"Loaded {len(jobs)} job descriptions\")\n",
    "    return jobs\n",
    "\n",
    "# Load job descriptions\n",
    "sample_jobs = load_job_descriptions(source_type=\"local\", limit=3)\n",
    "\n",
    "# Display a preview of the first job\n",
    "if sample_jobs:\n",
    "    print(\"\\nPreview of first job:\")\n",
    "    company_names = sample_jobs[0].get(\"details\", {}).get(\"company_name\", [\"Unknown\"])\n",
    "    job_title = sample_jobs[0].get(\"details\", {}).get(\"job_title\", [\"Unknown\"])\n",
    "    \n",
    "    job_preview = {\n",
    "        \"job_id\": sample_jobs[0].get(\"job_id\"),\n",
    "        \"job_title\": job_title[0] if job_title else \"Unknown\",\n",
    "        \"company_name\": company_names[0] if company_names else \"Unknown\"\n",
    "    }\n",
    "    print(json.dumps(job_preview, indent=2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 3 job descriptions\n",
      "\n",
      "Preview of first job:\n",
      "{\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\",\n",
      "  \"job_title\": \"Full Stack .NET Developer\",\n",
      "  \"company_name\": \"Unknown\"\n",
      "}\n"
     ]
    }
   ],
   "metadata": {
    "id": "J6431PKCWaUC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Generate and display chunks for a sample job\n",
    "if sample_jobs:\n",
    "    sample_job = sample_jobs[0]\n",
    "\n",
    "    print(f\"Generating chunks for job: {sample_job.get('job_id')}\")\n",
    "    chunks = chunk_job_description(sample_job)\n",
    "\n",
    "    print(f\"Generated {len(chunks)} chunks\")\n",
    "\n",
    "    # Display a few sample chunks\n",
    "    print(\"\\nSample chunks:\")\n",
    "    for i, chunk in enumerate(chunks[:3]):  # Show first 3 chunks\n",
    "        print(f\"\\nChunk {i+1}:\")\n",
    "        print(f\"Text: {chunk['text']}\")\n",
    "        print(f\"Metadata: {json.dumps({k: v for k, v in chunk['metadata'].items() if k != 'source_type'}, indent=2)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating chunks for job: f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Generated 45 chunks\n",
      "\n",
      "Sample chunks:\n",
      "\n",
      "Chunk 1:\n",
      "Text: Job title: Full Stack .NET Developer\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"job_title\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\"\n",
      "}\n",
      "\n",
      "Chunk 2:\n",
      "Text: Employment type: Contract\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"employment_type\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\"\n",
      "}\n",
      "\n",
      "Chunk 3:\n",
      "Text: Work arrangement: On-site\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"wfh_policy\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\"\n",
      "}\n"
     ]
    }
   ],
   "metadata": {
    "id": "z5EZaDp4Wdxa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def process_and_embed_job(job_data, embedder):\n",
    "    \"\"\"\n",
    "    Process a job into chunks and generate embeddings.\n",
    "    \n",
    "    Args:\n",
    "        job_data: Job description dictionary\n",
    "        embedder: EmbeddingGenerator instance or SageMakerEmbedder instance\n",
    "        \n",
    "    Returns:\n",
    "        List of vectors ready for Pinecone\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "\n",
    "    # Validate job data\n",
    "    if not isinstance(job_data, dict) or \"details\" not in job_data:\n",
    "        print(\"Invalid job data format\")\n",
    "        return []\n",
    "    \n",
    "    # Ensure job has an ID\n",
    "    job_id = job_data.get(\"job_id\")\n",
    "    if not job_id:\n",
    "        job_id = str(uuid.uuid4())\n",
    "        job_data[\"job_id\"] = job_id\n",
    "    \n",
    "    # Generate chunks\n",
    "    chunks = chunk_job_description(job_data)\n",
    "    print(f\"Generated {len(chunks)} chunks for job {job_id}\")\n",
    "    \n",
    "    if not chunks:\n",
    "        print(\"No chunks generated. Check the job data structure.\")\n",
    "        return []\n",
    "    \n",
    "    # Create batch for embedding\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    \n",
    "    # Generate embeddings in batches\n",
    "    vectors = []\n",
    "    batch_size = 32  # Adjust as needed\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            # Check which type of embedder we're using\n",
    "            if isinstance(embedder, SageMakerEmbedder):\n",
    "                # If using SageMakerEmbedder directly, only pass texts\n",
    "                batch_embeddings = embedder.generate_embeddings(batch_texts)\n",
    "            else:\n",
    "                # If using EmbeddingGenerator, prepare instructions\n",
    "                batch_instructions = []\n",
    "                for j in range(i, min(i+batch_size, len(chunks))):\n",
    "                    chunk_type = chunks[j][\"metadata\"][\"chunk_type\"]\n",
    "                    if chunk_type == \"skill\":\n",
    "                        instruction = \"Represent this skill qualification for job-resume matching\"\n",
    "                    elif chunk_type == \"education\":\n",
    "                        instruction = \"Represent this educational qualification for job-resume matching\"\n",
    "                    elif chunk_type == \"experience\":\n",
    "                        instruction = \"Represent this professional experience for job-resume matching\"\n",
    "                    elif chunk_type == \"credential\":\n",
    "                        instruction = \"Represent this professional credential for job-resume matching\"\n",
    "                    else:\n",
    "                        instruction = \"Represent this qualification for job-resume matching\"\n",
    "                    batch_instructions.append(instruction)\n",
    "                \n",
    "                # Pass instructions only if using EmbeddingGenerator\n",
    "                batch_embeddings = embedder.generate_embeddings(\n",
    "                    batch_texts,\n",
    "                    batch_instructions if not USE_JINA_API else None\n",
    "                )\n",
    "            \n",
    "            # Create vectors for Pinecone\n",
    "            for j, emb in enumerate(batch_embeddings):\n",
    "                chunk_index = i + j\n",
    "                if chunk_index < len(chunks):  # Safety check\n",
    "                    vector_id = f\"{job_id}_chunk_{chunk_index}\"\n",
    "                    \n",
    "                    # Extract the actual embedding vector if emb is a dict\n",
    "                    if isinstance(emb, dict) and \"embedding\" in emb:\n",
    "                        embedding_vector = emb[\"embedding\"]\n",
    "                    else:\n",
    "                        embedding_vector = emb\n",
    "                    \n",
    "                    # Convert each element in the embedding vector to a float\n",
    "                    try:\n",
    "                        embedding_floats = [float(v) for v in embedding_vector]\n",
    "                    except Exception as conv_e:\n",
    "                        print(f\"Error converting embedding to floats for chunk {chunk_index}: {conv_e}\")\n",
    "                        continue\n",
    "                    \n",
    "                    vector = {\n",
    "                        \"id\": vector_id,\n",
    "                        \"values\": embedding_floats,\n",
    "                        \"metadata\": {\n",
    "                            \"chunk_text\": chunks[chunk_index][\"text\"],\n",
    "                            **chunks[chunk_index][\"metadata\"]\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    vectors.append(vector)\n",
    "            \n",
    "            print(f\"Processed batch of {len(batch_texts)} chunks\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {str(e)}\")\n",
    "        \n",
    "    return vectors\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "IioWN5jwWfe3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def upload_vectors_to_pinecone(vectors, index):\n",
    "    \"\"\"\n",
    "    Upload vectors to Pinecone in batches.\n",
    "\n",
    "    Args:\n",
    "        vectors: List of vectors\n",
    "        index: Pinecone index\n",
    "\n",
    "    Returns:\n",
    "        Number of vectors uploaded\n",
    "    \"\"\"\n",
    "    if not vectors:\n",
    "        print(\"No vectors to upload\")\n",
    "        return 0\n",
    "\n",
    "    if not index:\n",
    "        print(\"No valid Pinecone index provided\")\n",
    "        return 0\n",
    "\n",
    "    batch_size = 100  # Pinecone recommends max 100 per batch\n",
    "\n",
    "    total_uploaded = 0\n",
    "    for i in tqdm(range(0, len(vectors), batch_size), desc=\"Uploading to Pinecone\"):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        try:\n",
    "            index.upsert(vectors=batch)\n",
    "            total_uploaded += len(batch)\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading batch to Pinecone: {str(e)}\")\n",
    "\n",
    "    return total_uploaded"
   ],
   "outputs": [],
   "metadata": {
    "id": "3INovyWVWi_s"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Process and embed a sample job\n",
    "if sample_jobs and pinecone_index:\n",
    "    sample_job = sample_jobs[0]\n",
    "    job_id = sample_job.get(\"job_id\")\n",
    "\n",
    "    print(f\"Processing job: {job_id}\")\n",
    "\n",
    "    try:\n",
    "        # Generate vectors\n",
    "        start_time = time.time()\n",
    "        vectors = process_and_embed_job(sample_job, embedder)\n",
    "        embedding_time = time.time() - start_time\n",
    "\n",
    "        if vectors:\n",
    "            print(f\"Generated {len(vectors)} vectors in {embedding_time:.2f} seconds\")\n",
    "\n",
    "            # Upload to Pinecone\n",
    "            upload_start = time.time()\n",
    "            uploaded = upload_vectors_to_pinecone(vectors, pinecone_index)\n",
    "            upload_time = time.time() - upload_start\n",
    "\n",
    "            print(f\"Successfully processed and indexed job {job_id} with {uploaded} vectors\")\n",
    "            print(f\"Upload took {upload_time:.2f} seconds\")\n",
    "        else:\n",
    "            print(\"No vectors were generated. Check for errors above.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing job {job_id}: {str(e)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing job: f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Generated 45 chunks for job f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 13 chunks\n",
      "Generated 45 vectors in 0.24 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading to Pinecone: 100%|| 1/1 [00:00<00:00,  3.16it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully processed and indexed job f6aeaba8-87f5-498c-919a-8d25d63d3d9e with 45 vectors\n",
      "Upload took 0.32 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "id": "uWJ7jCenWlx9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Test retrieving vectors for sample job\n",
    "if pinecone_index and 'job_id' in locals() and job_id:\n",
    "    try:\n",
    "        # Query for vectors related to this job\n",
    "        results = pinecone_index.query(\n",
    "            vector=[0.0] * EMBEDDING_DIMENSION,  #Using a zero vector just to retrieve by metadata\n",
    "            filter={\"job_id\": job_id},\n",
    "            top_k=5,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        print(f\"\\nRetrieved {len(results['matches'])} vectors for job {job_id}\")\n",
    "\n",
    "        # Show a sample of retrieved vectors\n",
    "        if results[\"matches\"]:\n",
    "            print(\"\\nSample retrieved vector:\")\n",
    "            sample_match = results[\"matches\"][0]\n",
    "            # Only show relevant metadata for clarity\n",
    "            relevant_metadata = {k: v for k, v in sample_match[\"metadata\"].items()\n",
    "                               if k in [\"chunk_text\", \"chunk_type\", \"requirement_level\", \"skill_name\"]}\n",
    "            print(json.dumps(relevant_metadata, indent=2))\n",
    "        else:\n",
    "            print(\"No vectors retrieved. Check if the upload was successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Pinecone: {str(e)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Retrieved 5 vectors for job f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "\n",
      "Sample retrieved vector:\n",
      "{\n",
      "  \"chunk_text\": \"Preferred skill: NServiceBus\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"preferred\",\n",
      "  \"skill_name\": \"NServiceBus\"\n",
      "}\n"
     ]
    }
   ],
   "metadata": {
    "id": "wgqXeJP7WonI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def process_all_jobs(jobs, embedder, index, batch_size=5):\n",
    "    \"\"\"\n",
    "    Process multiple jobs and upload to Pinecone.\n",
    "\n",
    "    Args:\n",
    "        jobs: List of job dictionaries\n",
    "        embedder: EmbeddingGenerator instance\n",
    "        index: Pinecone index\n",
    "        batch_size: Number of jobs to process at once\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with processing statistics\n",
    "    \"\"\"\n",
    "    if not jobs:\n",
    "        print(\"No jobs to process\")\n",
    "        return {\"total_jobs\": 0}\n",
    "\n",
    "    if not index:\n",
    "        print(\"No valid Pinecone index provided\")\n",
    "        return {\"total_jobs\": len(jobs), \"successful_jobs\": 0, \"failed_jobs\": [job.get(\"job_id\", \"unknown\") for job in jobs]}\n",
    "\n",
    "    total_jobs = len(jobs)\n",
    "    total_chunks = 0\n",
    "    total_vectors = 0\n",
    "    failed_jobs = []\n",
    "\n",
    "    print(f\"Starting processing of {total_jobs} jobs\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, job in enumerate(jobs):\n",
    "        job_id = job.get(\"job_id\", str(uuid.uuid4()))\n",
    "        print(f\"\\nProcessing job {i+1}/{total_jobs}: {job_id}\")\n",
    "\n",
    "        try:\n",
    "            # Generate vectors\n",
    "            vectors = process_and_embed_job(job, embedder)\n",
    "            total_chunks += len(vectors)\n",
    "\n",
    "            # Upload to Pinecone\n",
    "            uploaded = upload_vectors_to_pinecone(vectors, index)\n",
    "            total_vectors += uploaded\n",
    "\n",
    "            print(f\"Successfully processed job {job_id} with {uploaded} vectors\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job {job_id}: {str(e)}\")\n",
    "            failed_jobs.append(job_id)\n",
    "\n",
    "        # Simple progress update\n",
    "        elapsed = time.time() - start_time\n",
    "        jobs_per_second = (i + 1) / elapsed if elapsed > 0 else 0\n",
    "        estimated_remaining = (total_jobs - (i + 1)) / jobs_per_second if jobs_per_second > 0 else 0\n",
    "\n",
    "        print(f\"Progress: {i+1}/{total_jobs} jobs processed\")\n",
    "        print(f\"Speed: {jobs_per_second:.2f} jobs/second\")\n",
    "        print(f\"Estimated time remaining: {estimated_remaining/60:.1f} minutes\")\n",
    "\n",
    "    # Final stats\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    stats = {\n",
    "        \"total_jobs\": total_jobs,\n",
    "        \"successful_jobs\": total_jobs - len(failed_jobs),\n",
    "        \"failed_jobs\": failed_jobs,\n",
    "        \"total_chunks\": total_chunks,\n",
    "        \"total_vectors\": total_vectors,\n",
    "        \"processing_time_seconds\": total_time,\n",
    "        \"jobs_per_second\": total_jobs / total_time if total_time > 0 else 0\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Process all sample jobs\n",
    "if sample_jobs and pinecone_index:\n",
    "    print(f\"Processing all {len(sample_jobs)} sample jobs\")\n",
    "\n",
    "    stats = process_all_jobs(sample_jobs, embedder, pinecone_index)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Successfully processed {stats['successful_jobs']}/{stats['total_jobs']} jobs\")\n",
    "    print(f\"Total vectors created: {stats.get('total_vectors', 0)}\")\n",
    "    print(f\"Processing time: {stats.get('processing_time_seconds', 0):.2f} seconds\")\n",
    "\n",
    "    if stats.get('processing_time_seconds', 0) > 0:\n",
    "        print(f\"Average processing speed: {stats.get('jobs_per_second', 0):.2f} jobs/second\")\n",
    "\n",
    "    if stats.get('failed_jobs', []):\n",
    "        print(f\"Failed jobs: {stats['failed_jobs']}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing all 3 sample jobs\n",
      "Starting processing of 3 jobs\n",
      "\n",
      "Processing job 1/3: f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Generated 45 chunks for job f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 13 chunks\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading to Pinecone: 100%|| 1/1 [00:00<00:00,  3.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully processed job f6aeaba8-87f5-498c-919a-8d25d63d3d9e with 45 vectors\n",
      "Progress: 1/3 jobs processed\n",
      "Speed: 1.91 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 2/3: 3acaf400-50b0-4906-8c86-ed7184df8712\n",
      "Generated 20 chunks for job 3acaf400-50b0-4906-8c86-ed7184df8712\n",
      "Processed batch of 20 chunks\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading to Pinecone: 100%|| 1/1 [00:00<00:00,  7.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully processed job 3acaf400-50b0-4906-8c86-ed7184df8712 with 20 vectors\n",
      "Progress: 2/3 jobs processed\n",
      "Speed: 2.65 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 3/3: 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\n",
      "Generated 37 chunks for job 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 5 chunks\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading to Pinecone: 100%|| 1/1 [00:00<00:00,  4.06it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully processed job 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e with 37 vectors\n",
      "Progress: 3/3 jobs processed\n",
      "Speed: 2.53 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing complete!\n",
      "Successfully processed 3/3 jobs\n",
      "Total vectors created: 102\n",
      "Processing time: 1.19 seconds\n",
      "Average processing speed: 2.53 jobs/second\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "id": "tV7R35gOWqTx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def print_job_chunks(job_id, num_chunks=None):\n",
    "    \"\"\"\n",
    "    Print chunks for a specific job\n",
    "    \n",
    "    Args:\n",
    "        job_id: ID of the job to display chunks for\n",
    "        num_chunks: Number of chunks to display (None for all)\n",
    "    \"\"\"\n",
    "    # Find the job in your loaded jobs\n",
    "    job = None\n",
    "    for j in sample_jobs:\n",
    "        if j.get(\"job_id\") == job_id:\n",
    "            job = j\n",
    "            break\n",
    "    \n",
    "    if not job:\n",
    "        print(f\"Job with ID {job_id} not found\")\n",
    "        return\n",
    "    \n",
    "    # Generate chunks for the job\n",
    "    chunks = chunk_job_description(job)\n",
    "    \n",
    "    # Determine how many chunks to display\n",
    "    display_count = num_chunks if num_chunks else len(chunks)\n",
    "    display_count = min(display_count, len(chunks))\n",
    "    \n",
    "    print(f\"Job ID: {job_id}\")\n",
    "    print(f\"Total chunks: {len(chunks)}\")\n",
    "    print(f\"Displaying {display_count} chunks:\\n\")\n",
    "    \n",
    "    # Display the chunks\n",
    "    for i, chunk in enumerate(chunks[:display_count]):\n",
    "        print(f\"Chunk {i+1}:\")\n",
    "        print(f\"Text: {chunk['text']}\")\n",
    "        print(f\"Metadata: {json.dumps(chunk['metadata'], indent=2)}\")\n",
    "        print(\"-\" * 50)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Print all chunks for a job\n",
    "print_job_chunks(\"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\", 20)\n",
    "\n",
    "# Print only the first 10 chunks\n",
    "print_job_chunks(\"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\", 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Job ID: 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\n",
      "Total chunks: 37\n",
      "Displaying 20 chunks:\n",
      "\n",
      "Chunk 1:\n",
      "Text: Job title: Program Manager\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"job_title\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 2:\n",
      "Text: Required skill: SAP\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"SAP\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 3:\n",
      "Text: Required skill: project delivery\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"project delivery\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 4:\n",
      "Text: Required skill: business operations\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"business operations\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 5:\n",
      "Text: Required skill: Agile practices\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"Agile practices\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 6:\n",
      "Text: Required skill: product management\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"product management\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 7:\n",
      "Text: Required skill: engineering execution tools\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"engineering execution tools\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 8:\n",
      "Text: Required skill: Rally\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"Rally\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 9:\n",
      "Text: Required skill: Aha\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"Aha\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 10:\n",
      "Text: Required skill: Jira\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"Jira\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 11:\n",
      "Text: Required skill: Confluence\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"Confluence\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 12:\n",
      "Text: Required experience: Program Management Leader\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"experience\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 13:\n",
      "Text: Preferred skill: communication skills influencing leaders\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"preferred\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"communication skills influencing leaders\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 14:\n",
      "Text: Preferred skill: building PowerPoint presentations\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"preferred\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\",\n",
      "  \"skill_name\": \"building PowerPoint presentations\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 15:\n",
      "Text: Job responsibility: monitor progress via effective information dashboards for project execution\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 16:\n",
      "Text: Job responsibility: monitor progress via effective information dashboards for progress against plan\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 17:\n",
      "Text: Job responsibility: monitor progress via effective information dashboards for quality & regulatory compliances\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 18:\n",
      "Text: Job responsibility: monitor progress via effective information dashboards for status review calls\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 19:\n",
      "Text: Job responsibility: monitor progress via effective information dashboards for escalation reporting\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 20:\n",
      "Text: Job responsibility: monitor progress via effective information dashboards for stakeholder reporting\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"job_id\": \"0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Job ID: f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Total chunks: 45\n",
      "Displaying 10 chunks:\n",
      "\n",
      "Chunk 1:\n",
      "Text: Job title: Full Stack .NET Developer\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"job_title\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 2:\n",
      "Text: Employment type: Contract\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"employment_type\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 3:\n",
      "Text: Work arrangement: On-site\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"wfh_policy\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 4:\n",
      "Text: Experience level: Senior\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"experience_level\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 5:\n",
      "Text: Required skill: C# with at least 4 years of experience\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\",\n",
      "  \"skill_name\": \"C#\",\n",
      "  \"minyears\": 4\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 6:\n",
      "Text: Required skill: .NET\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\",\n",
      "  \"skill_name\": \".NET\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 7:\n",
      "Text: Required skill: C#\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\",\n",
      "  \"skill_name\": \"C#\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 8:\n",
      "Text: Required skill: Typescript\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\",\n",
      "  \"skill_name\": \"Typescript\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 9:\n",
      "Text: Required skill: HTML\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\",\n",
      "  \"skill_name\": \"HTML\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "Chunk 10:\n",
      "Text: Required skill: Bootstrap\n",
      "Metadata: {\n",
      "  \"source_type\": \"job_description\",\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"job_id\": \"f6aeaba8-87f5-498c-919a-8d25d63d3d9e\",\n",
      "  \"skill_name\": \"Bootstrap\",\n",
      "  \"minyears\": 0\n",
      "}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}