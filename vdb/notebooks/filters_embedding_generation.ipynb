{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#03_embedding_generation\n",
    "- Sets up the embedding generator using either Jina API or SageMaker\n",
    "- Loads job descriptions from files\n",
    "- Creates chunks from job descriptions using a custom chunker\n",
    "- Generates embeddings for each chunk\n",
    "- Uploads the embedded vectors to Pinecone\n",
    "- Includes batch processing for efficiency"
   ],
   "metadata": {
    "id": "dynvT9cEdx4s"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install pinecone"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pinecone in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (6.0.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pinecone) (2025.1.31)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pinecone) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!pip show pinecone"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name: pinecone\n",
      "Version: 6.0.2\n",
      "Summary: Pinecone client and SDK\n",
      "Home-page: https://www.pinecone.io\n",
      "Author: Pinecone Systems, Inc.\n",
      "Author-email: support@pinecone.io\n",
      "License: Apache-2.0\n",
      "Location: /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages\n",
      "Requires: certifi, pinecone-plugin-interface, python-dateutil, typing-extensions, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ],
   "outputs": [],
   "metadata": {
    "id": "Eh1Rdi4NVCIP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# SageMaker endpoint configuration\n",
    "SAGEMAKER_ENDPOINT_NAME = \"e5-large-instruct-endpoint-325\" \n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "# Set Pinecone credentials directly\n",
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENVIRONMENT = \"us-east-1\" # matched with AWS region\n",
    "PINECONE_INDEX_NAME = \"mirra-filtering\"\n",
    "\n",
    "EMBEDDING_DIMENSION = 1024\n",
    "\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIMENSION}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "metadata": {
    "id": "7rXs4HpmWK-w"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class E5EmbeddingGenerator:\n",
    "    \"\"\"Class for embedding generation using SageMaker E5 endpoint\"\"\"\n",
    "\n",
    "    def __init__(self, endpoint_name=SAGEMAKER_ENDPOINT_NAME, region=AWS_REGION):\n",
    "        \"\"\"\n",
    "        Initialize with SageMaker endpoint\n",
    "        \n",
    "        Args:\n",
    "            endpoint_name: Name of the SageMaker endpoint for E5 embeddings\n",
    "            region: AWS region where the endpoint is deployed\n",
    "        \"\"\"\n",
    "        self.endpoint_name = endpoint_name\n",
    "        self.region = region\n",
    "        self.sagemaker_runtime = boto3.client('sagemaker-runtime', region_name=region)\n",
    "        print(f\"Initialized SageMaker embedder for endpoint: {endpoint_name}\")\n",
    "\n",
    "    def generate_embeddings(self, texts):\n",
    "        \"\"\"\n",
    "        Generate embeddings using SageMaker E5 endpoint\n",
    "        \n",
    "        Args:\n",
    "            texts: String or list of texts to embed\n",
    "            \n",
    "        Returns:\n",
    "            List of embedding vectors\n",
    "        \"\"\"\n",
    "        # Ensure texts is a list\n",
    "        if not isinstance(texts, list):\n",
    "            texts = [texts]\n",
    "            \n",
    "        try:\n",
    "            # Prepare input for E5 model\n",
    "            # E5 requires \"passage: \" prefix for embedding text passages\n",
    "            prefixed_texts = [\"passage: \" + text for text in texts]\n",
    "        \n",
    "            # Prepare payload for SageMaker endpoint\n",
    "            payload = {\n",
    "                \"inputs\": prefixed_texts,\n",
    "                \"normalize\": True  # Normalize embeddings for cosine similarity\n",
    "            }\n",
    "            \n",
    "            # Call SageMaker endpoint\n",
    "            response = self.sagemaker_runtime.invoke_endpoint(\n",
    "                EndpointName=self.endpoint_name,\n",
    "                ContentType='application/json',\n",
    "                Body=json.dumps(payload)\n",
    "            )\n",
    "            \n",
    "            # Parse response from endpoint\n",
    "            response_body = json.loads(response['Body'].read().decode('utf-8'))\n",
    "            \n",
    "            # Process the response\n",
    "            embeddings = []\n",
    "            \n",
    "            for emb in response_body:\n",
    "                # Convert to numpy for easier manipulation\n",
    "                emb_array = np.array(emb)\n",
    "                \n",
    "                # Handle various possible shapes\n",
    "                if len(emb_array.shape) == 3:  # Shape is (batch, tokens, dim)\n",
    "                    # Remove batch dimension if it's 1\n",
    "                    if emb_array.shape[0] == 1:\n",
    "                        emb_array = emb_array[0]  # Now shape is (tokens, dim)\n",
    "                    \n",
    "                    # Average over token dimension to get (dim)\n",
    "                    emb_vector = np.mean(emb_array, axis=0).tolist()\n",
    "                    embeddings.append(emb_vector)\n",
    "                elif len(emb_array.shape) == 2:  # Shape is (tokens, dim)\n",
    "                    # Average over token dimension\n",
    "                    emb_vector = np.mean(emb_array, axis=0).tolist()\n",
    "                    embeddings.append(emb_vector)\n",
    "                elif len(emb_array.shape) == 1:  # Already a 1D array\n",
    "                    embeddings.append(emb_array.tolist())\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected embedding shape: {emb_array.shape}\")\n",
    "            \n",
    "            return embeddings\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embeddings with SageMaker: {str(e)}\")\n",
    "            # Return zero vectors as fallback\n",
    "            return [[0.0] * EMBEDDING_DIMENSION] * len(texts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Initialize Pinecone\n",
    "def initialize_pinecone():\n",
    "    \"\"\"Initialize Pinecone and return the index\"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone client\n",
    "        from pinecone import Pinecone\n",
    "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        \n",
    "        # Check if the index exists\n",
    "        existing_indexes = pc.list_indexes().names()\n",
    "        print(f\"Available Pinecone indexes: {existing_indexes}\")\n",
    "        \n",
    "        if PINECONE_INDEX_NAME not in existing_indexes:\n",
    "            print(f\"Creating new index '{PINECONE_INDEX_NAME}'...\")\n",
    "            \n",
    "            # Create the index\n",
    "            pc.create_index(\n",
    "                name=PINECONE_INDEX_NAME,\n",
    "                dimension=EMBEDDING_DIMENSION,\n",
    "                metric=\"cosine\",\n",
    "                metadata_config={\n",
    "                    \"indexed\": [\n",
    "                        \"source_type\",\n",
    "                        \"job_id\",\n",
    "                        \"industry\",\n",
    "                        \"location\",\n",
    "                        \"experience_level\",\n",
    "                        \"visa_sponsorship\"\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            print(f\"Index '{PINECONE_INDEX_NAME}' created successfully\")\n",
    "        \n",
    "        # Connect to the index\n",
    "        index = pc.Index(PINECONE_INDEX_NAME)\n",
    "        print(f\"Connected to Pinecone index: {PINECONE_INDEX_NAME}\")\n",
    "        \n",
    "        return index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Pinecone: {str(e)}\")\n",
    "        print(\"Please check your API key and environment settings.\")\n",
    "        return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def load_job_descriptions(limit=1, bucket=\"mirra-matcher-325\", prefix=\"data/processed/jobs/\"):\n",
    "    \"\"\"\n",
    "    Load job descriptions from S3.\n",
    "    \n",
    "    Args:\n",
    "        limit: Maximum number of jobs to load\n",
    "        bucket: S3 bucket name\n",
    "        prefix: S3 prefix for job files\n",
    "        \n",
    "    Returns:\n",
    "        List of job description dictionaries\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "    \n",
    "    # Load from S3\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading job descriptions from S3: s3://{bucket}/{prefix}\")\n",
    "        response = s3_client.list_objects_v2(\n",
    "            Bucket=bucket,\n",
    "            Prefix=prefix,\n",
    "            MaxKeys=limit\n",
    "        )\n",
    "\n",
    "        if 'Contents' in response:\n",
    "            for obj in response['Contents']:\n",
    "                key = obj['Key']\n",
    "                if key.endswith(\".json\"):\n",
    "                    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                    job_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "                    # Add job_id if not present\n",
    "                    if \"job_id\" not in job_data:\n",
    "                        job_data[\"job_id\"] = key.split(\"/\")[-1].replace(\".json\", \"\")\n",
    "                    jobs.append(job_data)\n",
    "                    print(f\"Loaded job: {job_data.get('job_id')}\")\n",
    "        else:\n",
    "            print(f\"No job files found in S3 bucket {bucket}/{prefix}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading files from S3: {str(e)}\")\n",
    "\n",
    "    print(f\"Loaded {len(jobs)} job descriptions from S3\")\n",
    "    return jobs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def format_job_for_embedding(job):\n",
    "    \"\"\"\n",
    "    Format a job JSON into a comprehensive text representation for embedding.\n",
    "    \n",
    "    Args:\n",
    "        job: Job description dictionary\n",
    "    \n",
    "    Returns:\n",
    "        String representation of the job with all key attributes\n",
    "    \"\"\"\n",
    "    # Extract job details\n",
    "    details = job.get(\"details\", {})\n",
    "    \n",
    "    # Extract each attribute, handling potential missing data gracefully\n",
    "    # Job title - handle empty lists safely\n",
    "    job_title_data = details.get(\"job_title\", [\"Unknown\"]) \n",
    "    job_title = job_title_data[0] if isinstance(job_title_data, list) and job_title_data else job_title_data if not isinstance(job_title_data, list) else \"Unknown\"\n",
    "    \n",
    "    # Location handling\n",
    "    location_data = details.get(\"location\", {})\n",
    "    location = \"Remote\"  # Default\n",
    "    \n",
    "    if isinstance(location_data, list) and location_data:\n",
    "        location_item = location_data[0]\n",
    "        if isinstance(location_item, dict):\n",
    "            city = location_item.get(\"city\", \"\")\n",
    "            state = location_item.get(\"state\", \"\")\n",
    "            country = location_item.get(\"country\", \"\")\n",
    "            location = \", \".join(filter(None, [city, state, country]))\n",
    "    elif isinstance(location_data, dict):\n",
    "        city = location_data.get(\"city\", \"\")\n",
    "        state = location_data.get(\"state\", \"\")\n",
    "        country = location_data.get(\"country\", \"\")\n",
    "        location = \", \".join(filter(None, [city, state, country]))\n",
    "    elif location_data:\n",
    "        location = str(location_data)\n",
    "    \n",
    "    # Company name - handle empty lists safely\n",
    "    company_data = details.get(\"company_name\", [\"Unknown\"])\n",
    "    company_name = company_data[0] if isinstance(company_data, list) and company_data else company_data if not isinstance(company_data, list) else \"Unknown\"\n",
    "    \n",
    "    # Employment type - handle empty lists safely\n",
    "    employment_data = details.get(\"employment_type\", [\"Full-time\"])\n",
    "    employment_type = employment_data[0] if isinstance(employment_data, list) and employment_data else employment_data if not isinstance(employment_data, list) else \"Full-time\"\n",
    "    \n",
    "    # Experience level (inferred from required years in hard skills)\n",
    "    experience_level = \"Entry-level\"  # Default\n",
    "    if job.get(\"mandatory\", {}).get(\"hard_skills\"):\n",
    "        max_years = 0\n",
    "        for skill in job[\"mandatory\"][\"hard_skills\"]:\n",
    "            min_years_data = skill.get(\"minyears\", [0])\n",
    "            min_years = min_years_data[0] if isinstance(min_years_data, list) and min_years_data else min_years_data if not isinstance(min_years_data, list) else 0\n",
    "            \n",
    "            # Convert to numeric if needed\n",
    "            if not isinstance(min_years, (int, float)):\n",
    "                try:\n",
    "                    min_years = float(min_years)\n",
    "                except (ValueError, TypeError):\n",
    "                    min_years = 0\n",
    "                    \n",
    "            max_years = max(max_years, min_years)\n",
    "        \n",
    "        if max_years >= 7:\n",
    "            experience_level = \"Senior\"\n",
    "        elif max_years >= 3:\n",
    "            experience_level = \"Mid-level\"\n",
    "        else:\n",
    "            experience_level = \"Entry-level\"\n",
    "    \n",
    "    # Salary range - handle empty lists safely\n",
    "    salary_data = details.get(\"salary_range\", [\"Not specified\"])\n",
    "    salary_range = salary_data[0] if isinstance(salary_data, list) and salary_data else salary_data if not isinstance(salary_data, list) else \"Not specified\"\n",
    "    \n",
    "    # Date posted (default to \"Recent\" if not available)\n",
    "    date_posted = details.get(\"date_posted\", \"Recent\")\n",
    "    \n",
    "    # Industry/domain (inferred from job title or company if not explicitly stated)\n",
    "    industry_data = details.get(\"industry\", [\"Technology\"])\n",
    "    industry = industry_data[0] if isinstance(industry_data, list) and industry_data else industry_data if not isinstance(industry_data, list) else \"Technology\"\n",
    "    \n",
    "    # Visa sponsorship (default to \"Not specified\")\n",
    "    visa_sponsorship = details.get(\"visa_sponsorship\", \"Not specified\")\n",
    "    \n",
    "    # Skills required\n",
    "    required_skills = []\n",
    "    if job.get(\"mandatory\", {}).get(\"hard_skills\"):\n",
    "        for skill in job[\"mandatory\"][\"hard_skills\"]:\n",
    "            skill_data = skill.get(\"skill\", [\"\"])\n",
    "            skill_name = skill_data[0] if isinstance(skill_data, list) and skill_data else skill_data if not isinstance(skill_data, list) else \"\"\n",
    "            \n",
    "            min_years_data = skill.get(\"minyears\", [0])\n",
    "            min_years = min_years_data[0] if isinstance(min_years_data, list) and min_years_data else min_years_data if not isinstance(min_years_data, list) else 0\n",
    "            if skill_name:\n",
    "                required_skills.append(f\"{skill_name} ({min_years} years)\")\n",
    "    \n",
    "    required_skills_text = \", \".join(required_skills) if required_skills else \"Not specified\"\n",
    "    \n",
    "    # Education requirements\n",
    "    education = []\n",
    "    if job.get(\"mandatory\", {}).get(\"education\"):\n",
    "        for edu in job[\"mandatory\"][\"education\"]:\n",
    "            level_data = edu.get(\"education_level\", [\"\"])\n",
    "            level = level_data[0] if isinstance(level_data, list) and level_data else level_data if not isinstance(level_data, list) else \"\"\n",
    "            \n",
    "            field_data = edu.get(\"field_of_study\", [\"\"])\n",
    "            field = field_data[0] if isinstance(field_data, list) and field_data else field_data if not isinstance(field_data, list) else \"\"\n",
    "            if level or field:\n",
    "                education.append(f\"{level} in {field}\" if field else level)\n",
    "    \n",
    "    education_text = \", \".join(education) if education else \"Not specified\"\n",
    "    \n",
    "    # Combine all attributes into a single comprehensive text\n",
    "    job_text = f\"\"\"\n",
    "Job Title: {job_title}\n",
    "Company: {company_name}\n",
    "Location: {location}\n",
    "Employment Type: {employment_type}\n",
    "Experience Level: {experience_level}\n",
    "Salary Range: {salary_range}\n",
    "Date Posted: {date_posted}\n",
    "Industry/Domain: {industry}\n",
    "Visa Sponsorship: {visa_sponsorship}\n",
    "Required Skills: {required_skills_text}\n",
    "Education Requirements: {education_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    return job_text.strip()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def process_jobs_batch(jobs, embedder, pinecone_index, batch_size=1):\n",
    "    \"\"\"\n",
    "    Process a batch of jobs: format them, generate embeddings, and upload to Pinecone.\n",
    "    \n",
    "    Args:\n",
    "        jobs: List of job dictionaries\n",
    "        embedder: Embedding generator instance\n",
    "        pinecone_index: Pinecone index\n",
    "        batch_size: Batch size for embedding generation\n",
    "        \n",
    "    Returns:\n",
    "        Number of vectors uploaded\n",
    "    \"\"\"\n",
    "    job_texts = []\n",
    "    job_metadata = []\n",
    "    \n",
    "    # Process each job and prepare metadata\n",
    "    print(f\"Formatting {len(jobs)} jobs for embedding...\")\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            job_id = job.get(\"job_id\", str(uuid.uuid4()))\n",
    "            \n",
    "            # Format the job text\n",
    "            job_text = format_job_for_embedding(job)\n",
    "            job_texts.append(job_text)\n",
    "            \n",
    "            # Extract key metadata for filtering\n",
    "            details = job.get(\"details\", {})\n",
    "            \n",
    "            # Extract metadata for Pinecone filtering with safe handling\n",
    "            metadata = {\n",
    "                \"job_id\": job_id,\n",
    "                \"source_type\": \"job_description\"\n",
    "            }\n",
    "            \n",
    "            # Extract job title safely\n",
    "            job_title_data = details.get(\"job_title\", [\"Unknown\"])\n",
    "            metadata[\"job_title\"] = job_title_data[0] if isinstance(job_title_data, list) and job_title_data else job_title_data if not isinstance(job_title_data, list) else \"Unknown\"\n",
    "            \n",
    "            # Extract company safely\n",
    "            company_data = details.get(\"company_name\", [\"Unknown\"])\n",
    "            metadata[\"company\"] = company_data[0] if isinstance(company_data, list) and company_data else company_data if not isinstance(company_data, list) else \"Unknown\"\n",
    "            \n",
    "            # Handle location\n",
    "            location_data = details.get(\"location\", {})\n",
    "            if isinstance(location_data, list) and location_data and isinstance(location_data[0], dict):\n",
    "                metadata[\"location\"] = location_data[0].get(\"city\", \"\") + \", \" + location_data[0].get(\"state\", \"\")\n",
    "            elif isinstance(location_data, dict):\n",
    "                metadata[\"location\"] = location_data.get(\"city\", \"\") + \", \" + location_data.get(\"state\", \"\")\n",
    "            else:\n",
    "                metadata[\"location\"] = \"Unknown\"\n",
    "            \n",
    "            # Experience level\n",
    "            experience_level = \"Entry-level\"\n",
    "            if job.get(\"mandatory\", {}).get(\"hard_skills\"):\n",
    "                max_years = 0\n",
    "                for skill in job[\"mandatory\"][\"hard_skills\"]:\n",
    "                    # Safe handling of min years\n",
    "                    min_years_data = skill.get(\"minyears\", [0])\n",
    "                    min_years = min_years_data[0] if isinstance(min_years_data, list) and min_years_data else min_years_data if not isinstance(min_years_data, list) else 0\n",
    "                    \n",
    "                    # Convert to numeric if needed\n",
    "                    if not isinstance(min_years, (int, float)):\n",
    "                        try:\n",
    "                            min_years = float(min_years)\n",
    "                        except (ValueError, TypeError):\n",
    "                            min_years = 0\n",
    "                            \n",
    "                    max_years = max(max_years, min_years)\n",
    "                \n",
    "                if max_years >= 7:\n",
    "                    experience_level = \"Senior\"\n",
    "                elif max_years >= 3:\n",
    "                    experience_level = \"Mid-level\"\n",
    "                else:\n",
    "                    experience_level = \"Entry-level\"\n",
    "            \n",
    "            metadata[\"experience_level\"] = experience_level\n",
    "            \n",
    "            # Industry/domain - safe handling\n",
    "            industry_data = details.get(\"industry\", [\"Technology\"])\n",
    "            metadata[\"industry\"] = industry_data[0] if isinstance(industry_data, list) and industry_data else industry_data if not isinstance(industry_data, list) else \"Technology\"\n",
    "            \n",
    "            # Visa sponsorship\n",
    "            visa_data = details.get(\"visa_sponsorship\", \"No\")\n",
    "            if isinstance(visa_data, list):\n",
    "                visa_value = visa_data[0] if visa_data else \"No\"\n",
    "            else:\n",
    "                visa_value = visa_data\n",
    "                \n",
    "            metadata[\"visa_sponsorship\"] = \"Yes\" if str(visa_value).lower() in [\"yes\", \"available\", \"offered\"] else \"No\"\n",
    "            \n",
    "            job_metadata.append(metadata)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job {job.get('job_id', 'unknown')}: {str(e)}\")\n",
    "            # Continue with next job instead of failing the entire batch\n",
    "            continue\n",
    "    \n",
    "    # Generate embeddings in batches\n",
    "    vectors_to_upload = []\n",
    "    for i in range(0, len(job_texts), batch_size):\n",
    "        batch_texts = job_texts[i:i+batch_size]\n",
    "        batch_metadata = job_metadata[i:i+batch_size]\n",
    "        \n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(len(job_texts)-1)//batch_size + 1 if len(job_texts) > 0 else 1}...\")\n",
    "        \n",
    "        # Generate embeddings for the batch\n",
    "        batch_embeddings = embedder.generate_embeddings(batch_texts)\n",
    "        \n",
    "        # Create vectors for Pinecone\n",
    "        for j, embedding in enumerate(batch_embeddings):\n",
    "            idx = i + j\n",
    "            if idx < len(job_metadata):\n",
    "                vector_id = f\"job_{job_metadata[idx]['job_id']}\"\n",
    "                \n",
    "                vectors_to_upload.append({\n",
    "                    \"id\": vector_id,\n",
    "                    \"values\": embedding,\n",
    "                    \"metadata\": {\n",
    "                        \"text\": job_texts[idx][:1000],  # Truncate text to avoid metadata size limits\n",
    "                        **job_metadata[idx]\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    # Upload vectors to Pinecone\n",
    "    total_uploaded = 0\n",
    "    upload_batch_size = 1  # Pinecone recommendation\n",
    "    \n",
    "    if vectors_to_upload:\n",
    "        for i in tqdm(range(0, len(vectors_to_upload), upload_batch_size), desc=\"Uploading to Pinecone\"):\n",
    "            batch = vectors_to_upload[i:i+upload_batch_size]\n",
    "            try:\n",
    "                pinecone_index.upsert(vectors=batch)\n",
    "                total_uploaded += len(batch)\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading batch to Pinecone: {str(e)}\")\n",
    "    else:\n",
    "        print(\"No vectors to upload\")\n",
    "    \n",
    "    return total_uploaded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def embed_jobs_main():\n",
    "    \"\"\"Main function to load jobs, generate embeddings, and upload to Pinecone\"\"\"\n",
    "    # Initialize embedding generator\n",
    "    embedder = E5EmbeddingGenerator()\n",
    "    \n",
    "    # Initialize Pinecone\n",
    "    pinecone_index = initialize_pinecone()\n",
    "    \n",
    "    if not pinecone_index:\n",
    "        print(\"Failed to initialize Pinecone. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Test the embedder\n",
    "    try:\n",
    "        test_text = \"Job Title: Software Engineer Location: San Francisco\"\n",
    "        embedding = embedder.generate_embeddings([test_text])\n",
    "        \n",
    "        print(\"Testing embedder\")\n",
    "        if isinstance(embedding, list) and len(embedding) > 0:\n",
    "            embedding_array = np.array(embedding[0])\n",
    "            print(f\"Embedding generation successful!\")\n",
    "            print(f\"Embedding dimension: {len(embedding[0])}\")\n",
    "            print(f\"Embedding shape: {embedding_array.shape}\")\n",
    "            print(f\"Embedding preview (first 5 values): {embedding[0][:5]}\")\n",
    "        else:\n",
    "            print(f\"Warning: Unexpected embedding format\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing embedding generation: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Load job descriptions\n",
    "    jobs = load_job_descriptions(limit=100)\n",
    "    \n",
    "    if not jobs:\n",
    "        print(\"No jobs loaded. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Process and embed jobs\n",
    "    print(f\"Processing {len(jobs)} jobs...\")\n",
    "    \n",
    "    # Process jobs in batches of 16\n",
    "    batch_size = 1\n",
    "    total_vectors = 0\n",
    "    \n",
    "    for i in range(0, len(jobs), batch_size):\n",
    "        job_batch = jobs[i:i+batch_size]\n",
    "        print(f\"\\nProcessing batch {i//batch_size + 1}/{(len(jobs)-1)//batch_size + 1} with {len(job_batch)} jobs\")\n",
    "        \n",
    "        vectors_uploaded = process_jobs_batch(\n",
    "            job_batch, \n",
    "            embedder, \n",
    "            pinecone_index, \n",
    "            batch_size=16\n",
    "        )\n",
    "        \n",
    "        total_vectors += vectors_uploaded\n",
    "        print(f\"Uploaded {vectors_uploaded} vectors in this batch\")\n",
    "    \n",
    "    print(f\"\\nCompleted job embedding process.\")\n",
    "    print(f\"Total jobs processed: {len(jobs)}\")\n",
    "    print(f\"Total vectors uploaded: {total_vectors}\")\n",
    "    \n",
    "    # Verify index contents\n",
    "    try:\n",
    "        index_stats = pinecone_index.describe_index_stats()\n",
    "        print(f\"\\nFinal Pinecone index statistics:\")\n",
    "        print(index_stats)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving index stats: {str(e)}\")\n",
    "\n",
    "# Run the main function if executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    embed_jobs_main()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "embedder = E5EmbeddingGenerator()\n",
    "\n",
    "def semantic_job_title_search(query_title, pinecone_index, embedder=None, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Search for semantically similar job titles in Pinecone.\n",
    "    \n",
    "    Args:\n",
    "        query_title: The job title to search for\n",
    "        pinecone_index: The Pinecone index to search\n",
    "        embedder: Embedding generator instance (optional)\n",
    "        similarity_threshold: Minimum similarity score (0-1) to include in results\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with job_id, job_title, and similarity score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create embedder if not provided\n",
    "        if embedder is None:\n",
    "            from random_embedding import RandomEmbeddingGenerator\n",
    "            print(\"No embedder provided. Creating RandomEmbeddingGenerator as fallback.\")\n",
    "            embedder = RandomEmbeddingGenerator()\n",
    "            \n",
    "        # 1. Create embedding for the query job title\n",
    "        query_text = f\"{query_title}\"  # You may need to adjust the format\n",
    "        query_embedding = embedder.generate_embeddings([query_text])[0]\n",
    "        \n",
    "        # 2. Query Pinecone\n",
    "        search_results = pinecone_index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=100,  # Get enough results to filter\n",
    "            include_metadata=True,\n",
    "            include_values=False  # only need the scores, not the vectors\n",
    "        )\n",
    "        \n",
    "        # 3. Filter and format results\n",
    "        similar_jobs = []\n",
    "        \n",
    "        # Pinecone v6+ returns objects instead of dictionaries\n",
    "        matches = getattr(search_results, 'matches', [])\n",
    "        \n",
    "        for match in matches:\n",
    "            # Extract match properties\n",
    "            score = getattr(match, 'score', 0)\n",
    "            metadata = getattr(match, 'metadata', {})\n",
    "            \n",
    "            # Skip if below threshold\n",
    "            if score < similarity_threshold:\n",
    "                continue\n",
    "                \n",
    "            # Extract job info from metadata\n",
    "            job_id = metadata.get('job_id', 'unknown')\n",
    "            job_title = metadata.get('job_title', metadata.get('text', '')).replace('Job title: ', '')\n",
    "            \n",
    "            similar_jobs.append({\n",
    "                'job_id': job_id,\n",
    "                'job_title': job_title,\n",
    "                'similarity': score\n",
    "            })\n",
    "        \n",
    "        return similar_jobs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in semantic search: {str(e)}\")\n",
    "        return []"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initialized SageMaker embedder for endpoint: e5-large-instruct-endpoint-325\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Test the function with a sample job title\n",
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "pinecone_index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "test_query = \"Senior Software Engineer\"\n",
    "results = semantic_job_title_search(\n",
    "    test_query, \n",
    "    pinecone_index=pinecone_index,\n",
    "    embedder=embedder\n",
    ")\n",
    "\n",
    "print(f\"Jobs similar to '{test_query}' (similarity > 0.8):\")\n",
    "for job in results:\n",
    "    print(f\"- {job['job_title']} (ID: {job['job_id']}, Score: {job['similarity']:.4f})\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Jobs similar to 'Senior Software Engineer' (similarity > 0.8):\n",
      "- Back-end Software Engineer (Hybrid) (ID: 901969dd-7034-47f0-b539-30dacd5e928d, Score: 0.8674)\n",
      "- Senior Solutions Engineer (ID: 57cea150-f3f7-4238-95a5-1db5b6e940eb, Score: 0.8576)\n",
      "- Software Engineer (ID: 1f58b149-ed8e-4fb2-96dd-d83d266f5310, Score: 0.8544)\n",
      "- Software Engineer in Test (ID: 98ab83df-021a-4889-9af3-bd6664d725e2, Score: 0.8529)\n",
      "- Software Engineer - ML Tools Support - 314915 (ID: a2998f35-d332-4fee-8170-c9c946fab8e0, Score: 0.8514)\n",
      "- Staff Security Operations Engineer (ID: babf4bb0-7f3a-48e6-be4b-53e3934f9e0a, Score: 0.8420)\n",
      "- Senior Mechanical Engineer (Rotating and Packaged Equipment) (ID: d84838c8-db39-4750-9021-64c5e2c14fe1, Score: 0.8391)\n",
      "- Technology Delivery Lead (ID: 04a9e436-fbc3-4d2f-a543-a6474dc485f9, Score: 0.8354)\n",
      "- Full Stack .NET Developer (ID: f6aeaba8-87f5-498c-919a-8d25d63d3d9e, Score: 0.8326)\n",
      "- Senior QA/QC Technical Architect - Aviation & Federal (ID: f20e91c6-5042-44a7-a065-6a9454797a47, Score: 0.8310)\n",
      "- Project Test Manager (PTM) (ID: 0d652f5d-9822-4b9b-8274-65674eb68b42, Score: 0.8281)\n",
      "- RTL ASIC Design Engineer (ID: d645a2b1-4888-40f7-be2b-efed95803965, Score: 0.8279)\n",
      "- Program Manager (ID: 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e, Score: 0.8278)\n",
      "- Business Analyst I (ID: 9d15576d-1d0f-4396-88d7-4ea76a13d639, Score: 0.8232)\n",
      "- Technical Writer (ID: f71df3a6-441f-44af-bd75-f6d922e08a37, Score: 0.8182)\n",
      "- AWS Infrastructure Consultant with Project Management Experience (ID: cd540421-60f8-4a39-acb5-e27a0659e83f, Score: 0.8176)\n",
      "- Service Desk Analyst (ID: b5c6e3df-df3a-4e5b-a850-8ebe8be6fcc6, Score: 0.8144)\n",
      "- Sr Training Specialist with child welfare Experience (ID: 90a9f50c-584c-49a4-ac5e-5928ff8a4b94, Score: 0.8103)\n",
      "- Mechanical Design Engineer (ID: a7fe9a21-6a8d-4069-ae47-57083bb97667, Score: 0.8096)\n",
      "- Project Coordinator (Architecture/Engineering) (ID: 5e00aafa-57c3-4c06-8b06-1fe311bc8e4e, Score: 0.8082)\n",
      "- Tier 1 - Help Desk Technician - Remote (ID: c51dca25-7ccf-4b90-a640-2a095c3aaea1, Score: 0.8037)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}