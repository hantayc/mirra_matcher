{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dynvT9cEdx4s"
   },
   "source": [
    "#03_embedding_generation\n",
    "- Sets up the embedding generator using either Jina API or SageMaker\n",
    "- Loads job descriptions from files\n",
    "- Creates chunks from job descriptions using a custom chunker\n",
    "- Generates embeddings for each chunk\n",
    "- Uploads the embedded vectors to Pinecone\n",
    "- Includes batch processing for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jinaai in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.2.10)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinaai) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->jinaai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->jinaai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->jinaai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->jinaai) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install jinaai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinaai import JinaAI\n",
    "client = JinaAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Eh1Rdi4NVCIP"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import modules\n",
    "from src.chunking.job_chunker import chunk_job_description\n",
    "from src.embedding.jina_embedder import JinaEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7rXs4HpmWK-w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding method: SageMaker Endpoint\n",
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "# 1: SageMaker endpoint configuration\n",
    "SAGEMAKER_ENDPOINT_NAME = \"jina-embeddings-v3-endpoint-config-325-v2\"\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "# alt option 2: Direct Jina API configuration\n",
    "USE_JINA_API = False  # Set to True to use direct Jina API instead of SageMaker, need to add API key\n",
    "JINA_API_HOST = \"grpc://api.jina.ai:443\"  # Jina API endpoint\n",
    "\n",
    "# Set Pinecone credentials directly\n",
    "PINECONE_API_KEY = \"pcsk_7VkStS_ifR3SH9d1MSkkju9kP7DUt5M16CpNyzi9dwNBm7iUqyXmbKZWQbC55ZzfSEaAB\"\n",
    "PINECONE_ENVIRONMENT = \"us-east-1\" # matched with AWS region\n",
    "PINECONE_INDEX_NAME = \"mirra\"\n",
    "\n",
    "EMBEDDING_DIMENSION = 1024\n",
    "\n",
    "print(f\"Embedding method: {'Direct Jina API' if USE_JINA_API else 'SageMaker Endpoint'}\")\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIMENSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nregion = \"us-east-1\" \\nmodel_name = \"jina-embeddings-v3-model\"\\nendpoint_name = \"jina-embeddings-v3-endpoint-config-325-v2\"\\ninstance_type = \"ml.g5.xlarge\" # limited to compatible options\\nmodel_package_arn = \"arn:aws:sagemaker:us-east-1:865070037744:model-package/jina-embeddings-v3-784cbb3a8e4b38998ef3708b26dd7cb7\"\\n\\n# Initialize boto3 clients\\nsm_client = boto3.client(\\'sagemaker\\', region_name=region)\\nsm_runtime = boto3.client(\\'sagemaker-runtime\\', region_name=region)\\n\\n# Create model\\ntry:\\n    model_response = sm_client.create_model(\\n        ModelName=model_name,\\n        PrimaryContainer={\\n            \\'ModelPackageName\\': model_package_arn\\n        },\\n        ExecutionRoleArn=\"arn:aws:iam::938638984428:role/service-role/AmazonSageMaker-ExecutionRole-20250217T202480\"\\n    )\\n    print(f\"Model created: {model_name}\")\\nexcept Exception as e:\\n    print(f\"Error creating model: {str(e)}\")\\n    # If model already exists, continue\\n    print(\"Continuing with existing model if available.\")\\n\\n# Create endpoint configuration\\ntry:\\n    endpoint_config_response = sm_client.create_endpoint_config(\\n        EndpointConfigName=endpoint_name,\\n        ProductionVariants=[{\\n            \\'VariantName\\': \\'default\\',\\n            \\'ModelName\\': model_name,\\n            \\'InstanceType\\': instance_type,\\n            \\'InitialInstanceCount\\': 1\\n        }]\\n    )\\n    print(f\"Endpoint configuration created: {endpoint_name}\")\\nexcept Exception as e:\\n    print(f\"Error creating endpoint configuration: {str(e)}\")\\n    # If config already exists, continue\\n    print(\"Continuing with existing endpoint configuration if available.\")\\n\\n# Check if endpoint exists\\ntry:\\n    endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\\n    print(f\"Endpoint already exists: {endpoint_name}\")\\n    print(f\"Current status: {endpoint_response[\\'EndpointStatus\\']}\")\\nexcept sm_client.exceptions.ClientError:\\n    # Create endpoint if it doesn\\'t exist\\n    try:\\n        create_endpoint_response = sm_client.create_endpoint(\\n            EndpointName=endpoint_name,\\n            EndpointConfigName=endpoint_name\\n        )\\n        print(f\"Creating endpoint: {endpoint_name}\")\\n        print(\"Endpoint creation initiated. This will take several minutes...\")\\n    except Exception as e:\\n        print(f\"Error creating endpoint: {str(e)}\")\\n        raise\\n\\n# wait for endpoint to be in service\\nwait_for_endpoint = True\\nif wait_for_endpoint:\\n    print(\"Waiting for endpoint to be ready... (this may take 5-10 minutes)\")\\n    waiter = sm_client.get_waiter(\\'endpoint_in_service\\')\\n    waiter.wait(EndpointName=endpoint_name)\\n    print(f\"Endpoint {endpoint_name} is now ready for use!\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set variables - skipping because endpoint is already created\n",
    "\"\"\"\n",
    "region = \"us-east-1\" \n",
    "model_name = \"jina-embeddings-v3-model\"\n",
    "endpoint_name = \"jina-embeddings-v3-endpoint-config-325-v2\"\n",
    "instance_type = \"ml.g5.xlarge\" # limited to compatible options\n",
    "model_package_arn = \"arn:aws:sagemaker:us-east-1:865070037744:model-package/jina-embeddings-v3-784cbb3a8e4b38998ef3708b26dd7cb7\"\n",
    "\n",
    "# Initialize boto3 clients\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "sm_runtime = boto3.client('sagemaker-runtime', region_name=region)\n",
    "\n",
    "# Create model\n",
    "try:\n",
    "    model_response = sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        PrimaryContainer={\n",
    "            'ModelPackageName': model_package_arn\n",
    "        },\n",
    "        ExecutionRoleArn=\"arn:aws:iam::938638984428:role/service-role/AmazonSageMaker-ExecutionRole-20250217T202480\"\n",
    "    )\n",
    "    print(f\"Model created: {model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating model: {str(e)}\")\n",
    "    # If model already exists, continue\n",
    "    print(\"Continuing with existing model if available.\")\n",
    "\n",
    "# Create endpoint configuration\n",
    "try:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_name,\n",
    "        ProductionVariants=[{\n",
    "            'VariantName': 'default',\n",
    "            'ModelName': model_name,\n",
    "            'InstanceType': instance_type,\n",
    "            'InitialInstanceCount': 1\n",
    "        }]\n",
    "    )\n",
    "    print(f\"Endpoint configuration created: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating endpoint configuration: {str(e)}\")\n",
    "    # If config already exists, continue\n",
    "    print(\"Continuing with existing endpoint configuration if available.\")\n",
    "\n",
    "# Check if endpoint exists\n",
    "try:\n",
    "    endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"Endpoint already exists: {endpoint_name}\")\n",
    "    print(f\"Current status: {endpoint_response['EndpointStatus']}\")\n",
    "except sm_client.exceptions.ClientError:\n",
    "    # Create endpoint if it doesn't exist\n",
    "    try:\n",
    "        create_endpoint_response = sm_client.create_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_name\n",
    "        )\n",
    "        print(f\"Creating endpoint: {endpoint_name}\")\n",
    "        print(\"Endpoint creation initiated. This will take several minutes...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating endpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# wait for endpoint to be in service\n",
    "wait_for_endpoint = True\n",
    "if wait_for_endpoint:\n",
    "    print(\"Waiting for endpoint to be ready... (this may take 5-10 minutes)\")\n",
    "    waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "    waiter.wait(EndpointName=endpoint_name)\n",
    "    print(f\"Endpoint {endpoint_name} is now ready for use!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zyFuKnf-WNul"
   },
   "outputs": [],
   "source": [
    "SAGEMAKER_ENDPOINT_NAME = \"jina-embeddings-v3-endpoint-config-325-v2\" \n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"Unified class for embedding generation using either SageMaker or Jina API\"\"\"\n",
    "    \n",
    "    def __init__(self, use_jina_api=True, jina_api_key=None):\n",
    "        \"\"\"\n",
    "        Initialize with embedding method.\n",
    "        \n",
    "        Args:\n",
    "            use_jina_api (bool): If True, use direct Jina API; otherwise use SageMaker.\n",
    "            jina_api_key: API key for Jina. Must be provided if using the Jina API.\n",
    "        \"\"\"\n",
    "        self.use_jina_api = use_jina_api\n",
    "        \n",
    "        if use_jina_api:\n",
    "            try:\n",
    "                if not jina_api_key:\n",
    "                    print(\"Warning: Jina API key not provided. Some functionality may be limited.\")\n",
    "                \n",
    "                # Initialize the Jina API client and configure it with the API key if provided\n",
    "                self.jina_client = JinaAI()\n",
    "                if jina_api_key:\n",
    "                    self.jina_client.configure(api_key=jina_api_key)\n",
    "                print(\"Initialized Jina API client\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing Jina API client: {str(e)}\")\n",
    "                raise\n",
    "        else:\n",
    "            # Initialize the SageMaker embedder\n",
    "            self.embedder = SageMakerEmbedder(\n",
    "                endpoint_name=SAGEMAKER_ENDPOINT_NAME, \n",
    "                region=AWS_REGION\n",
    "            )\n",
    "            print(f\"Initialized SageMaker embedder for endpoint: {SAGEMAKER_ENDPOINT_NAME}\")\n",
    "            \n",
    "    def generate_embeddings(self, texts, instructions=None):\n",
    "        \"\"\"Generate embeddings using the configured method\"\"\"\n",
    "        # Ensure texts is a list\n",
    "        if not isinstance(texts, list):\n",
    "            texts = [texts]\n",
    "        # Process using the appropriate method\n",
    "        if self.use_jina_api:\n",
    "            return self._generate_with_jina_api(texts)\n",
    "        else:\n",
    "            return self._generate_with_sagemaker(texts)\n",
    "            \n",
    "    def _generate_with_jina_api(self, texts):\n",
    "        \"\"\"Generate embeddings using Jina API\"\"\"\n",
    "        try:\n",
    "            # Call the embeddings API using the JinaAI client\n",
    "            embeddings_response = self.jina_client.embeddings(\n",
    "                texts=texts,\n",
    "                model=\"jina-embeddings-v3-base-en\"\n",
    "            )\n",
    "            \n",
    "            if isinstance(embeddings_response, dict) and 'embeddings' in embeddings_response:\n",
    "                # If response is {embeddings: [[values], [values]]}\n",
    "                embeddings = embeddings_response['embeddings']\n",
    "            elif isinstance(embeddings_response, list):\n",
    "                # If response is a list of objects with 'embedding' field\n",
    "                embeddings = [item['embedding'] for item in embeddings_response]\n",
    "            else:\n",
    "                # Fallback case\n",
    "                print(f\"Unexpected response format: {type(embeddings_response)}\")\n",
    "                print(f\"Response sample: {str(embeddings_response)[:100]}...\")\n",
    "                raise ValueError(\"Could not parse embedding response\")\n",
    "                \n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embeddings with Jina API: {str(e)}\")\n",
    "            raise \n",
    "            \n",
    "    def _generate_with_sagemaker(self, texts, instructions=None):\n",
    "        \"\"\"Generate embeddings using SageMaker endpoint\"\"\"\n",
    "        try:\n",
    "            # Format the payload directly here rather than in SageMakerEmbedder\n",
    "            payload = {\n",
    "                \"data\": [{\"text\": text} for text in texts],\n",
    "                \"parameters\": {\n",
    "                    \"task\": \"text-matching\",\n",
    "                    \"late_chunking\": False,\n",
    "                    \"dimensions\": 1024\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Pass the properly formatted payload to the embedder\n",
    "            embeddings = self.embedder.generate_embeddings(payload)\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"Error with SageMaker embedding: {str(e)}\")\n",
    "            # Return zero vectors as fallback\n",
    "            return [[0.0] * EMBEDDING_DIMENSION] * len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZIFlvOu_WURm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Pinecone indexes: ['mirra']\n",
      "Connected to Pinecone index: mirra\n",
      "Index statistics: {\n",
      "  \"namespaces\": {},\n",
      "  \"index_fullness\": 0.0,\n",
      "  \"total_vector_count\": 0,\n",
      "  \"dimension\": 1024,\n",
      "  \"metric\": \"cosine\",\n",
      "  \"vector_type\": \"dense\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone with credentials\n",
    "from pinecone import Pinecone\n",
    "\n",
    "def initialize_pinecone():\n",
    "    \"\"\"Initialize Pinecone and return the index\"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone \n",
    "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        \n",
    "        # Check if the index exists\n",
    "        existing_indexes = pc.list_indexes().names()\n",
    "        print(f\"Available Pinecone indexes: {existing_indexes}\")\n",
    "        \n",
    "        if PINECONE_INDEX_NAME not in existing_indexes:\n",
    "            print(f\"Creating new index '{PINECONE_INDEX_NAME}'...\")\n",
    "            # Create the index\n",
    "            pc.create_index(\n",
    "                name=PINECONE_INDEX_NAME,\n",
    "                dimension=EMBEDDING_DIMENSION,\n",
    "                metric=\"cosine\",\n",
    "                metadata_config={\n",
    "                    \"indexed\": [\n",
    "                        \"source_type\",\n",
    "                        \"chunk_type\",\n",
    "                        \"requirement_level\",\n",
    "                        \"job_id\",\n",
    "                        \"resume_id\"\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            print(f\"Index '{PINECONE_INDEX_NAME}' created successfully\")\n",
    "        \n",
    "        # Connect to the index\n",
    "        index = pc.Index(PINECONE_INDEX_NAME)\n",
    "        print(f\"Connected to Pinecone index: {PINECONE_INDEX_NAME}\")\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Pinecone: {str(e)}\")\n",
    "        print(\"Please check your API key and environment settings.\")\n",
    "        # Return None to indicate initialization failed\n",
    "        return None\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone_index = initialize_pinecone()\n",
    "if pinecone_index:\n",
    "    # Check index stats\n",
    "    index_stats = pinecone_index.describe_index_stats()\n",
    "    # Convert to dictionary for JSON serialization\n",
    "    index_stats_dict = index_stats.to_dict()\n",
    "    print(f\"Index statistics: {json.dumps(index_stats_dict, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('self', 'api_key', 'Embeddings')\n"
     ]
    }
   ],
   "source": [
    "# Check how JinaEmbedder is defined\n",
    "print(JinaEmbedder.__init__.__code__.co_varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update\n",
    "class SageMakerEmbedder:\n",
    "    def __init__(self, endpoint_name, region=\"us-east-1\"):\n",
    "        self.endpoint_name = endpoint_name\n",
    "        self.region = region\n",
    "        self.client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "        \n",
    "    def generate_embeddings(self, texts_or_payload):\n",
    "        \"\"\"\n",
    "        Generate embeddings using SageMaker endpoint.\n",
    "        \n",
    "        Args:\n",
    "            texts_or_payload: Either a string, list of strings, or pre-formatted payload\n",
    "            \n",
    "        Returns:\n",
    "            List of embedding vectors\n",
    "        \"\"\"\n",
    "        # Check if texts_or_payload is already formatted as a payload\n",
    "        if isinstance(texts_or_payload, dict) and \"data\" in texts_or_payload:\n",
    "            payload = texts_or_payload\n",
    "        else:\n",
    "            # Convert input to proper format\n",
    "            if isinstance(texts_or_payload, str):\n",
    "                texts = [texts_or_payload]\n",
    "            else:\n",
    "                texts = texts_or_payload\n",
    "                \n",
    "            # Format as Jina Embeddings v3 payload\n",
    "            payload = {\n",
    "                \"data\": [{\"text\": text} for text in texts],\n",
    "                \"parameters\": {\n",
    "                    \"task\": \"text-matching\",\n",
    "                    \"late_chunking\": False,\n",
    "                    \"dimensions\": 1024\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Call the SageMaker endpoint\n",
    "        response = self.client.invoke_endpoint(\n",
    "            EndpointName=self.endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Handle the specific response format we've observed\n",
    "        if isinstance(result, list) and all(\"embedding\" in item for item in result):\n",
    "            # Response contains a list of objects with 'embedding' key\n",
    "            embeddings = [item[\"embedding\"] for item in result]\n",
    "            return embeddings\n",
    "        \n",
    "        # Fallback to previous handling methods if format changes\n",
    "        if \"embeddings\" in result:\n",
    "            return result[\"embeddings\"]\n",
    "        elif \"data\" in result:\n",
    "            return result[\"data\"]\n",
    "        else:\n",
    "            # Try to find embeddings in the result structure\n",
    "            for key in result:\n",
    "                if isinstance(result[key], list) and len(result[key]) > 0:\n",
    "                    return result[key]\n",
    "        \n",
    "        raise ValueError(\"Could not find embeddings in response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: {\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"text\": \"Required skill: Python programming with 3 years experience\"\n",
      "    }\n",
      "  ],\n",
      "  \"parameters\": {\n",
      "    \"task\": \"text-matching\",\n",
      "    \"late_chunking\": false,\n",
      "    \"dimensions\": 1024\n",
      "  }\n",
      "}\n",
      "Full embedding result: [{'id': 'dc44f8f7fcf59605ef2fe4a9083c05c8', 'embedding': [0.042495023, -0.100973584, 0.13122457, 0.09683984, 0.010602621, 0.029769432, -0.11279018, -0.03456933, 0.005282447, -0.07970909, 0.01447604, 0.049952693, 0.035989024, 0.020272836, 0.070766844, 0.0012989584, -0.01198133, 0.08423315, -0.05487654, 0.031116141, -0.07024854, -0.008453575, 0.09742766, 0.11486971, 0.002564517, -0.044930875, 0.0024241956, 0.048844982, -0.05904031, -0.016179081, -0.015846059, 0.0410697, -0.06578453, -0.08232428, 0.06688908, 0.021171479, 0.05903241, -0.007505971, -0.025006961, -0.078260064, 0.0702359, 0.01094404, 0.01820606, 0.042301454, -0.0039463546, 0.01971612, 0.023533441, 0.006535729, 0.074573494, -0.0012242949, 0.014283259, -0.05642985, 0.007336387, -0.033324443, 0.056659576, -0.014966786, 0.070384435, 0.0052306964, -0.078392796, -0.060712148, -0.034851294, 0.040063124, 0.018525502, 0.047081504, 0.027381431, 0.046021324, -0.004920783, -0.03273464, 0.025062367, -0.0265587, 0.015320055, -0.035983495, -0.0013892263, 0.0241029, -0.027820671, -0.02815567, 0.055894174, 0.011467573, -0.06769299, -0.00939319, 0.016119257, 0.04227617, 0.027897706, 0.052159414, 0.047639303, 0.0083459, -0.0020873456, 0.040867046, -0.06913135, 0.03607665, 0.041794214, 0.008470561, 0.060432456, 0.011392811, -0.035879005, -0.087374546, -0.0750997, -0.0002143121, 0.03256675, -0.040297784, -0.0013873498, 0.065593325, -0.064670496, -0.044848505, -0.018402692, 0.007809651, -0.0752988, -0.016742762, -0.039874297, -0.048637982, 0.009684685, 0.041413393, 0.027772874, -0.00584035, 0.006856111, 0.0027697058, 0.024162157, 0.012294205, 0.07818263, 0.012221418, -0.028164016, 0.050703276, -0.03983163, 0.059532538, -0.06731098, -0.04820817, -0.09890987, -0.010855846, 0.011616456, -0.021758504, 0.0042696116, 0.008301779, -0.0077858986, 0.062617846, -0.011616308, -0.035374332, 0.0055988785, -0.012492124, -0.043574587, -0.005170551, 0.023792395, -0.014969058, -0.054603167, 0.017728351, 0.04869961, -0.046347506, -0.03597026, 0.0064286464, -0.003423364, 0.016038395, 0.056625795, 0.0019438206, -0.014067959, -0.01507019, -0.06840447, -0.054169405, -0.050685108, -0.014034775, 0.006522445, -0.043261416, -0.020599268, 0.044094957, -0.03210257, 0.015777469, 0.005292422, -0.03552445, 0.02072793, -0.036046304, -0.014218866, -0.052607395, -0.0039839954, -0.020520432, 0.017278563, 0.0142911095, -0.006391636, 0.024680557, -0.024917984, 0.086470686, 0.07649658, -0.027595496, -0.035217106, 0.051308487, -1.2740212e-05, 0.033152994, 0.0153807625, 0.05282625, -0.0056401365, 0.019401861, -0.022719083, 0.028744388, -0.03181932, -0.051180493, 0.0014678033, 0.033314172, -0.03146516, 0.05969135, 0.018168826, -0.026737507, -0.0078031328, 0.012310451, -0.0038755923, 0.007905647, -0.05716464, -0.085193895, 0.007744271, 0.07513604, 0.01666084, -0.037914474, -0.08246018, -0.0011470141, -0.0135109285, -0.0049781143, -0.061423227, -0.02384474, -0.07027698, 0.013157182, -0.0075049787, 0.02561632, -0.02970741, -0.028797222, 0.017425844, 0.017384266, -0.029756729, 0.0012946129, -0.056349266, -0.106643274, -0.025035998, 0.026160939, 0.023199826, -0.043955904, 0.036178254, -0.07061198, 0.0142560005, -0.028493186, 0.02227621, -0.0050497656, -0.028088119, 0.037635177, -0.02924323, 0.08252971, 0.024934074, 0.00011772351, -0.008886149, -0.027731393, 0.013002424, 0.010549574, -0.040945165, 0.00856004, -0.0382396, 0.085193895, 0.006056489, 0.034059227, -0.032403495, 0.02827379, 0.0077219508, -0.0105976835, 0.06640238, -0.00844841, 0.014027072, -0.032258216, 0.044252187, 0.04009552, 0.00088322256, 0.0057289656, 0.033802446, 0.026243653, 0.005516536, -0.015461012, -0.0005411133, 0.0054907594, -0.031031204, -0.0022565976, -0.03218039, 0.013954581, 0.0065014586, 0.014585764, 0.0018716259, -0.011910913, -0.0033046282, -0.0327378, -0.055198893, -0.05120103, -0.043255884, -0.03564968, -0.030050702, -0.03218237, -0.016032606, -0.023237456, 0.007052448, 0.017080575, 0.032054372, 0.030982813, 0.0077667404, -0.0475919, -0.01035199, 0.0023338783, -0.0006193138, 0.015873712, -0.0007192541, -0.03863859, 0.061050303, 0.05786466, -0.018339386, -0.0070180297, 0.01259744, -0.04580946, -0.026607882, -0.0046885153, -0.0041913074, 0.017348021, -0.010981816, -0.02941468, 0.011768194, 0.03249801, 0.01708897, 0.010896116, -0.04226195, 0.051305328, 0.017959155, 0.038876016, 0.00013482156, 0.06375874, -0.01658657, 0.03903206, -0.030651962, -0.025969885, 0.034965463, -0.013105432, -0.008826843, 0.01633216, -0.03610635, -0.013133627, -0.035857476, 0.01819475, -0.049543425, 0.012613599, -0.01631063, 0.032423344, 0.035753973, 0.06856881, 0.032358162, -0.022662269, 0.008159463, 0.0066780685, 0.057380334, 0.027155021, -0.002749179, -0.033280198, -0.0005200772, -0.029714126, -0.0056135943, 0.006489529, -0.021851735, 0.013414554, -0.023994066, 0.027456835, 0.024205292, -0.029841725, 0.013814438, -0.040398914, -0.006454571, 0.0181788, 0.018564364, 0.07413579, 0.03040654, 0.00686827, -0.008649567, 0.030923752, 0.022723403, -0.048147332, 0.0050135204, 0.026202962, 0.0074726185, 0.029897818, -0.035612546, -0.026207305, 0.023977518, 0.043129466, 0.041729428, 0.013394407, -0.019221226, -0.023377992, -0.019079505, 0.04460536, -0.037815712, 0.052122284, 0.080266885, -0.04226985, -0.030727414, 0.045799974, 0.025870334, -0.065274134, -0.04028277, -0.013677259, 0.01109989, -0.0009780334, 0.044592716, -0.044578493, 0.007066275, -0.028233098, 0.049794674, -0.00027890198, 0.04479656, -0.007964064, 0.015348843, 0.043535575, 0.0059533822, 0.010688639, 0.06503118, 0.035565536, 0.039602503, -0.011065689, 0.00090734503, 0.03381193, -0.05978616, -0.009268356, -0.012080214, 0.033247802, 0.031088043, 0.009075475, 0.050494693, -0.0043931296, 0.043259043, -0.02692313, -0.010897399, -0.010515699, 0.00137219, -0.0191715, -0.031660117, -0.02704263, 0.036935158, 0.025694935, -0.010136962, -0.04087534, -0.031191988, 0.00016253647, -0.03467313, -0.04068888, -0.019930629, 0.038226165, 0.06125731, 0.022343367, -0.045102425, -0.04790438, -0.014195164, 0.0020281628, 0.016108468, -0.024569744, 0.029656054, 0.015958814, 0.010225847, -0.006810483, -0.019841349, -0.010693482, -0.023954166, -0.038490057, 0.022426723, 0.020856615, -0.016232733, -0.038494796, 0.020594405, 0.047235172, 0.014213731, -0.030867264, 0.009099573, -0.0038552473, 0.023537194, 0.051777802, 0.006480521, -0.0019958182, 0.039523493, -0.031473298, -0.023503099, 0.012323043, -0.011041714, -0.039528236, -0.028218681, 0.00921942, -0.005444317, -0.062086903, -0.003079971, 0.0042318488, 0.024589993, 0.01905427, -0.046718057, 0.0014853951, -0.011471623, 0.0008362122, 0.05332638, 0.01788153, 0.011022061, -0.006962279, -0.02580199, 0.014910393, 0.031211546, -0.037136633, 0.018761888, 0.016504401, -0.008871138, -0.048503663, -0.005763119, -0.0065850164, 0.010165702, 0.005366493, -0.060353443, -0.021174664, 0.028277343, 0.00881119, -0.032315496, -0.027968813, -0.0036915503, -0.020829555, -0.01798839, 0.008608631, 0.06419013, -0.013133973, 0.00717364, -0.01414966, 0.0465632, 0.017154448, -0.026660794, 0.02706258, 0.035887495, -0.007616375, 0.06801733, 0.006739177, -0.021772528, -0.030992884, 0.0028950712, -0.031971037, 0.003298505, -0.006441683, 0.030606532, -0.03762017, 0.035464007, -0.0041361987, 0.015813565, -0.0043683373, 0.030875286, -0.034063917, -0.016113602, -0.002871881, -0.01956304, 0.0027995936, -0.0066453046, 0.023717137, -0.0065870844, -0.03513375, -0.0066106888, 0.031458054, -0.037236184, 0.013327151, -0.05270853, 0.004853231, -0.016240314, 0.0078057996, 0.042208225, 0.015480937, 0.06778662, 0.040566415, 0.008052702, 0.034583848, -0.028124068, 0.028478028, -0.021554068, -0.019096885, -0.010828192, -0.0020008553, -0.023091681, 0.026598401, -0.016345, -0.062031597, 0.031396225, 0.02683306, 0.011431723, -0.04499882, -0.013614843, 0.04236782, 0.0018992791, 0.006454448, 0.008434909, -0.010442134, -0.029381102, -0.03675423, 0.015530257, 0.00852493, 0.018513206, 0.014674588, -0.0065468396, -0.052533127, -0.013372136, -0.011397551, -0.023427965, 0.026513468, 0.008475007, 0.017390981, -0.041987788, -0.0582439, 0.013280832, -0.014252446, 0.010152566, 0.022982946, 0.026208492, -0.014353576, 0.028226877, -0.006172287, 0.007937251, 0.03408056, -0.033577275, -0.013945891, 0.010243475, 0.04096304, 0.03485643, -0.029157111, -0.015069251, 0.01728429, 0.013677309, 0.023257207, -0.031046808, 0.02556015, 0.001913365, 0.0397862, -0.015430927, -0.027572388, -0.0064147464, 0.0037405854, -0.003452764, 0.072002545, -0.009226657, 0.01354613, -0.018053373, -0.035531167, 0.032771382, 0.04592323, 0.014789263, 0.032436926, -0.009271195, -0.038289376, 0.0055981874, 0.019073183, 0.001051973, 0.0041091545, 0.002999579, -0.010985896, 0.019655086, 0.026771685, 0.0449767, -0.022204213, -0.029535873, -0.0060967347, -0.030221758, -0.007690249, 0.01610906, -0.05732108, -0.00020809013, -0.03662702, -0.05739851, -0.021484936, -0.028348058, 0.0056162607, 0.0073458673, -0.035439122, 0.029380705, -0.041982256, 0.02732884, 0.013827277, 0.014514632, 0.049128626, 0.0024722924, -0.020886391, -0.019511683, 0.004054301, -0.048340905, -0.0017850983, 0.021365039, -0.04871383, -0.0075140586, 0.00044309272, -0.04044356, -0.008320543, -0.009704092, 0.0079910755, -0.031372525, -0.014096008, -0.04592876, -0.010030497, -0.051777802, -0.010376261, 0.03436657, 0.018522492, -0.022016766, -0.0061470037, -0.018645745, 0.031615626, 0.0033017888, -0.0059103966, -0.010450282, -0.029074768, -0.020304935, 0.011098798, -0.0026732718, 0.01151404, 0.008307383, 0.0105963005, 0.007529354, 0.0068182354, 0.011166277, 0.02380148, 0.005774884, -0.050790187, -0.011678331, 0.020296441, 0.0037766828, 0.003984995, -0.03443215, -0.032514602, -0.02813671, -0.022544445, 0.021462813, -0.005384665, 0.022491906, 0.012893095, 0.047334332, 0.009069549, 0.038832165, -0.012095275, 0.045853704, -0.031826235, 0.032712124, -0.049706973, 0.00025150037, -0.05684702, -0.040090777, -0.043982767, 0.027154624, -0.033134032, 0.003777374, 0.0058625713, -0.016049506, -0.0017383599, -0.015281144, 0.04764247, -0.018379088, 0.010027386, -0.0010053163, -0.026232885, -0.03800257, 0.033105586, 0.058627885, 0.0006897738, 0.0019025137, 0.040598016, -0.013421221, -0.015445877, -0.0016699554, 0.008404392, -0.009171175, -0.0013115999, 0.0369636, 0.020449422, -0.0044343346, 0.039965946, -0.016773032, -0.007650448, 0.0034035624, -0.015105058, -0.06796834, 0.0031098956, -0.0037443878, -0.011017716, 0.022610739, 5.0121376e-05, -0.04728218, 0.020990338, -0.008418613, 0.020655734, 0.03818449, -0.030528512, 0.016867448, -0.0075285533, -0.025005382, -0.021540044, 0.022214089, 0.0047383714, -0.011671219, -0.007365916, -0.016791204, 0.039070774, -0.028080562, -0.00037400916, -0.0026313846, 0.017764991, 0.028108265, -0.0032396184, -0.016402282, 0.018701939, -0.021408297, -0.00391406, 0.00949363, 0.026709806, -0.006607528, -0.010854463, -0.0012577502, -0.018163987, 0.00610424, 0.02048784, -0.022119083, 0.009821469, -0.018716063, -0.053108312, 0.012857436, -0.007900956, -0.00089890097, -0.0049422393, -0.01756885, 0.03495361, 0.008524621, 0.005245807, -0.0198613, 0.038281474, 0.029385053, -0.004774876, -0.030336322, -0.017407203, -0.016541205, 0.051024053, -0.008610112, -6.518248e-06, -0.03031973, 0.024757886, 0.018962571, -0.012892798, -0.009085302, 0.019739231, -0.008910396, 0.016474327, -0.009826048, 0.021165146, -0.030313408, 0.03704261, 0.006643082, 0.021609843, -0.039014675, 0.018986076, 0.022358874, -0.01255533, -0.035995834, -0.012131742, -0.013217031, -0.015655054, -0.00846671, 0.0022066615, 0.03456884, -0.011293161, 0.014707265, 0.007170813, -0.015302673, 0.03407977, -0.01747562, 0.014168893, 0.022221103, -0.009129201, -0.027563892, 0.008546682, -0.0026264095, 0.014787337, -0.01150609, 0.013559536, -0.008898001, 0.03118804, -0.0034660534, -0.028385391, -0.0016763748, 0.026261229, -0.013727133, -0.0048458236, -0.010358014, 0.0066727973, -0.017142992, 0.008351554, 0.026404435, -0.0051104054, -0.011803954, 0.013847129, 0.017126992, -0.009369512, 0.015118386, -0.03973682, -0.0062125074, 0.0180035, 0.0031914478, -0.034196705, 0.055623963, 0.0020350267, -0.013412975, -0.027290551, 0.024507822, 0.005175884, 0.04610653, -0.0047531854, 0.013119258, -0.028346874, -0.0040103523, 0.006709944, -0.00051822537, -0.017142251, -0.010078051, 0.028008517, 0.045116547, -0.013331991, 0.005691023, 0.015359066, 0.025152534, 0.004866489, -0.008376985, -0.018213565, 0.0060684765, 0.05778723, -0.01136496, 0.021700937, -0.015636487, 0.013452649, 0.0030876496, -0.007872426, 0.0047555557, -0.006734239, -0.06230813, -0.036132425, 0.015871143, -0.031526197, 0.03844265, 0.027008854, 0.0061059194, 0.010292313, 0.03512743, 0.011795756, -0.026776567, 0.01168233, 0.037545107, 0.011863235, -0.03513217, -0.012273861, -0.021850253, -0.01089688, 0.0089069605, -0.033383306, -0.029186936, -0.02612751, 0.005296175, 0.004691262, 0.017273752, 0.010638817, 0.0035204093, 0.03847307, -0.021516934, -0.017887652, 0.014704325, 0.014788521, -0.027537424, 0.0046625715, 0.011277013, 0.0040909904, -0.01780857, 0.00783644, 0.004683793, -0.0022868186, -0.017704748, 0.0063631427, -0.024620805, 0.039907478, -0.026451446, -0.01875695, 0.009637624, 0.026333325, -0.0049995454, -0.003414772, 0.018437259, -0.00746248, -0.014964317, -0.00047577193, -0.014795633, -0.01130837, 0.023122791, -0.01053497, -0.021992965, 0.0061070183, 0.020760817, 0.004615117, 0.06892435, 0.002411011, -0.00086386537, 0.023648106, -0.011993823, 0.025132783, 0.0057477118, 0.004122267, 0.028886206, -0.00048215283, 0.008833769, 0.01368526, 0.0006675525, 4.098595e-06, 0.014153561, -0.0126887085, -0.0008737415, 0.017107092, -0.013705085, -0.010913127, -0.03438593, -0.003961885, -0.016732737, 0.010757824, -0.025162807, -0.007605116, 0.0037755962, -0.06571184, -0.0013288091, -0.009515309, 0.0038065582, -0.052095417, -0.008815782, 0.007712644, -0.023777777, 0.0022099824], 'usage': {'id': 'e5e6a05240c708dfc1ce73ea212f0632', 'total_tokens': 14}}]\n",
      "Embedding generation successful!\n",
      "Embedding dimension: 1024\n",
      "Embedding preview (first 5 values): [0.042495023, -0.100973584, 0.13122457, 0.09683984, 0.010602621]\n"
     ]
    }
   ],
   "source": [
    "# Use the SageMaker embedder\n",
    "embedder = SageMakerEmbedder(endpoint_name=SAGEMAKER_ENDPOINT_NAME, region=AWS_REGION)\n",
    "\n",
    "try:\n",
    "    test_text = \"Required skill: Python programming with 3 years experience\"\n",
    "    # Correct payload matching the required JSON format:\n",
    "    payload = {\n",
    "        \"data\": [{\"text\": test_text}],\n",
    "        \"parameters\": {\n",
    "            \"task\": \"text-matching\",\n",
    "            \"late_chunking\": False,\n",
    "            \"dimensions\": 1024\n",
    "        }\n",
    "    }\n",
    "    print(\"Payload:\", json.dumps(payload, indent=2))  # Debug output\n",
    "\n",
    "    result = embedder.generate_embeddings(payload)\n",
    "    \n",
    "    print(\"Full embedding result:\", result)\n",
    "    \n",
    "    # Extract the embedding vector from the first document in the returned list\n",
    "    embedding_vector = result[0].get(\"embedding\")\n",
    "    if not embedding_vector:\n",
    "        raise ValueError(\"No embedding vector found in the result.\")\n",
    "    \n",
    "    # calculate its dimension; print a preview\n",
    "    embedding_dim = len(embedding_vector)\n",
    "    print(\"Embedding generation successful!\")\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "    print(f\"Embedding preview (first 5 values): {embedding_vector[:5]}\")\n",
    "    \n",
    "    if 'EMBEDDING_DIMENSION' in globals() and embedding_dim != EMBEDDING_DIMENSION:\n",
    "        print(f\"Warning: Expected dimension {EMBEDDING_DIMENSION}, but got {embedding_dim}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error testing embedding generation: {str(e)}\")\n",
    "    print(\"Please check your configuration and try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J6431PKCWaUC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_job_descriptions(source_type=\"local\", limit=10):\\n    \"\"\"\\n    Load job descriptions from local storage or S3.\\n\\n    Args:\\n        source_type: \\'local\\' or \\'s3\\'\\n        limit: Maximum number of jobs to load\\n\\n    Returns:\\n        List of job description dictionaries\\n    \"\"\"\\n    jobs = []\\n\\n    if source_type == \"local\":\\n        # Load from local directory\\n        job_dir = \"../data/processed/jobs\"\\n\\n        # Create directory if it doesn\\'t exist\\n        os.makedirs(job_dir, exist_ok=True)\\n\\n        # Check if directory contains files\\n        if not os.path.exists(job_dir) or not os.listdir(job_dir):\\n            print(f\"No job files found in {job_dir}\")\\n\\n            # Create a sample job for testing if no files found\\n            print(\"Creating a sample job for testing...\")\\n            sample_job = {\\n                \"job_id\": \"sample_job_001\",\\n                \"details\": {\\n                    \"job_title\": [\"Software Engineer\"],\\n                    \"job_title_base\": [\"Software Engineer\"],\\n                    \"company_name\": [\"Sample Company\"],\\n                    \"employment_type\": [\"Full-time\"],\\n                    \"location\": [{\"city\": \"New York\", \"state\": \"NY\", \"country\": \"US\"}]\\n                },\\n                \"mandatory\": {\\n                    \"hard_skills\": [\\n                        {\"skill\": [\"Python\"], \"minyears\": [3]},\\n                        {\"skill\": [\"Machine Learning\"], \"minyears\": [1]}\\n                    ],\\n                    \"education\": [\\n                        {\"education_level\": [\"Bachelor\\'s\"], \"field_of_study\": [\"Computer Science\"]}\\n                    ],\\n                    \"credentials\": [\\n                        {\"credential\": [\"AWS Certified Developer\"]}\\n                    ],\\n                    \"professional_background\": [\\n                        {\"background\": [\"Software Development\"], \"minyears\": [2], \"industry\": [\"Technology\"]}\\n                    ]\\n                },\\n                \"preferred\": {\\n                    \"hard_skills\": [\\n                        {\"skill\": [\"AWS\"], \"minyears\": [1]},\\n                        {\"skill\": [\"Docker\"], \"minyears\": [1]}\\n                    ],\\n                    \"education\": [],\\n                    \"credentials\": [],\\n                    \"professional_background\": []\\n                },\\n                \"responsibility\": {\\n                    \"hard_skills\": [\\n                        {\"skill\": [\"Develop and maintain software applications\"]}\\n                    ],\\n                    \"professional_background\": [\\n                        {\"background\": [\"Work in a collaborative team environment\"]}\\n                    ]\\n                }\\n            }\\n\\n            # Save the sample job\\n            os.makedirs(job_dir, exist_ok=True)\\n            with open(os.path.join(job_dir, \"sample_job_001.json\"), \\'w\\') as f:\\n                json.dump(sample_job, f, indent=2)\\n\\n            # Add to jobs list\\n            jobs.append(sample_job)\\n            return jobs\\n\\n        # Load job files\\n        job_files = os.listdir(job_dir)[:limit]\\n\\n        for filename in job_files:\\n            if filename.endswith(\".json\"):\\n                with open(os.path.join(job_dir, filename), \\'r\\') as f:\\n                    job_data = json.load(f)\\n                    # Add job_id if not present\\n                    if \"job_id\" not in job_data:\\n                        job_data[\"job_id\"] = filename.replace(\".json\", \"\")\\n                    jobs.append(job_data)\\n\\n    elif source_type == \"s3\":\\n        # Load from S3\\n        s3_client = boto3.client(\\'s3\\')\\n        bucket = \"mirra-matcher-325\"\\n        prefix = \"processed/jobs/\"\\n\\n        try:\\n            response = s3_client.list_objects_v2(\\n                Bucket=bucket,\\n                Prefix=prefix,\\n                MaxKeys=limit\\n            )\\n\\n            if \\'Contents\\' in response:\\n                for obj in response[\\'Contents\\']:\\n                    key = obj[\\'Key\\']\\n                    if key.endswith(\".json\"):\\n                        response = s3_client.get_object(Bucket=bucket, Key=key)\\n                        job_data = json.loads(response[\\'Body\\'].read().decode(\\'utf-8\\'))\\n                        # Add job_id if not present\\n                        if \"job_id\" not in job_data:\\n                            job_data[\"job_id\"] = key.split(\"/\")[-1].replace(\".json\", \"\")\\n                        jobs.append(job_data)\\n            else:\\n                print(f\"No job files found in S3 bucket {bucket}/{prefix}\")\\n        except Exception as e:\\n            print(f\"Error loading files from S3: {str(e)}\")\\n\\n    print(f\"Loaded {len(jobs)} job descriptions\")\\n    return jobs\\n\\n# Load job descriptions\\nsample_jobs = load_job_descriptions(source_type=\"local\", limit=3)\\n\\n# Display a preview of the first job\\nif sample_jobs:\\n    print(\"\\nPreview of first job:\")\\n    company_names = sample_jobs[0].get(\"details\", {}).get(\"company_name\", [\"Unknown\"])\\n    job_title = sample_jobs[0].get(\"details\", {}).get(\"job_title\", [\"Unknown\"])\\n    \\n    job_preview = {\\n        \"job_id\": sample_jobs[0].get(\"job_id\"),\\n        \"job_title\": job_title[0] if job_title else \"Unknown\",\\n        \"company_name\": company_names[0] if company_names else \"Unknown\"\\n    }\\n    print(json.dumps(job_preview, indent=2))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_job_descriptions(source_type=\"local\", limit=10):\n",
    "    \"\"\"\n",
    "    Load job descriptions from local storage or S3.\n",
    "\n",
    "    Args:\n",
    "        source_type: 'local' or 's3'\n",
    "        limit: Maximum number of jobs to load\n",
    "\n",
    "    Returns:\n",
    "        List of job description dictionaries\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "\n",
    "    if source_type == \"local\":\n",
    "        # Load from local directory\n",
    "        job_dir = \"../data/processed/jobs\"\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(job_dir, exist_ok=True)\n",
    "\n",
    "        # Check if directory contains files\n",
    "        if not os.path.exists(job_dir) or not os.listdir(job_dir):\n",
    "            print(f\"No job files found in {job_dir}\")\n",
    "\n",
    "            # Create a sample job for testing if no files found\n",
    "            print(\"Creating a sample job for testing...\")\n",
    "            sample_job = {\n",
    "                \"job_id\": \"sample_job_001\",\n",
    "                \"details\": {\n",
    "                    \"job_title\": [\"Software Engineer\"],\n",
    "                    \"job_title_base\": [\"Software Engineer\"],\n",
    "                    \"company_name\": [\"Sample Company\"],\n",
    "                    \"employment_type\": [\"Full-time\"],\n",
    "                    \"location\": [{\"city\": \"New York\", \"state\": \"NY\", \"country\": \"US\"}]\n",
    "                },\n",
    "                \"mandatory\": {\n",
    "                    \"hard_skills\": [\n",
    "                        {\"skill\": [\"Python\"], \"minyears\": [3]},\n",
    "                        {\"skill\": [\"Machine Learning\"], \"minyears\": [1]}\n",
    "                    ],\n",
    "                    \"education\": [\n",
    "                        {\"education_level\": [\"Bachelor's\"], \"field_of_study\": [\"Computer Science\"]}\n",
    "                    ],\n",
    "                    \"credentials\": [\n",
    "                        {\"credential\": [\"AWS Certified Developer\"]}\n",
    "                    ],\n",
    "                    \"professional_background\": [\n",
    "                        {\"background\": [\"Software Development\"], \"minyears\": [2], \"industry\": [\"Technology\"]}\n",
    "                    ]\n",
    "                },\n",
    "                \"preferred\": {\n",
    "                    \"hard_skills\": [\n",
    "                        {\"skill\": [\"AWS\"], \"minyears\": [1]},\n",
    "                        {\"skill\": [\"Docker\"], \"minyears\": [1]}\n",
    "                    ],\n",
    "                    \"education\": [],\n",
    "                    \"credentials\": [],\n",
    "                    \"professional_background\": []\n",
    "                },\n",
    "                \"responsibility\": {\n",
    "                    \"hard_skills\": [\n",
    "                        {\"skill\": [\"Develop and maintain software applications\"]}\n",
    "                    ],\n",
    "                    \"professional_background\": [\n",
    "                        {\"background\": [\"Work in a collaborative team environment\"]}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Save the sample job\n",
    "            os.makedirs(job_dir, exist_ok=True)\n",
    "            with open(os.path.join(job_dir, \"sample_job_001.json\"), 'w') as f:\n",
    "                json.dump(sample_job, f, indent=2)\n",
    "\n",
    "            # Add to jobs list\n",
    "            jobs.append(sample_job)\n",
    "            return jobs\n",
    "\n",
    "        # Load job files\n",
    "        job_files = os.listdir(job_dir)[:limit]\n",
    "\n",
    "        for filename in job_files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                with open(os.path.join(job_dir, filename), 'r') as f:\n",
    "                    job_data = json.load(f)\n",
    "                    # Add job_id if not present\n",
    "                    if \"job_id\" not in job_data:\n",
    "                        job_data[\"job_id\"] = filename.replace(\".json\", \"\")\n",
    "                    jobs.append(job_data)\n",
    "\n",
    "    elif source_type == \"s3\":\n",
    "        # Load from S3\n",
    "        s3_client = boto3.client('s3')\n",
    "        bucket = \"mirra-matcher-325\"\n",
    "        prefix = \"processed/jobs/\"\n",
    "\n",
    "        try:\n",
    "            response = s3_client.list_objects_v2(\n",
    "                Bucket=bucket,\n",
    "                Prefix=prefix,\n",
    "                MaxKeys=limit\n",
    "            )\n",
    "\n",
    "            if 'Contents' in response:\n",
    "                for obj in response['Contents']:\n",
    "                    key = obj['Key']\n",
    "                    if key.endswith(\".json\"):\n",
    "                        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                        job_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "                        # Add job_id if not present\n",
    "                        if \"job_id\" not in job_data:\n",
    "                            job_data[\"job_id\"] = key.split(\"/\")[-1].replace(\".json\", \"\")\n",
    "                        jobs.append(job_data)\n",
    "            else:\n",
    "                print(f\"No job files found in S3 bucket {bucket}/{prefix}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading files from S3: {str(e)}\")\n",
    "\n",
    "    print(f\"Loaded {len(jobs)} job descriptions\")\n",
    "    return jobs\n",
    "\n",
    "# Load job descriptions\n",
    "sample_jobs = load_job_descriptions(source_type=\"local\", limit=3)\n",
    "\n",
    "# Display a preview of the first job\n",
    "if sample_jobs:\n",
    "    print(\"\\nPreview of first job:\")\n",
    "    company_names = sample_jobs[0].get(\"details\", {}).get(\"company_name\", [\"Unknown\"])\n",
    "    job_title = sample_jobs[0].get(\"details\", {}).get(\"job_title\", [\"Unknown\"])\n",
    "    \n",
    "    job_preview = {\n",
    "        \"job_id\": sample_jobs[0].get(\"job_id\"),\n",
    "        \"job_title\": job_title[0] if job_title else \"Unknown\",\n",
    "        \"company_name\": company_names[0] if company_names else \"Unknown\"\n",
    "    }\n",
    "    print(json.dumps(job_preview, indent=2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_jobs_from_s3(bucket_name=\"mirra-matcher-325\", prefix=\"data/processed/jobs/\", limit=None):\n",
    "    \"\"\"\n",
    "    Load all job descriptions from S3.\n",
    "    \n",
    "    Args:\n",
    "        bucket_name: S3 bucket name\n",
    "        prefix: Prefix for job files in the bucket\n",
    "        limit: Maximum number of jobs to load (None for all)\n",
    "        \n",
    "    Returns:\n",
    "        List of job description dictionaries\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # List all objects with the given prefix\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        \n",
    "        # Initialize page iterator\n",
    "        page_iterator = paginator.paginate(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=prefix\n",
    "        )\n",
    "        \n",
    "        count = 0\n",
    "        # Process each page of results\n",
    "        for page in page_iterator:\n",
    "            if 'Contents' not in page:\n",
    "                continue\n",
    "                \n",
    "            for obj in page['Contents']:\n",
    "                key = obj['Key']\n",
    "                \n",
    "                if key.endswith('.json'):\n",
    "                    try:\n",
    "                        # Get the object content\n",
    "                        response = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "                        job_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "                        \n",
    "                        # Ensure job_id is present\n",
    "                        if \"job_id\" not in job_data:\n",
    "                            job_id = key.split('/')[-1].replace('.json', '')\n",
    "                            job_data[\"job_id\"] = job_id\n",
    "                            \n",
    "                        jobs.append(job_data)\n",
    "                        count += 1\n",
    "                        \n",
    "                        # Check if we've reached the limit\n",
    "                        if limit and count >= limit:\n",
    "                            print(f\"Reached limit of {limit} jobs\")\n",
    "                            return jobs\n",
    "                            \n",
    "                        # Print progress for every 10 jobs loaded\n",
    "                        if count % 10 == 0:\n",
    "                            print(f\"Loaded {count} jobs...\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading job from {key}: {e}\")\n",
    "        \n",
    "        print(f\"Successfully loaded {len(jobs)} jobs from S3\")\n",
    "        return jobs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing objects in S3: {e}\")\n",
    "        return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IioWN5jwWfe3"
   },
   "outputs": [],
   "source": [
    "def process_and_embed_job(job_data, embedder):\n",
    "    \"\"\"\n",
    "    Process a job into chunks and generate embeddings.\n",
    "    \n",
    "    Args:\n",
    "        job_data: Job description dictionary\n",
    "        embedder: EmbeddingGenerator instance or SageMakerEmbedder instance\n",
    "        \n",
    "    Returns:\n",
    "        List of vectors ready for Pinecone\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "\n",
    "    # Validate job data\n",
    "    if not isinstance(job_data, dict) or \"details\" not in job_data:\n",
    "        print(\"Invalid job data format\")\n",
    "        return []\n",
    "    \n",
    "    # Ensure job has an ID\n",
    "    job_id = job_data.get(\"job_id\")\n",
    "    if not job_id:\n",
    "        job_id = str(uuid.uuid4())\n",
    "        job_data[\"job_id\"] = job_id\n",
    "    \n",
    "    # Generate chunks\n",
    "    chunks = chunk_job_description(job_data)\n",
    "    print(f\"Generated {len(chunks)} chunks for job {job_id}\")\n",
    "    \n",
    "    if not chunks:\n",
    "        print(\"No chunks generated. Check the job data structure.\")\n",
    "        return []\n",
    "    \n",
    "    # Create batch for embedding\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    \n",
    "    # Generate embeddings in batches\n",
    "    vectors = []\n",
    "    batch_size = 32  # Adjust as needed\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            # Check which type of embedder we're using\n",
    "            if isinstance(embedder, SageMakerEmbedder):\n",
    "                # If using SageMakerEmbedder directly, only pass texts\n",
    "                batch_embeddings = embedder.generate_embeddings(batch_texts)\n",
    "            else:\n",
    "                # If using EmbeddingGenerator, prepare instructions\n",
    "                batch_instructions = []\n",
    "                for j in range(i, min(i+batch_size, len(chunks))):\n",
    "                    chunk_type = chunks[j][\"metadata\"][\"chunk_type\"]\n",
    "                    if chunk_type == \"skill\":\n",
    "                        instruction = \"Represent this skill qualification for job-resume matching\"\n",
    "                    elif chunk_type == \"education\":\n",
    "                        instruction = \"Represent this educational qualification for job-resume matching\"\n",
    "                    elif chunk_type == \"experience\":\n",
    "                        instruction = \"Represent this professional experience for job-resume matching\"\n",
    "                    elif chunk_type == \"credential\":\n",
    "                        instruction = \"Represent this professional credential for job-resume matching\"\n",
    "                    else:\n",
    "                        instruction = \"Represent this qualification for job-resume matching\"\n",
    "                    batch_instructions.append(instruction)\n",
    "                \n",
    "                # Pass instructions only if using EmbeddingGenerator\n",
    "                batch_embeddings = embedder.generate_embeddings(\n",
    "                    batch_texts,\n",
    "                    batch_instructions if not USE_JINA_API else None\n",
    "                )\n",
    "            \n",
    "            # Create vectors for Pinecone\n",
    "            for j, emb in enumerate(batch_embeddings):\n",
    "                chunk_index = i + j\n",
    "                if chunk_index < len(chunks):  # Safety check\n",
    "                    vector_id = f\"{job_id}_chunk_{chunk_index}\"\n",
    "                    \n",
    "                    # Extract the actual embedding vector if emb is a dict\n",
    "                    if isinstance(emb, dict) and \"embedding\" in emb:\n",
    "                        embedding_vector = emb[\"embedding\"]\n",
    "                    else:\n",
    "                        embedding_vector = emb\n",
    "                    \n",
    "                    # Convert each element in the embedding vector to a float\n",
    "                    try:\n",
    "                        embedding_floats = [float(v) for v in embedding_vector]\n",
    "                    except Exception as conv_e:\n",
    "                        print(f\"Error converting embedding to floats for chunk {chunk_index}: {conv_e}\")\n",
    "                        continue\n",
    "                    \n",
    "                    vector = {\n",
    "                        \"id\": vector_id,\n",
    "                        \"values\": embedding_floats,\n",
    "                        \"metadata\": {\n",
    "                            \"chunk_text\": chunks[chunk_index][\"text\"],\n",
    "                            **chunks[chunk_index][\"metadata\"]\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    vectors.append(vector)\n",
    "            \n",
    "            print(f\"Processed batch of {len(batch_texts)} chunks\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {str(e)}\")\n",
    "        \n",
    "    return vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectors_for_pinecone(vectors):\n",
    "    \"\"\"\n",
    "    Clean metadata to make it compatible with Pinecone by removing null values.\n",
    "    \n",
    "    Args:\n",
    "        vectors: List of vector dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        List of vectors with cleaned metadata\n",
    "    \"\"\"\n",
    "    cleaned_vectors = []\n",
    "    \n",
    "    for vector in vectors:\n",
    "        # Create a new metadata dictionary without None values\n",
    "        cleaned_metadata = {}\n",
    "        \n",
    "        for key, value in vector[\"metadata\"].items():\n",
    "            if value is not None:\n",
    "                cleaned_metadata[key] = value\n",
    "            else:\n",
    "                # Replace None with appropriate default values\n",
    "                if key in [\"context_id\", \"relationship_type\", \"industry\", \n",
    "                         \"responsibility_category\"]:\n",
    "                    cleaned_metadata[key] = \"\"  # Empty string for text fields\n",
    "                elif key in [\"context_index\", \"context_total\"]:\n",
    "                    cleaned_metadata[key] = 0  # Zero for numeric fields\n",
    "                else:\n",
    "                    cleaned_metadata[key] = \"\"  # Default to empty string\n",
    "        \n",
    "        # Create a new vector with cleaned metadata\n",
    "        cleaned_vector = {\n",
    "            \"id\": vector[\"id\"],\n",
    "            \"values\": vector[\"values\"],\n",
    "            \"metadata\": cleaned_metadata\n",
    "        }\n",
    "        \n",
    "        cleaned_vectors.append(cleaned_vector)\n",
    "    \n",
    "    return cleaned_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3INovyWVWi_s"
   },
   "outputs": [],
   "source": [
    "def upload_vectors_to_pinecone(vectors, index):\n",
    "    \"\"\"\n",
    "    Upload vectors to Pinecone in batches.\n",
    "\n",
    "    Args:\n",
    "        vectors: List of vectors\n",
    "        index: Pinecone index\n",
    "\n",
    "    Returns:\n",
    "        Number of vectors uploaded\n",
    "    \"\"\"\n",
    "    if not vectors:\n",
    "        print(\"No vectors to upload\")\n",
    "        return 0\n",
    "\n",
    "    if not index:\n",
    "        print(\"No valid Pinecone index provided\")\n",
    "        return 0\n",
    "\n",
    "    batch_size = 100  # Pinecone recommends max 100 per batch\n",
    "\n",
    "    total_uploaded = 0\n",
    "    for i in tqdm(range(0, len(vectors), batch_size), desc=\"Uploading to Pinecone\"):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        try:\n",
    "            index.upsert(vectors=batch)\n",
    "            total_uploaded += len(batch)\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading batch to Pinecone: {str(e)}\")\n",
    "\n",
    "    return total_uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached limit of 1 jobs\n",
      "Processing job: 04a9e436-fbc3-4d2f-a543-a6474dc485f9\n",
      "Generated 38 chunks for job 04a9e436-fbc3-4d2f-a543-a6474dc485f9\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 6 chunks\n",
      "Generated 38 vectors in 0.24 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and indexed job 04a9e436-fbc3-4d2f-a543-a6474dc485f9 with 38 vectors\n",
      "Upload took 0.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process and embed a single sample job from S3 for testing\n",
    "test_job = load_all_jobs_from_s3(limit=1)\n",
    "\n",
    "if test_job and pinecone_index:\n",
    "    sample_job = test_job[0]\n",
    "    job_id = sample_job.get(\"job_id\")\n",
    "\n",
    "    print(f\"Processing job: {job_id}\")\n",
    "\n",
    "    try:\n",
    "        # Generate vectors\n",
    "        start_time = time.time()\n",
    "        vectors = process_and_embed_job(sample_job, embedder)\n",
    "        embedding_time = time.time() - start_time\n",
    "\n",
    "        if vectors:\n",
    "            print(f\"Generated {len(vectors)} vectors in {embedding_time:.2f} seconds\")\n",
    "            \n",
    "            # Clean vectors before uploading to Pinecone\n",
    "            clean_vectors = prepare_vectors_for_pinecone(vectors)\n",
    "            \n",
    "            # Upload to Pinecone\n",
    "            upload_start = time.time()\n",
    "            uploaded = upload_vectors_to_pinecone(clean_vectors, pinecone_index)\n",
    "            upload_time = time.time() - upload_start\n",
    "\n",
    "            print(f\"Successfully processed and indexed job {job_id} with {uploaded} vectors\")\n",
    "            print(f\"Upload took {upload_time:.2f} seconds\")\n",
    "        else:\n",
    "            print(\"No vectors were generated. Check for errors above.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing job {job_id}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wgqXeJP7WonI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved 0 vectors for job 04a9e436-fbc3-4d2f-a543-a6474dc485f9\n",
      "No vectors retrieved. Check if the upload was successful.\n"
     ]
    }
   ],
   "source": [
    "# Test retrieving vectors for sample job\n",
    "if pinecone_index and 'job_id' in locals() and job_id:\n",
    "    try:\n",
    "        # Query for vectors related to this job\n",
    "        results = pinecone_index.query(\n",
    "            vector=[0.0] * EMBEDDING_DIMENSION,  #Using a zero vector just to retrieve by metadata\n",
    "            filter={\"job_id\": job_id},\n",
    "            top_k=5,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        print(f\"\\nRetrieved {len(results['matches'])} vectors for job {job_id}\")\n",
    "\n",
    "        # Show a sample of retrieved vectors\n",
    "        if results[\"matches\"]:\n",
    "            print(\"\\nSample retrieved vector:\")\n",
    "            sample_match = results[\"matches\"][0]\n",
    "            # Only show relevant metadata for clarity\n",
    "            relevant_metadata = {k: v for k, v in sample_match[\"metadata\"].items()\n",
    "                               if k in [\"chunk_text\", \"chunk_type\", \"requirement_level\", \"skill_name\"]}\n",
    "            print(json.dumps(relevant_metadata, indent=2))\n",
    "        else:\n",
    "            print(\"No vectors retrieved. Check if the upload was successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Pinecone: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tV7R35gOWqTx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 jobs...\n",
      "Loaded 20 jobs...\n",
      "Successfully loaded 25 jobs from S3\n",
      "Processing all 25 jobs from S3\n",
      "Starting processing of 25 jobs\n",
      "\n",
      "Processing job 1/25: 04a9e436-fbc3-4d2f-a543-a6474dc485f9\n",
      "Generated 38 chunks for job 04a9e436-fbc3-4d2f-a543-a6474dc485f9\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 6 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 04a9e436-fbc3-4d2f-a543-a6474dc485f9 with 38 vectors\n",
      "Progress: 1/25 jobs processed\n",
      "Speed: 1.93 jobs/second\n",
      "Estimated time remaining: 0.2 minutes\n",
      "\n",
      "Processing job 2/25: 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\n",
      "Generated 42 chunks for job 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 10 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 0ca4cd66-bba5-4efa-8b26-ecc57bb3939e with 42 vectors\n",
      "Progress: 2/25 jobs processed\n",
      "Speed: 1.86 jobs/second\n",
      "Estimated time remaining: 0.2 minutes\n",
      "\n",
      "Processing job 3/25: 0d652f5d-9822-4b9b-8274-65674eb68b42\n",
      "Generated 46 chunks for job 0d652f5d-9822-4b9b-8274-65674eb68b42\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 14 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 0d652f5d-9822-4b9b-8274-65674eb68b42 with 46 vectors\n",
      "Progress: 3/25 jobs processed\n",
      "Speed: 1.88 jobs/second\n",
      "Estimated time remaining: 0.2 minutes\n",
      "\n",
      "Processing job 4/25: 11afeb1b-bfe3-414e-9946-4f199f93f011\n",
      "Generated 30 chunks for job 11afeb1b-bfe3-414e-9946-4f199f93f011\n",
      "Processed batch of 30 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 11afeb1b-bfe3-414e-9946-4f199f93f011 with 30 vectors\n",
      "Progress: 4/25 jobs processed\n",
      "Speed: 1.98 jobs/second\n",
      "Estimated time remaining: 0.2 minutes\n",
      "\n",
      "Processing job 5/25: 1f58b149-ed8e-4fb2-96dd-d83d266f5310\n",
      "Generated 24 chunks for job 1f58b149-ed8e-4fb2-96dd-d83d266f5310\n",
      "Processed batch of 24 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 1f58b149-ed8e-4fb2-96dd-d83d266f5310 with 24 vectors\n",
      "Progress: 5/25 jobs processed\n",
      "Speed: 2.22 jobs/second\n",
      "Estimated time remaining: 0.2 minutes\n",
      "\n",
      "Processing job 6/25: 3acaf400-50b0-4906-8c86-ed7184df8712\n",
      "Generated 24 chunks for job 3acaf400-50b0-4906-8c86-ed7184df8712\n",
      "Processed batch of 24 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 3acaf400-50b0-4906-8c86-ed7184df8712 with 24 vectors\n",
      "Progress: 6/25 jobs processed\n",
      "Speed: 2.26 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 7/25: 44c8bc5c-49c1-4467-b7b4-fdb2e7e11790\n",
      "Generated 55 chunks for job 44c8bc5c-49c1-4467-b7b4-fdb2e7e11790\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 23 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 44c8bc5c-49c1-4467-b7b4-fdb2e7e11790 with 55 vectors\n",
      "Progress: 7/25 jobs processed\n",
      "Speed: 2.13 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 8/25: 57cea150-f3f7-4238-95a5-1db5b6e940eb\n",
      "Generated 31 chunks for job 57cea150-f3f7-4238-95a5-1db5b6e940eb\n",
      "Processed batch of 31 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 57cea150-f3f7-4238-95a5-1db5b6e940eb with 31 vectors\n",
      "Progress: 8/25 jobs processed\n",
      "Speed: 2.22 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 9/25: 5e00aafa-57c3-4c06-8b06-1fe311bc8e4e\n",
      "Generated 16 chunks for job 5e00aafa-57c3-4c06-8b06-1fe311bc8e4e\n",
      "Processed batch of 16 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 5e00aafa-57c3-4c06-8b06-1fe311bc8e4e with 16 vectors\n",
      "Progress: 9/25 jobs processed\n",
      "Speed: 2.33 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 10/25: 69c34396-8455-47cf-a8df-d09dbd7e31ea\n",
      "Generated 32 chunks for job 69c34396-8455-47cf-a8df-d09dbd7e31ea\n",
      "Processed batch of 32 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 69c34396-8455-47cf-a8df-d09dbd7e31ea with 32 vectors\n",
      "Progress: 10/25 jobs processed\n",
      "Speed: 2.30 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 11/25: 901969dd-7034-47f0-b539-30dacd5e928d\n",
      "Generated 27 chunks for job 901969dd-7034-47f0-b539-30dacd5e928d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch of 27 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 901969dd-7034-47f0-b539-30dacd5e928d with 27 vectors\n",
      "Progress: 11/25 jobs processed\n",
      "Speed: 2.36 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 12/25: 90a9f50c-584c-49a4-ac5e-5928ff8a4b94\n",
      "Generated 38 chunks for job 90a9f50c-584c-49a4-ac5e-5928ff8a4b94\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 6 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 90a9f50c-584c-49a4-ac5e-5928ff8a4b94 with 38 vectors\n",
      "Progress: 12/25 jobs processed\n",
      "Speed: 2.32 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 13/25: 98ab83df-021a-4889-9af3-bd6664d725e2\n",
      "Generated 28 chunks for job 98ab83df-021a-4889-9af3-bd6664d725e2\n",
      "Processed batch of 28 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 98ab83df-021a-4889-9af3-bd6664d725e2 with 28 vectors\n",
      "Progress: 13/25 jobs processed\n",
      "Speed: 2.39 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 14/25: 9d15576d-1d0f-4396-88d7-4ea76a13d639\n",
      "Generated 43 chunks for job 9d15576d-1d0f-4396-88d7-4ea76a13d639\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 11 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job 9d15576d-1d0f-4396-88d7-4ea76a13d639 with 43 vectors\n",
      "Progress: 14/25 jobs processed\n",
      "Speed: 2.37 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 15/25: a2998f35-d332-4fee-8170-c9c946fab8e0\n",
      "Generated 33 chunks for job a2998f35-d332-4fee-8170-c9c946fab8e0\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 1 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job a2998f35-d332-4fee-8170-c9c946fab8e0 with 33 vectors\n",
      "Progress: 15/25 jobs processed\n",
      "Speed: 2.39 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 16/25: a7fe9a21-6a8d-4069-ae47-57083bb97667\n",
      "Generated 38 chunks for job a7fe9a21-6a8d-4069-ae47-57083bb97667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch of 32 chunks\n",
      "Processed batch of 6 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job a7fe9a21-6a8d-4069-ae47-57083bb97667 with 38 vectors\n",
      "Progress: 16/25 jobs processed\n",
      "Speed: 2.35 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 17/25: b5c6e3df-df3a-4e5b-a850-8ebe8be6fcc6\n",
      "Generated 23 chunks for job b5c6e3df-df3a-4e5b-a850-8ebe8be6fcc6\n",
      "Processed batch of 23 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job b5c6e3df-df3a-4e5b-a850-8ebe8be6fcc6 with 23 vectors\n",
      "Progress: 17/25 jobs processed\n",
      "Speed: 2.35 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 18/25: babf4bb0-7f3a-48e6-be4b-53e3934f9e0a\n",
      "Generated 49 chunks for job babf4bb0-7f3a-48e6-be4b-53e3934f9e0a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch of 32 chunks\n",
      "Processed batch of 17 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job babf4bb0-7f3a-48e6-be4b-53e3934f9e0a with 49 vectors\n",
      "Progress: 18/25 jobs processed\n",
      "Speed: 2.30 jobs/second\n",
      "Estimated time remaining: 0.1 minutes\n",
      "\n",
      "Processing job 19/25: c51dca25-7ccf-4b90-a640-2a095c3aaea1\n",
      "Generated 34 chunks for job c51dca25-7ccf-4b90-a640-2a095c3aaea1\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 2 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job c51dca25-7ccf-4b90-a640-2a095c3aaea1 with 34 vectors\n",
      "Progress: 19/25 jobs processed\n",
      "Speed: 2.32 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 20/25: cd540421-60f8-4a39-acb5-e27a0659e83f\n",
      "Generated 63 chunks for job cd540421-60f8-4a39-acb5-e27a0659e83f\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 31 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job cd540421-60f8-4a39-acb5-e27a0659e83f with 63 vectors\n",
      "Progress: 20/25 jobs processed\n",
      "Speed: 2.22 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 21/25: d645a2b1-4888-40f7-be2b-efed95803965\n",
      "Generated 34 chunks for job d645a2b1-4888-40f7-be2b-efed95803965\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 2 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job d645a2b1-4888-40f7-be2b-efed95803965 with 34 vectors\n",
      "Progress: 21/25 jobs processed\n",
      "Speed: 2.22 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 22/25: d84838c8-db39-4750-9021-64c5e2c14fe1\n",
      "Generated 27 chunks for job d84838c8-db39-4750-9021-64c5e2c14fe1\n",
      "Processed batch of 27 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job d84838c8-db39-4750-9021-64c5e2c14fe1 with 27 vectors\n",
      "Progress: 22/25 jobs processed\n",
      "Speed: 2.25 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 23/25: f20e91c6-5042-44a7-a065-6a9454797a47\n",
      "Generated 34 chunks for job f20e91c6-5042-44a7-a065-6a9454797a47\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 2 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job f20e91c6-5042-44a7-a065-6a9454797a47 with 34 vectors\n",
      "Progress: 23/25 jobs processed\n",
      "Speed: 2.24 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 24/25: f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Generated 51 chunks for job f6aeaba8-87f5-498c-919a-8d25d63d3d9e\n",
      "Processed batch of 32 chunks\n",
      "Processed batch of 19 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job f6aeaba8-87f5-498c-919a-8d25d63d3d9e with 51 vectors\n",
      "Progress: 24/25 jobs processed\n",
      "Speed: 2.23 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing job 25/25: f71df3a6-441f-44af-bd75-f6d922e08a37\n",
      "Generated 26 chunks for job f71df3a6-441f-44af-bd75-f6d922e08a37\n",
      "Processed batch of 26 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed job f71df3a6-441f-44af-bd75-f6d922e08a37 with 26 vectors\n",
      "Progress: 25/25 jobs processed\n",
      "Speed: 2.25 jobs/second\n",
      "Estimated time remaining: 0.0 minutes\n",
      "\n",
      "Processing complete!\n",
      "Successfully processed 25/25 jobs\n",
      "Total vectors created: 886\n",
      "Processing time: 11.11 seconds\n",
      "Average processing speed: 2.25 jobs/second\n",
      "\n",
      "Final index statistics: {\n",
      "  \"namespaces\": {\n",
      "    \"\": {\n",
      "      \"vector_count\": 809\n",
      "    }\n",
      "  },\n",
      "  \"index_fullness\": 0.0,\n",
      "  \"total_vector_count\": 809,\n",
      "  \"dimension\": 1024,\n",
      "  \"metric\": \"cosine\",\n",
      "  \"vector_type\": \"dense\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_all_jobs(jobs, embedder, index, batch_size=5):\n",
    "    \"\"\"\n",
    "    Process multiple jobs and upload to Pinecone.\n",
    "\n",
    "    Args:\n",
    "        jobs: List of job dictionaries\n",
    "        embedder: EmbeddingGenerator instance\n",
    "        index: Pinecone index\n",
    "        batch_size: Number of jobs to process at once\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with processing statistics\n",
    "    \"\"\"\n",
    "    if not jobs:\n",
    "        print(\"No jobs to process\")\n",
    "        return {\"total_jobs\": 0}\n",
    "\n",
    "    if not index:\n",
    "        print(\"No valid Pinecone index provided\")\n",
    "        return {\"total_jobs\": len(jobs), \"successful_jobs\": 0, \"failed_jobs\": [job.get(\"job_id\", \"unknown\") for job in jobs]}\n",
    "\n",
    "    total_jobs = len(jobs)\n",
    "    total_chunks = 0\n",
    "    total_vectors = 0\n",
    "    failed_jobs = []\n",
    "\n",
    "    print(f\"Starting processing of {total_jobs} jobs\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, job in enumerate(jobs):\n",
    "        job_id = job.get(\"job_id\", str(uuid.uuid4()))\n",
    "        print(f\"\\nProcessing job {i+1}/{total_jobs}: {job_id}\")\n",
    "\n",
    "        try:\n",
    "            # Generate vectors\n",
    "            vectors = process_and_embed_job(job, embedder)\n",
    "            total_chunks += len(vectors)\n",
    "\n",
    "            # Upload to Pinecone\n",
    "            uploaded = upload_vectors_to_pinecone(vectors, index)\n",
    "            total_vectors += uploaded\n",
    "\n",
    "            print(f\"Successfully processed job {job_id} with {uploaded} vectors\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing job {job_id}: {str(e)}\")\n",
    "            failed_jobs.append(job_id)\n",
    "\n",
    "        # Simple progress update\n",
    "        elapsed = time.time() - start_time\n",
    "        jobs_per_second = (i + 1) / elapsed if elapsed > 0 else 0\n",
    "        estimated_remaining = (total_jobs - (i + 1)) / jobs_per_second if jobs_per_second > 0 else 0\n",
    "\n",
    "        print(f\"Progress: {i+1}/{total_jobs} jobs processed\")\n",
    "        print(f\"Speed: {jobs_per_second:.2f} jobs/second\")\n",
    "        print(f\"Estimated time remaining: {estimated_remaining/60:.1f} minutes\")\n",
    "\n",
    "    # Final stats\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    stats = {\n",
    "        \"total_jobs\": total_jobs,\n",
    "        \"successful_jobs\": total_jobs - len(failed_jobs),\n",
    "        \"failed_jobs\": failed_jobs,\n",
    "        \"total_chunks\": total_chunks,\n",
    "        \"total_vectors\": total_vectors,\n",
    "        \"processing_time_seconds\": total_time,\n",
    "        \"jobs_per_second\": total_jobs / total_time if total_time > 0 else 0\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Load all jobs from S3 \n",
    "all_s3_jobs = load_all_jobs_from_s3(limit=None)  \n",
    "\n",
    "if all_s3_jobs and pinecone_index:\n",
    "    print(f\"Processing all {len(all_s3_jobs)} jobs from S3\")\n",
    "\n",
    "    stats = process_all_jobs(all_s3_jobs, embedder, pinecone_index, batch_size=10)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Successfully processed {stats['successful_jobs']}/{stats['total_jobs']} jobs\")\n",
    "    print(f\"Total vectors created: {stats.get('total_vectors', 0)}\")\n",
    "    print(f\"Processing time: {stats.get('processing_time_seconds', 0):.2f} seconds\")\n",
    "\n",
    "    if stats.get('processing_time_seconds', 0) > 0:\n",
    "        print(f\"Average processing speed: {stats.get('jobs_per_second', 0):.2f} jobs/second\")\n",
    "\n",
    "    if stats.get('failed_jobs', []):\n",
    "        print(f\"Failed jobs: {stats['failed_jobs']}\")\n",
    "        \n",
    "    # Check the index statistics after processing\n",
    "    index_stats = pinecone_index.describe_index_stats()\n",
    "    index_stats_dict = index_stats.to_dict()\n",
    "    print(f\"\\nFinal index statistics: {json.dumps(index_stats_dict, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_job_chunks(job, num_chunks=3, include_metadata_fields=None, exclude_metadata_fields=None):\n",
    "    \"\"\"\n",
    "    Generate and display chunks for a job, with customizable metadata viewing options.\n",
    "    \n",
    "    Args:\n",
    "        job: Job description dictionary\n",
    "        num_chunks: Number of chunks to display (default 3)\n",
    "        include_metadata_fields: List of specific metadata fields to include (None for all)\n",
    "        exclude_metadata_fields: List of metadata fields to exclude (default ['source_type'])\n",
    "    \"\"\"\n",
    "    if not job:\n",
    "        print(\"No job provided\")\n",
    "        return\n",
    "    \n",
    "    # Default exclusions\n",
    "    if exclude_metadata_fields is None:\n",
    "        exclude_metadata_fields = ['source_type']\n",
    "    \n",
    "    job_id = job.get('job_id', 'unknown')\n",
    "    print(f\"Generating chunks for job: {job_id}\")\n",
    "    \n",
    "    # Get job title if available\n",
    "    job_title = \"Unknown\"\n",
    "    if \"details\" in job and \"job_title\" in job[\"details\"]:\n",
    "        job_title_data = job[\"details\"][\"job_title\"]\n",
    "        if isinstance(job_title_data, list) and job_title_data:\n",
    "            job_title = job_title_data[0]\n",
    "        elif isinstance(job_title_data, str):\n",
    "            job_title = job_title_data\n",
    "    print(f\"Job Title: {job_title}\")\n",
    "    \n",
    "    # Generate chunks\n",
    "    chunks = chunk_job_description(job)\n",
    "    print(f\"Generated {len(chunks)} chunks\")\n",
    "    \n",
    "    # Count chunk types\n",
    "    chunk_types = {}\n",
    "    for chunk in chunks:\n",
    "        chunk_type = chunk[\"metadata\"].get(\"chunk_type\", \"unknown\")\n",
    "        if chunk_type not in chunk_types:\n",
    "            chunk_types[chunk_type] = 0\n",
    "        chunk_types[chunk_type] += 1\n",
    "    \n",
    "    print(\"\\nChunk Type Distribution:\")\n",
    "    for chunk_type, count in chunk_types.items():\n",
    "        print(f\"  {chunk_type}: {count} chunks\")\n",
    "    \n",
    "    # Display sample chunks\n",
    "    display_count = min(num_chunks, len(chunks))\n",
    "    print(f\"\\nShowing {display_count} sample chunks:\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunks[:display_count]):\n",
    "        print(f\"\\nChunk {i+1}:\")\n",
    "        print(f\"Text: {chunk['text']}\")\n",
    "        \n",
    "        # Filter metadata based on include/exclude parameters\n",
    "        filtered_metadata = {}\n",
    "        for k, v in chunk['metadata'].items():\n",
    "            if exclude_metadata_fields and k in exclude_metadata_fields:\n",
    "                continue\n",
    "            if include_metadata_fields and k not in include_metadata_fields:\n",
    "                continue\n",
    "            filtered_metadata[k] = v\n",
    "        \n",
    "        print(f\"Metadata: {json.dumps(filtered_metadata, indent=2)}\")\n",
    "    \n",
    "    # Option to show more chunks\n",
    "    if len(chunks) > display_count:\n",
    "        print(f\"\\nNot showing {len(chunks) - display_count} additional chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached limit of 3 jobs\n",
      "Generating chunks for job: 04a9e436-fbc3-4d2f-a543-a6474dc485f9\n",
      "Job Title: Technology Delivery Lead\n",
      "Generated 38 chunks\n",
      "\n",
      "Chunk Type Distribution:\n",
      "  job_title: 1 chunks\n",
      "  employment_type: 1 chunks\n",
      "  experience_level: 1 chunks\n",
      "  location: 1 chunks\n",
      "  work_authorization: 1 chunks\n",
      "  skill: 17 chunks\n",
      "  skill_group: 2 chunks\n",
      "  experience: 3 chunks\n",
      "  experience_group: 1 chunks\n",
      "  responsibility: 9 chunks\n",
      "  responsibility_group: 1 chunks\n",
      "\n",
      "Showing 38 sample chunks:\n",
      "\n",
      "Chunk 1:\n",
      "Text: Job title: Technology Delivery Lead\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"job_title\"\n",
      "}\n",
      "\n",
      "Chunk 2:\n",
      "Text: Employment type: Contract\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"employment_type\"\n",
      "}\n",
      "\n",
      "Chunk 3:\n",
      "Text: Experience level: Senior\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"experience_level\"\n",
      "}\n",
      "\n",
      "Chunk 4:\n",
      "Text: Location: Irving, TX, US\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"location\"\n",
      "}\n",
      "\n",
      "Chunk 5:\n",
      "Text: Work authorization: Does Not Offer Sponsorship\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"work_authorization\"\n",
      "}\n",
      "\n",
      "Chunk 6:\n",
      "Text: Required skill: Allegro with at least 3 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"Allegro\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 7:\n",
      "Text: Required skill: Commodity Trading in Power with at least 3 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"Commodity Trading in Power\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 8:\n",
      "Text: Required skill: Commodity Trading in Gas with at least 3 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"Commodity Trading in Gas\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 9:\n",
      "Text: Required skill: Commodity Trading in Coal with at least 3 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"Commodity Trading in Coal\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 10:\n",
      "Text: Required skill: Commodity Trading in Nuclear with at least 3 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"Commodity Trading in Nuclear\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 11:\n",
      "Text: Required skill: designing allegro extensions with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"designing allegro extensions\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 12:\n",
      "Text: Required skill: developing allegro extensions with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"developing allegro extensions\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 13:\n",
      "Text: Required skill: managing implementation allegro extensions with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"managing implementation allegro extensions\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 14:\n",
      "Text: Required skill: designing interfaces with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"designing interfaces\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 15:\n",
      "Text: Required skill: developing interfaces with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"developing interfaces\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 16:\n",
      "Text: Required skill: managing implementation interfaces with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"managing implementation interfaces\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 17:\n",
      "Text: Required skill: designing other complex systems with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"designing other complex systems\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 18:\n",
      "Text: Required skill: developing other complex systems with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"developing other complex systems\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 19:\n",
      "Text: Required skill: managing implementation other complex systems with at least 8 years of experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"skill_name\": \"managing implementation other complex systems\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 20:\n",
      "Text: Required skills (needs all of these): Allegro; Commodity Trading in Power; Commodity Trading in Gas; Commodity Trading in Coal; Commodity Trading in Nuclear; designing allegro extensions; developing allegro extensions; managing implementation allegro extensions; designing interfaces; developing interfaces; managing implementation interfaces; designing other complex systems; developing other complex systems; managing implementation other complex systems\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill_group\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"context_id\": \"3e7b6d83-ec05-45a1-a7dd-76443880042c\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 21:\n",
      "Text: Required experience: Experienced Leadership skills in managing implementation allegro extensions with significant (8+ years) professional experience (significant depth of experience required)\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"experience\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"context_id\": \"e4691d00-c716-4824-884f-dd3f9f64d968\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 22:\n",
      "Text: Required experience: Experienced Leadership skills in managing implementation interfaces with significant (8+ years) professional experience (significant depth of experience required)\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"experience\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"context_id\": \"e4691d00-c716-4824-884f-dd3f9f64d968\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 23:\n",
      "Text: Required experience: Experienced Leadership skills in managing implementation other complex systems with significant (8+ years) professional experience (significant depth of experience required)\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"experience\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"context_id\": \"e4691d00-c716-4824-884f-dd3f9f64d968\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 24:\n",
      "Text: Required experience (looking for one of the following): Leadership skills in managing implementation allegro extensions with significant (8+ years) professional experience OR Leadership skills in managing implementation interfaces with significant (8+ years) professional experience OR Leadership skills in managing implementation other complex systems with significant (8+ years) professional experience\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"experience_group\",\n",
      "  \"requirement_level\": \"mandatory\",\n",
      "  \"context_id\": \"e4691d00-c716-4824-884f-dd3f9f64d968\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 25:\n",
      "Text: Preferred skill: Systems Architecture\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"preferred\",\n",
      "  \"skill_name\": \"Systems Architecture\",\n",
      "  \"context_id\": \"b1243a3a-f654-4dd7-b697-03aec463129c\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 26:\n",
      "Text: Preferred skill: Service Delivery\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"preferred\",\n",
      "  \"skill_name\": \"Service Delivery\",\n",
      "  \"context_id\": \"b1243a3a-f654-4dd7-b697-03aec463129c\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 27:\n",
      "Text: Preferred skill: AWS Cloud Skills\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill\",\n",
      "  \"requirement_level\": \"preferred\",\n",
      "  \"skill_name\": \"AWS Cloud Skills\",\n",
      "  \"context_id\": \"b1243a3a-f654-4dd7-b697-03aec463129c\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 28:\n",
      "Text: Preferred skills (any of these): Systems Architecture, Service Delivery and AWS Cloud Skills\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"skill_group\",\n",
      "  \"requirement_level\": \"preferred\",\n",
      "  \"context_id\": \"b1243a3a-f654-4dd7-b697-03aec463129c\",\n",
      "  \"relationship_type\": \"OR\"\n",
      "}\n",
      "\n",
      "Chunk 29:\n",
      "Text: Job responsibility: Build and maintain Oversee overall IT operations of client Wholesale applications.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 30:\n",
      "Text: Job responsibility: Manage incident and problem resolution processes.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 31:\n",
      "Text: Job responsibility: Oversee end-of-day batch processes and ensure Service Level Agreements (SLAs) are met.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 32:\n",
      "Text: Job responsibility: Manage month/year-end activities and support critical business processes.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 33:\n",
      "Text: Job responsibility: Manage on/off cycle releases and secure change management approvals.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 34:\n",
      "Text: Job responsibility: Act as a business point of contact for any critical incident.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 35:\n",
      "Text: Job responsibility: Manage onshore and offshore day-to-day work.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 36:\n",
      "Text: Job responsibility: Participate in audits and coordinate security patching activities.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 37:\n",
      "Text: Job responsibility: Generate and analyze Report status and metrics to Accenture and client leadership.\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n",
      "\n",
      "Chunk 38:\n",
      "Text: Core job responsibilities:\n",
      "• Oversee overall IT operations of client Wholesale applications\n",
      "• Manage incident and problem resolution processes\n",
      "• Oversee end-of-day batch processes and ensure Service Level Agreements (SLAs) are met\n",
      "• Manage month/year-end activities and support critical business processes\n",
      "• Manage on/off cycle releases and secure change management approvals\n",
      "• Act as a business point of contact for any critical incident\n",
      "• Manage onshore and offshore day-to-day work\n",
      "• Participate in audits and coordinate security patching activities\n",
      "• Report status and metrics to Accenture and client leadership\n",
      "Metadata: {\n",
      "  \"chunk_type\": \"responsibility_group\",\n",
      "  \"requirement_level\": \"responsibility\",\n",
      "  \"context_id\": \"a87eb725-4d49-4b32-9dd0-1434424810c4\",\n",
      "  \"relationship_type\": \"AND\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "all_s3_jobs = load_all_jobs_from_s3(limit=3)  # Load just 3 for demonstration\n",
    "if all_s3_jobs:\n",
    "    sample_job = all_s3_jobs[0]\n",
    "    # Show more chunks with specific metadata fields\n",
    "    inspect_job_chunks(\n",
    "        sample_job, \n",
    "        num_chunks=38,  # Show 5 chunks\n",
    "        include_metadata_fields=['chunk_type', 'requirement_level', 'skill_name', 'context_id', 'relationship_type']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
